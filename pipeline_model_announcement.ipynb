{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae0109c-d6a7-4dad-9fda-c48274918378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from supabase import create_client, Client\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")\n",
    "supabase_api_key = os.environ.get(\"SUPBASE_KEY\")\n",
    "\n",
    "supabase: Client = create_client(supabase_url, supabase_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcd5de9-e30f-4d41-afcb-cbb8ef32706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09ad069-ed12-4396-886d-1a9e3d537ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_research(date):\n",
    "    result = supabase.table('curation_selected_items')\\\n",
    "        .select('event_id, output,sources, news_date','topic')\\\n",
    "    .eq('news_date', date)\\\n",
    "    .eq('topic', 'Model announcements/enhancements')\\\n",
    "        .order('created_at', desc=False)\\\n",
    "        .execute()\n",
    "    \n",
    "    return result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00beaf8-02bd-476d-aa35-cad741be6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_deep_dive = funding_research('2026-02-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8c51735-39df-4978-a7d1-5a42544b1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_research_model(research_input):\n",
    "    for i in research_input:\n",
    "        response = client.responses.create(\n",
    "            model = \"gpt-5-nano\",\n",
    "            tools = [{\n",
    "                \"type\": \"web_search\"\n",
    "            }],\n",
    "            include = [\"web_search_call.action.sources\"],\n",
    "            input = f\"\"\"\n",
    "           You are a research analyst for Krux.\n",
    "\n",
    "          TASK:\n",
    "          Create a fact-checked research brief for ONE model announcement/enhancement.\n",
    "        \n",
    "          GOAL:\n",
    "          Explain what was announced, what changed, and why it matters in simple language for working teams.\n",
    "        \n",
    "          OUTPUT FORMAT:\n",
    "          - 8 to 10 bullet points max.\n",
    "          - Each bullet must end with inline citations:\n",
    "            [Source: <publisher>, <url>]\n",
    "          - No text before or after bullets.\n",
    "        \n",
    "          MANDATORY STRUCTURE:\n",
    "          1) WHAT IS NEW (first bullet, one sentence)\n",
    "             - Exact announcement today (new model/version/feature rollout).\n",
    "          2) WHAT CHANGED vs BEFORE\n",
    "             - New capabilities, limits, speed/cost/context/tool-use changes.\n",
    "             - If comparison is not explicitly available, write:\n",
    "               \"Not explicitly benchmarked in cited sources.\"\n",
    "          3) AVAILABILITY\n",
    "             - Who gets access (free/pro/enterprise/API), regions, rollout timeline.\n",
    "          4) PRACTICAL USE CASES\n",
    "             - 2 concrete workflows this enables, explained in plain language.\n",
    "          5) TEAM IMPACT (CONDITIONAL)\n",
    "             - Always include ONE unified \"team impact\" bullet relevant across roles.\n",
    "             - If the launch clearly impacts one role more (e.g., designers/developers/marketers/product managers),\n",
    "               add ONLY ONE extra role-specific bullet.\n",
    "             - Do NOT create separate bullets for every persona.\n",
    "          6) RISKS / LIMITS\n",
    "             - Known constraints, safety caveats, reliability limitations.\n",
    "          7) WHY THIS MATTERS NOW\n",
    "             - One factual bullet on relevance or impact.\n",
    "             - The impact on a specific industry, stock, sector etc\n",
    "        \n",
    "          STRICT RULES:\n",
    "          - Keep language simple and non-jargony.\n",
    "          - No hype, no opinions, no predictions.\n",
    "          - Every claim must be source-backed.\n",
    "          - Prefer primary/high-signal sources (official docs/releases + major outlets).\n",
    "          - If sources conflict, include both and label as conflicting.\n",
    "          - No repeated facts across bullets.\n",
    "        \n",
    "          QUALITY CHECK BEFORE FINALIZING:\n",
    "          - First bullet clearly states the new announcement.\n",
    "          - At least one impact bullet is practical and actionable for teams.\n",
    "          - All bullets contain citations.\n",
    "          - Output is concise and non-redundant.\n",
    "          \n",
    "          Event to research:\n",
    "              \n",
    "              Event: {i['output']}\n",
    "              \n",
    "              Sources: {i['sources']}\n",
    "            \"\"\",\n",
    "        )\n",
    "\n",
    "        output = response.output_text\n",
    "        print(output)\n",
    "\n",
    "        final_dictionary = {\n",
    "            'event_id': i['event_id'],\n",
    "            'news_date': i['news_date'],\n",
    "            'output': output,\n",
    "            'model_provider': 'openai',\n",
    "            'topic': i['topic']\n",
    "        }\n",
    "        print(final_dictionary)\n",
    "\n",
    "        save_research(final_dictionary)\n",
    "\n",
    "        print(\"✅ Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c277359-0292-4466-bdbf-b9f50363306d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event_id': '1300_2026-02-21',\n",
       "  'output': 'Anthropic launched Claude Code Security, a security-focused product built using its Opus 4.6 model family. The tool can autonomously review large codebases, surface and prioritize high-severity vulnerabilities, double-check its findings, and suggest fixes; it is being released as a limited research preview for Enterprise/Team customers and open-source maintainers, with safeguards and cautious rollout due to dual-use risks.',\n",
       "  'sources': [{'url': 'https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/',\n",
       "    'name': 'Fortune'},\n",
       "   {'url': 'https://www.pcmag.com/news/anthropic-rolls-out-autonomous-vulnerability-hunting-ai-tool-for-claude',\n",
       "    'name': 'PCMag'}],\n",
       "  'news_date': '2026-02-21',\n",
       "  'topic': 'Model announcements/enhancements'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funding_deep_dive[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c775408-a022-4518-a6bd-3da987759d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- WHAT IS NEW: On February 20, 2026, Anthropic announced Claude Code Security, a security-focused tool built on the Claude Opus 4.6 model family that autonomously reviews large codebases, surfaces and prioritizes high-severity vulnerabilities, double-checks its findings, and suggests fixes, released as a limited research preview for Enterprise/Team customers and expedited access for open-source maintainers. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\n",
      "\n",
      "- WHAT CHANGED vs BEFORE: It adds end-to-end autonomous codebase analysis, cross-component data-flow reasoning, automatic severity scoring, and suggested fixes (not auto-applied), extending beyond traditional pattern-based code scans. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\n",
      "\n",
      "- AVAILABILITY: The feature is available as a limited research preview for Enterprise/Team customers, with expedited access for open-source maintainers; broad public access or API details were not announced at launch. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\n",
      "\n",
      "- PRACTICAL USE CASES: Workflow A — security teams run Claude Code Security to systematically scan entire codebases and triage vulnerabilities for fixes; Workflow B — open-source maintainers get expedited access to surface issues in their projects for community review and remediation. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\n",
      "\n",
      "- TEAM IMPACT: Across teams, Claude Code Security acts as a force multiplier for security groups and provides developers with guided fixes and richer context, enabling faster, more comprehensive vulnerability coverage. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\n",
      "\n",
      "- RISKS / LIMITS: The rollout emphasizes dual-use risk; safeguards are in place to detect misuse, but the tool surfaces issues and suggests fixes rather than applying them automatically, requiring human review. [Source: Fortune, https://fortune.com/2026/02/06/anthropic-s newest-model-excels-at-finding-security-vulnerabilities—but-raises-fresh-cybersecurity-risks/; Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\n",
      "\n",
      "- WHY THIS MATTERS NOW: The combination of Opus 4.6’s improved ability to find high-severity, previously unknown vulnerabilities across large, real-world codebases addresses a growing open-source and enterprise security challenge, making automated vulnerability discovery more actionable for defenders. [Source: Fortune, https://fortune.com/2026/02/06/anthropic-s-newest-model-excels-at-finding-security-vulnerabilities—but-raises-fresh-cybersecurity-risks/; Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\n",
      "\n",
      "- MODEL DETAILS: Claude Opus 4.6 is the latest Opus-class model, with improvements in coding, agentic tasks, reliability, and a 1M token context window (beta), plus broader enterprise workflow support. [Source: Anthropic, Claude Opus 4.6, https://www.anthropic.com/claude/opus; https://www.anthropic.com/news/claude-opus-4-6]\n",
      "\n",
      "- AVAILABILITY & PLATFORM INTEGRATION: Opus 4.6 is available on Claude for Pro, Max, Team, and Enterprise users, and can be accessed via the Claude Developer Platform as well as major cloud platforms (Bedrock, Vertex AI, Foundry); pricing starts at $5 per million input tokens and $25 per million output tokens, with a 1M token context window (beta). [Source: Anthropic, Claude Opus 4.6, https://www.anthropic.com/claude/opus; https://www.anthropic.com/news/claude-opus-4-6]\n",
      "{'event_id': '1300_2026-02-21', 'news_date': '2026-02-21', 'output': '- WHAT IS NEW: On February 20, 2026, Anthropic announced Claude Code Security, a security-focused tool built on the Claude Opus 4.6 model family that autonomously reviews large codebases, surfaces and prioritizes high-severity vulnerabilities, double-checks its findings, and suggests fixes, released as a limited research preview for Enterprise/Team customers and expedited access for open-source maintainers. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\\n\\n- WHAT CHANGED vs BEFORE: It adds end-to-end autonomous codebase analysis, cross-component data-flow reasoning, automatic severity scoring, and suggested fixes (not auto-applied), extending beyond traditional pattern-based code scans. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\\n\\n- AVAILABILITY: The feature is available as a limited research preview for Enterprise/Team customers, with expedited access for open-source maintainers; broad public access or API details were not announced at launch. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\\n\\n- PRACTICAL USE CASES: Workflow A — security teams run Claude Code Security to systematically scan entire codebases and triage vulnerabilities for fixes; Workflow B — open-source maintainers get expedited access to surface issues in their projects for community review and remediation. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\\n\\n- TEAM IMPACT: Across teams, Claude Code Security acts as a force multiplier for security groups and provides developers with guided fixes and richer context, enabling faster, more comprehensive vulnerability coverage. [Source: Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\\n\\n- RISKS / LIMITS: The rollout emphasizes dual-use risk; safeguards are in place to detect misuse, but the tool surfaces issues and suggests fixes rather than applying them automatically, requiring human review. [Source: Fortune, https://fortune.com/2026/02/06/anthropic-s newest-model-excels-at-finding-security-vulnerabilities—but-raises-fresh-cybersecurity-risks/; Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\\n\\n- WHY THIS MATTERS NOW: The combination of Opus 4.6’s improved ability to find high-severity, previously unknown vulnerabilities across large, real-world codebases addresses a growing open-source and enterprise security challenge, making automated vulnerability discovery more actionable for defenders. [Source: Fortune, https://fortune.com/2026/02/06/anthropic-s-newest-model-excels-at-finding-security-vulnerabilities—but-raises-fresh-cybersecurity-risks/; Fortune, https://fortune.com/2026/02/20/exclusive-anthropic-rolls-out-ai-tool-that-can-hunt-software-bugs-on-its-own-including-the-most-dangerous-ones-humans-miss/]\\n\\n- MODEL DETAILS: Claude Opus 4.6 is the latest Opus-class model, with improvements in coding, agentic tasks, reliability, and a 1M token context window (beta), plus broader enterprise workflow support. [Source: Anthropic, Claude Opus 4.6, https://www.anthropic.com/claude/opus; https://www.anthropic.com/news/claude-opus-4-6]\\n\\n- AVAILABILITY & PLATFORM INTEGRATION: Opus 4.6 is available on Claude for Pro, Max, Team, and Enterprise users, and can be accessed via the Claude Developer Platform as well as major cloud platforms (Bedrock, Vertex AI, Foundry); pricing starts at $5 per million input tokens and $25 per million output tokens, with a 1M token context window (beta). [Source: Anthropic, Claude Opus 4.6, https://www.anthropic.com/claude/opus; https://www.anthropic.com/news/claude-opus-4-6]', 'model_provider': 'openai', 'topic': 'Model announcements/enhancements'}\n",
      "✅ Done\n",
      "- WHAT IS NEW: Google announces Lyria 3 integration in the Gemini app, enabling users to generate 30-second AI music tracks from text or image prompts, with lyrics and custom cover art, in beta as of February 18, 2026. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/] [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\n",
      "- WHAT CHANGED vs BEFORE: Lyria 3 adds auto-generated lyrics, more control over style, vocals, and tempo, and produces more realistic, complex tracks; outputs are 30 seconds long and include cover art, with SynthID watermarks for AI-origin identification. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/] [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\n",
      "- AVAILABILITY: Rolling out in beta to Gemini users 18+ worldwide, with support for eight languages; desktop access is live now and mobile support is coming in the next days; higher limits for Google AI Plus, Pro, and Ultra subscribers. [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\n",
      "- PRACTICAL USE CASES: 1) Create a 30-second track for a Shorts/video by describing mood/genre; 2) Pair a photo or video with a prompt to generate a lyrics-enabled track that can be downloaded or shared. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/]\n",
      "- TEAM IMPACT: Enables faster content prototyping and publishing for creators, marketers, and product teams; all tracks include SynthID for AI-content verification; YouTube Dream Track integration broadens creator workflows. [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/] [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/]\n",
      "- RISKS / LIMITS: The feature is in beta/experimental and may produce imperfect results; there are safeguards to avoid mimicking real artists, with content filters and usage terms applying. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/] [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\n",
      "- WHY THIS MATTERS NOW: Expands Gemini’s capabilities to support the creator economy and social video workflows, with global rollout and Dream Track integration meeting rising demand for AI-generated music in content creation. [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/] [Source: Gemini music overview, https://gemini.google/us/overview/music-generation/]\n",
      "- VERIFICATION / CONTENT ID: SynthID watermarking is embedded in Gemini-generated music, and Gemini can verify whether a track was AI-generated when uploaded for checking. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/] [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\n",
      "{'event_id': '1314_2026-02-21', 'news_date': '2026-02-21', 'output': '- WHAT IS NEW: Google announces Lyria 3 integration in the Gemini app, enabling users to generate 30-second AI music tracks from text or image prompts, with lyrics and custom cover art, in beta as of February 18, 2026. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/] [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\\n- WHAT CHANGED vs BEFORE: Lyria 3 adds auto-generated lyrics, more control over style, vocals, and tempo, and produces more realistic, complex tracks; outputs are 30 seconds long and include cover art, with SynthID watermarks for AI-origin identification. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/] [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\\n- AVAILABILITY: Rolling out in beta to Gemini users 18+ worldwide, with support for eight languages; desktop access is live now and mobile support is coming in the next days; higher limits for Google AI Plus, Pro, and Ultra subscribers. [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\\n- PRACTICAL USE CASES: 1) Create a 30-second track for a Shorts/video by describing mood/genre; 2) Pair a photo or video with a prompt to generate a lyrics-enabled track that can be downloaded or shared. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/]\\n- TEAM IMPACT: Enables faster content prototyping and publishing for creators, marketers, and product teams; all tracks include SynthID for AI-content verification; YouTube Dream Track integration broadens creator workflows. [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/] [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/]\\n- RISKS / LIMITS: The feature is in beta/experimental and may produce imperfect results; there are safeguards to avoid mimicking real artists, with content filters and usage terms applying. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/] [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]\\n- WHY THIS MATTERS NOW: Expands Gemini’s capabilities to support the creator economy and social video workflows, with global rollout and Dream Track integration meeting rising demand for AI-generated music in content creation. [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/] [Source: Gemini music overview, https://gemini.google/us/overview/music-generation/]\\n- VERIFICATION / CONTENT ID: SynthID watermarking is embedded in Gemini-generated music, and Gemini can verify whether a track was AI-generated when uploaded for checking. [Source: Google, https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/] [Source: TechCrunch, https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/]', 'model_provider': 'openai', 'topic': 'Model announcements/enhancements'}\n",
      "✅ Done\n",
      "- WHAT IS NEW: On February 18, 2026, Sarvam AI announced two indigenous large language models—Sarvam-30B and Sarvam-105B—trained for all 22 Indian languages, along with Vikram, an offline multilingual AI assistant showcased at the India AI Impact Summit in New Delhi. [Source: TechCrunch, https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/] ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/?utm_source=openai))\n",
      "- WHAT CHANGED vs BEFORE: The lineup uses a mixture-of-experts design with 30B (32,000-token context) and 105B (128,000-token context), aiming for real-time, costly-efficient reasoning and competitive performance against frontier models. [Source: Business Standard, https://www.business-standard.com/technology/tech-news/ai-startup-sarvam-launches-two-made-in-india-large-language-models-126021801397_1.html] ([business-standard.com](https://www.business-standard.com/technology/tech-news/ai-startup-sarvam-launches-two-made-in-india-large-language-models-126021801397_1.html))\n",
      "- WHAT CHANGED vs BEFORE: The models are positioned for edge/offline use and real-time, voice-first interactions in multiple languages, with demonstrations around local-language conversational capabilities. [Source: TechCrunch, https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/] ([techcrunch.com](https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/))\n",
      "- AVAILABILITY: Access details emphasize sovereign, IndiaAI Mission–aligned deployment with infrastructure from Nvidia and Yotta; explicit public API/tiers were not fully disclosed in cited sources. [Source: ISTI Portal, https://www.indiascienceandtechnology.gov.in/stihighlights/sarvam-ai-unveils-indigenous-multilingual-foundation-models-india-ai-impact-summit] ([indiascienceandtechnology.gov.in](https://www.indiascienceandtechnology.gov.in/stihighlights/sarvam-ai-unveils-indigenous-multilingual-foundation-models-india-ai-impact-summit?utm_source=openai))\n",
      "- AVAILABILITY: Government-aligned coverage and open-source/sovereign AI positioning are highlighted, with a broader push toward domestic AI infrastructure and governance. [Source: Times of India, https://timesofindia.indiatimes.com/technology/artificial-intelligence/government-selects-indian-ai-company-sarvam-to-develop-nations-first-sovereign-large-language-model/articleshow/120645896.cms] ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/artificial-intelligence/government-selects-indian-ai-company-sarvam-to-develop-nations-first-sovereign-large-language-model/amp_articleshow/120645896.cms?utm_source=openai))\n",
      "- PRACTICAL USE CASES: Vikram enables multilingual, offline conversations on devices like feature phones for government-schemes guidance and local-market help; other workflows target edge devices (cars, wearables) for real-time assistance. [Source: TechCrunch, https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/] ([techcrunch.com](https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/))\n",
      "- PRACTICAL USE CASES: Demonstrations include Vikram conversing in Hindi/Punjabi and planning consumer-device deployments; partnerships hint at car AI and consumer wearables as rollout pathways. [Source: Business Standard, https://www.business-standard.com/technology/tech-news/ai-startup-sarvam-launches-two-made-in-india-large-language-models-126021801397_1.html] ([business-standard.com](https://www.business-standard.com/technology/tech-news/ai-startup-sarvam-launches-two-made-in-india-large-language-models-126021801397_1.html))\n",
      "- TEAM IMPACT (CONDITIONAL): Teams should plan for on-device/offline inference, multilingual data governance, and close collaboration with hardware partners (Nvidia, Yotta) to enable sovereign, edge-first AI solutions. [Source: ISTI Portal, https://www.indiascienceandtechnology.gov.in/stihighlights/sarvam-ai-unveils-indigenous-multilingual-foundation-models-india-ai-impact-summit] ([indiascienceandtechnology.gov.in](https://www.indiascienceandtechnology.gov.in/stihighlights/sarvam-ai-unveils-indigenous-multilingual-foundation-models-india-ai-impact-summit?utm_source=openai))\n",
      "- RISKS / LIMITS: Some features may not be fully functional offline in all contexts; real-world performance across 22 languages and large context windows requires further validation; deployment depends on sovereign infrastructure. [Source: TechCrunch, https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/] ([techcrunch.com](https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/))\n",
      "- WHY THIS MATTERS NOW: This aligns with India’s sovereign AI push under the IndiaAI Mission, signaling government-supported development of homegrown, language-enabled AI that could affect governance, enterprise AI adoption, and domestic technology leadership. [Source: Times of India, https://timesofindia.indiatimes.com/technology/artificial-intelligence/government-selects-indian-ai-company-sarvam-to-develop-nations-first-sovereign-large-language-model/articleshow/120645896.cms] ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/artificial-intelligence/government-selects-indian-ai-company-sarvam-to-develop-nations-first-sovereign-large-language-model/amp_articleshow/120645896.cms?utm_source=openai))\n",
      "{'event_id': '1316_2026-02-21', 'news_date': '2026-02-21', 'output': '- WHAT IS NEW: On February 18, 2026, Sarvam AI announced two indigenous large language models—Sarvam-30B and Sarvam-105B—trained for all 22 Indian languages, along with Vikram, an offline multilingual AI assistant showcased at the India AI Impact Summit in New Delhi. [Source: TechCrunch, https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/] ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/?utm_source=openai))\\n- WHAT CHANGED vs BEFORE: The lineup uses a mixture-of-experts design with 30B (32,000-token context) and 105B (128,000-token context), aiming for real-time, costly-efficient reasoning and competitive performance against frontier models. [Source: Business Standard, https://www.business-standard.com/technology/tech-news/ai-startup-sarvam-launches-two-made-in-india-large-language-models-126021801397_1.html] ([business-standard.com](https://www.business-standard.com/technology/tech-news/ai-startup-sarvam-launches-two-made-in-india-large-language-models-126021801397_1.html))\\n- WHAT CHANGED vs BEFORE: The models are positioned for edge/offline use and real-time, voice-first interactions in multiple languages, with demonstrations around local-language conversational capabilities. [Source: TechCrunch, https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/] ([techcrunch.com](https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/))\\n- AVAILABILITY: Access details emphasize sovereign, IndiaAI Mission–aligned deployment with infrastructure from Nvidia and Yotta; explicit public API/tiers were not fully disclosed in cited sources. [Source: ISTI Portal, https://www.indiascienceandtechnology.gov.in/stihighlights/sarvam-ai-unveils-indigenous-multilingual-foundation-models-india-ai-impact-summit] ([indiascienceandtechnology.gov.in](https://www.indiascienceandtechnology.gov.in/stihighlights/sarvam-ai-unveils-indigenous-multilingual-foundation-models-india-ai-impact-summit?utm_source=openai))\\n- AVAILABILITY: Government-aligned coverage and open-source/sovereign AI positioning are highlighted, with a broader push toward domestic AI infrastructure and governance. [Source: Times of India, https://timesofindia.indiatimes.com/technology/artificial-intelligence/government-selects-indian-ai-company-sarvam-to-develop-nations-first-sovereign-large-language-model/articleshow/120645896.cms] ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/artificial-intelligence/government-selects-indian-ai-company-sarvam-to-develop-nations-first-sovereign-large-language-model/amp_articleshow/120645896.cms?utm_source=openai))\\n- PRACTICAL USE CASES: Vikram enables multilingual, offline conversations on devices like feature phones for government-schemes guidance and local-market help; other workflows target edge devices (cars, wearables) for real-time assistance. [Source: TechCrunch, https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/] ([techcrunch.com](https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/))\\n- PRACTICAL USE CASES: Demonstrations include Vikram conversing in Hindi/Punjabi and planning consumer-device deployments; partnerships hint at car AI and consumer wearables as rollout pathways. [Source: Business Standard, https://www.business-standard.com/technology/tech-news/ai-startup-sarvam-launches-two-made-in-india-large-language-models-126021801397_1.html] ([business-standard.com](https://www.business-standard.com/technology/tech-news/ai-startup-sarvam-launches-two-made-in-india-large-language-models-126021801397_1.html))\\n- TEAM IMPACT (CONDITIONAL): Teams should plan for on-device/offline inference, multilingual data governance, and close collaboration with hardware partners (Nvidia, Yotta) to enable sovereign, edge-first AI solutions. [Source: ISTI Portal, https://www.indiascienceandtechnology.gov.in/stihighlights/sarvam-ai-unveils-indigenous-multilingual-foundation-models-india-ai-impact-summit] ([indiascienceandtechnology.gov.in](https://www.indiascienceandtechnology.gov.in/stihighlights/sarvam-ai-unveils-indigenous-multilingual-foundation-models-india-ai-impact-summit?utm_source=openai))\\n- RISKS / LIMITS: Some features may not be fully functional offline in all contexts; real-world performance across 22 languages and large context windows requires further validation; deployment depends on sovereign infrastructure. [Source: TechCrunch, https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/] ([techcrunch.com](https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/))\\n- WHY THIS MATTERS NOW: This aligns with India’s sovereign AI push under the IndiaAI Mission, signaling government-supported development of homegrown, language-enabled AI that could affect governance, enterprise AI adoption, and domestic technology leadership. [Source: Times of India, https://timesofindia.indiatimes.com/technology/artificial-intelligence/government-selects-indian-ai-company-sarvam-to-develop-nations-first-sovereign-large-language-model/articleshow/120645896.cms] ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/artificial-intelligence/government-selects-indian-ai-company-sarvam-to-develop-nations-first-sovereign-large-language-model/amp_articleshow/120645896.cms?utm_source=openai))', 'model_provider': 'openai', 'topic': 'Model announcements/enhancements'}\n",
      "✅ Done\n"
     ]
    }
   ],
   "source": [
    "openai_research_model(funding_deep_dive[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe168d4-6eda-449c-a831-2b65d0988a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_research(research_json):\n",
    "    supabase.table('research_assistant').insert({\n",
    "        'event_id': research_json['event_id'],\n",
    "        'model_provider': research_json['model_provider'],\n",
    "        'news_date': research_json['news_date'],\n",
    "        'output': research_json['output'],\n",
    "        'topic': research_json['topic']\n",
    "    }).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9285db5-df3a-40a0-a68c-d6e83d0f0a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
