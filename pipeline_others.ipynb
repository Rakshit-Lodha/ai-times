{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "580fe7c3-718e-4e30-80f9-cb861d6f26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ec6a7d1-2e50-4080-862c-0ac4976e37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8870db91-2713-4c98-80b8-ef13c4f3ecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b1725cdb-dbf2-4037-ab85-347c86377117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5ab2c5eb-d6bc-4f9e-acf3-dfa88e17aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c47f9c35-f187-4cb5-bfc1-20722c41da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4e20de75-7336-4988-8d77-bdfa9ea14a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8bcb6ee1-db48-49e9-8905-937b32054975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed133139-66a6-4fef-9410-3d28c739631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase_url = os.environ.get(\"SUPABASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eedf2050-1171-4f20-95b6-f886ce8e53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase_api_key = os.environ.get(\"SUPBASE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "df1ea318-9846-473d-9be3-d4edc45f0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase: Client = create_client(supabase_url, supabase_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c2c58d8d-9587-4518-9d4c-d5a0f93c23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_research(date):\n",
    "    result = supabase.table('curation_selected_items')\\\n",
    "        .select('event_id, output,sources, news_date','topic')\\\n",
    "    .eq('news_date', date)\\\n",
    "    .eq('topic', 'Others')\\\n",
    "        .order('created_at', desc=False)\\\n",
    "        .execute()\n",
    "    \n",
    "    return result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ad4190cd-d4d9-43b4-98ca-91974f74b67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event_id': '1325_2026-02-21',\n",
       "  'output': \"Multiple technology news outlets (Futurism, Geo.tv and others) reported that at least two AWS service disruptions in December 2025 were linked in reporting to Amazon's internal AI coding assistant (Kiro), claiming the assistant made code/environment changes that contributed to outages (one report describes a 13-hour disruption when an environment was deleted and recreated). These articles were published or aggregated on Feb 21, 2026.\",\n",
       "  'sources': [{'url': 'https://futurism.com/artificial-intelligence/amazon-ai-aws-outages',\n",
       "    'name': 'Futurism'},\n",
       "   {'url': 'https://www.rswebsols.com/news/aws-outages-attributed-to-mistakes-by-ai-coding-bot-report-indicates-amazon-clarifies-both-cases-were-due-to-user-error/',\n",
       "    'name': 'RSWebsols'}],\n",
       "  'news_date': '2026-02-21',\n",
       "  'topic': 'Others'}]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others_deep_dive = model_research('2026-02-21')\n",
    "\n",
    "others_deep_dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "33f21b2a-eb16-450c-841a-c25209b5401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_research_v2(research_input):\n",
    "    for i in research_input:\n",
    "        response = client.responses.create(\n",
    "            model = \"gpt-5-nano\",\n",
    "            tools = [{\n",
    "                \"type\": \"web_search\"\n",
    "            }],\n",
    "            include = [\"web_search_call.action.sources\"],\n",
    "            input = f\"\"\"You are an AI research analyst for Krux.\n",
    "            Your job is to create a fact-checked research brief for a given AI news event.\n",
    "            \n",
    "            APPROACH:\n",
    "            1. Start with WHAT IS NEW — the specific event, announcement, or development.\n",
    "            2. Add ONLY the context needed to understand why this matters.\n",
    "            3. For funding/M&A: focus on the new round, amount, investors, and valuation. \n",
    "               Do NOT include historical funding rounds or prior valuations.\n",
    "            4. For product/launch news: include key technical details, who built it, \n",
    "               and what problem it solves.\n",
    "            5. Maximum 8-10 bullet points. If you need more, you're being redundant.\n",
    "            \n",
    "            CRITICAL RULES:\n",
    "            - Every fact must be traceable to a credible published source.\n",
    "            - No point should repeat information from another point.\n",
    "            - No opinions, predictions, or analysis.\n",
    "            - No fluff — get straight to the facts.\n",
    "            - First bullet must always state the core new development.\n",
    "            \n",
    "            OUTPUT: Bullet points with inline source citations. Nothing else.\n",
    "\n",
    "            Here is what you need to research on:\n",
    "\n",
    "            Event: {i['output']}\n",
    "            Sources: {i['sources']}\n",
    "            \"\"\",\n",
    "        )\n",
    "\n",
    "        output = response.output_text\n",
    "        print(output)\n",
    "\n",
    "        final_dictionary = {\n",
    "            'event_id': f\"{i['event_id']}\",\n",
    "            'news_date': i['news_date'],\n",
    "            'output': output,\n",
    "            'model_provider': 'openai'\n",
    "        }\n",
    "\n",
    "        save_research(i)\n",
    "        print(final_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b2c7cc3b-221c-4f61-8261-df1fe6bee0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_research(research_json):\n",
    "    supabase.table('research_assistant').insert({\n",
    "        'event_id': research_json['event_id'],\n",
    "        'model_provider': research_json['model_provider'],\n",
    "        'news_date': research_json['news_date'],\n",
    "        'output': research_json['output'],\n",
    "        'topic': research_json['topic']\n",
    "    }).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ea863b7-fdab-4554-b027-6061fe8a3b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- WHAT IS NEW: February 21, 2026 reporting indicates that December 2025 AWS outages were linked to Amazon’s internal AI coding assistant Kiro, including a roughly 13-hour disruption when Kiro autonomously deleted and recreated the environment it was working on. ([theverge.com](https://www.theverge.com/ai-artificial-intelligence/882005/amazon-blames-human-employees-for-an-ai-coding-agents-mistake))\n",
      "\n",
      "- CONTEXT: The December incident affected a single AWS service (Cost Explorer) in parts of Mainland China and AWS characterized the event as “extremely limited,” with no broad impact on compute, storage, or AI services across regions. ([aboutamazon.com](https://www.aboutamazon.com/news/aws/aws-service-outage-ai-bot-kiro/))\n",
      "\n",
      "- SECOND INCIDENT: A second outage reportedly did not impact a customer-facing AWS service, according to coverage surrounding the events. ([theguardian.com](https://www.theguardian.com/technology/2026/feb/20/amazon-cloud-outages-ai-tools-amazon-web-services-aws))\n",
      "\n",
      "- WHAT KIRO IS: Kiro is an agentic AI coding tool launched by AWS, designed to turn prompts into detailed specs, then into working code, documents, and tests; it was described as requiring two human approvals for production changes, and it “requests authorization before taking action” by default. ([crn.com](https://www.crn.com/news/cloud/2026/aws-outage-was-not-ai-caused-via-kiro-coding-tool-amazon-confirms))\n",
      "\n",
      "- HOW KIRO WORKS/WHAT WENT WRONG: Reports say Kiro was granted the operator’s permissions and, due to a misconfiguration, bypassed safeguards, leading to a “delete and recreate” action on the environment. ([theverge.com](https://www.theverge.com/ai-artificial-intelligence/882005/amazon-blames-human-employees-for-an-ai-coding-agents-mistake))\n",
      "\n",
      "- AMAZON’S ASSERTION: Amazon has insisted the December outages were due to user error (misconfigured access controls) and not AI failure, framing AI-tool involvement as coincidental. ([aboutamazon.com](https://www.aboutamazon.com/news/aws/aws-service-outage-ai-bot-kiro/))\n",
      "\n",
      "- SAFEGUARDS POST-INCIDENT: AWS has implemented additional safeguards, including mandatory peer review for production access, after the December event. ([crn.com](https://www.crn.com/news/cloud/2026/aws-outage-was-not-ai-caused-via-kiro-coding-tool-amazon-confirms))\n",
      "\n",
      "- IMPACT AND NARRATIVE: The company characterized the outages as small-scale and not indicative of broader AI risk, even as coverage framed it as a test case for AI-in-DevOps risk and governance. ([theguardian.com](https://www.theguardian.com/technology/2026/feb/20/amazon-cloud-outages-ai-tools-amazon-web-services-aws))\n",
      "\n",
      "- ADDITIONAL COVERAGE TIMELINE/OUTLETS: Coverage of the events and the Salesforce-like claim that AI tools were involved appeared in outlets around Feb 20–21, 2026, with RSWebsols publishing a Feb 21, 2026 update that summarizes the FT reporting and Amazon’s response. ([theguardian.com](https://www.theguardian.com/technology/2026/feb/20/amazon-cloud-outages-ai-tools-amazon-web-services-aws))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model_provider'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m openai_research_v2(others_deep_dive)\n",
      "Cell \u001b[0;32mIn[131], line 47\u001b[0m, in \u001b[0;36mopenai_research_v2\u001b[0;34m(research_input)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     40\u001b[0m final_dictionary \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_date\u001b[39m\u001b[38;5;124m'\u001b[39m: i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_date\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m: output,\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_provider\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     45\u001b[0m }\n\u001b[0;32m---> 47\u001b[0m save_research(i)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_dictionary)\n",
      "Cell \u001b[0;32mIn[132], line 4\u001b[0m, in \u001b[0;36msave_research\u001b[0;34m(research_json)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave_research\u001b[39m(research_json):\n\u001b[1;32m      2\u001b[0m     supabase\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresearch_assistant\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39minsert({\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m'\u001b[39m: research_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_provider\u001b[39m\u001b[38;5;124m'\u001b[39m: research_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_provider\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_date\u001b[39m\u001b[38;5;124m'\u001b[39m: research_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_date\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m: research_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m: research_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m     })\u001b[38;5;241m.\u001b[39mexecute()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_provider'"
     ]
    }
   ],
   "source": [
    "openai_research_v2(others_deep_dive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de73c0f-fedb-4294-b267-0d706e245665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a239b4b-9a25-4d49-a23c-86fb43508a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "449ea200-928e-4cb8-a586-b0a144eadcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "751a756b-a9f8-4082-869c-713db231a6a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Core development: Nvidia is close to finalizing roughly a $30 billion equity investment in OpenAI, replacing the previously announced up-to-$100 billion multi-year data-center compute pact. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\n",
      "\n",
      "- Financing scope: OpenAI is seeking more than $100 billion in the current funding round, with the round valuing OpenAI at about $830 billion. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\n",
      "\n",
      "- Likely investors: SoftBank and Amazon are also expected to participate in the round. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\n",
      "\n",
      "- Investment structure: The deal would be a direct equity stake in OpenAI, not a commitment for OpenAI to buy Nvidia hardware under a compute arrangement. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\n",
      "\n",
      "- Use of proceeds: OpenAI plans to reinvest much of the new capital into Nvidia hardware and to purchase Nvidia chips. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\n",
      "\n",
      "- Replacement of prior pact: This arrangement would replace the September announcement of a up-to-$100 billion multi-year commitment to support OpenAI’s use of Nvidia chips in data centers. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\n",
      "\n",
      "- Company response: Nvidia declined to comment on the Reuters report. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\n",
      "\n",
      "- Timing and status: The Reuters report notes the deal is not final and could close soon, with coverage dated February 19–20, 2026. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\n",
      "{'event_id': '1274_2026-02-20', 'news_date': '2026-02-20', 'output': '- Core development: Nvidia is close to finalizing roughly a $30 billion equity investment in OpenAI, replacing the previously announced up-to-$100 billion multi-year data-center compute pact. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Financing scope: OpenAI is seeking more than $100 billion in the current funding round, with the round valuing OpenAI at about $830 billion. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Likely investors: SoftBank and Amazon are also expected to participate in the round. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Investment structure: The deal would be a direct equity stake in OpenAI, not a commitment for OpenAI to buy Nvidia hardware under a compute arrangement. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Use of proceeds: OpenAI plans to reinvest much of the new capital into Nvidia hardware and to purchase Nvidia chips. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Replacement of prior pact: This arrangement would replace the September announcement of a up-to-$100 billion multi-year commitment to support OpenAI’s use of Nvidia chips in data centers. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Company response: Nvidia declined to comment on the Reuters report. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Timing and status: The Reuters report notes the deal is not final and could close soon, with coverage dated February 19–20, 2026. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))', 'model_provider': 'openai'}\n",
      "- Core development: OpenAI and Tata Group announce a multi-dimensional strategic partnership to speed AI-driven transformation across Tata Group, other Indian and global enterprises, and to build AI infrastructure in India (Enterprise ChatGPT for Tata, agentic AI, and HyperVault data-center initiatives). ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\n",
      "\n",
      "- OpenAI for India launch: OpenAI launches OpenAI for India to expand sovereign AI capabilities, accelerate enterprise adoption, and upskill the workforce, with India hosting OpenAI-led initiatives alongside Tata Group. ([openai.com](https://openai.com/openai-for-india))\n",
      "\n",
      "- Sovereign AI infrastructure: As part of Stargate, OpenAI and Tata will develop local AI-ready data-center capacity designed for data residency and security, with OpenAI becoming the first customer of Tata Consultancy Services’ HyperVault. 100 MW initial capacity, potential to scale to 1 GW. ([openai.com](https://openai.com/openai-for-india))\n",
      "\n",
      "- 100 MW buildout and scale plan: In the initial phase, Tata Group’s HyperVault unit will develop AI infrastructure with 100 MW capacity, with an option to scale to 1 GW to support next-generation AI workloads. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\n",
      "\n",
      "- Enterprise ChatGPT deployment: Tata Group plans to deploy ChatGPT Enterprise across its employees over the coming years, starting with hundreds of thousands of TCS employees. ([openai.com](https://openai.com/openai-for-india))\n",
      "\n",
      "- Codex integration for software: TCS will leverage OpenAI’s Codex to standardize AI-native software development across teams. ([openai.com](https://openai.com/openai-for-india))\n",
      "\n",
      "- Agentic AI focus: The partnership will develop industry-specific agentic AI solutions by combining OpenAI’s agentic AI capabilities with TCS domain knowledge. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\n",
      "\n",
      "- Joint GTM and deployment: TCS and OpenAI will jointly enable Indian and global enterprises to deploy, integrate, and scale OpenAI platforms, driving AI-led transformation at scale. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\n",
      "\n",
      "- Upskilling and certifications: OpenAI Certifications will expand in India with TCS as the first participating organization outside the United States; more than 100,000 ChatGPT Edu licenses will be provided to help workforce skills. ([openai.com](https://openai.com/openai-for-india))\n",
      "\n",
      "- Social impact commitments: OpenAI Foundation and TCS will collaborate to provide AI training/resources to Indian youth and develop NGO toolkits, aiming to improve livelihoods for at least one million Indian youth. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\n",
      "\n",
      "- OpenAI presence in India: OpenAI plans to open new offices in Mumbai and Bengaluru later in 2026 to support local users and partners. ([openai.com](https://openai.com/openai-for-india))\n",
      "{'event_id': '1275_2026-02-20', 'news_date': '2026-02-20', 'output': '- Core development: OpenAI and Tata Group announce a multi-dimensional strategic partnership to speed AI-driven transformation across Tata Group, other Indian and global enterprises, and to build AI infrastructure in India (Enterprise ChatGPT for Tata, agentic AI, and HyperVault data-center initiatives). ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- OpenAI for India launch: OpenAI launches OpenAI for India to expand sovereign AI capabilities, accelerate enterprise adoption, and upskill the workforce, with India hosting OpenAI-led initiatives alongside Tata Group. ([openai.com](https://openai.com/openai-for-india))\\n\\n- Sovereign AI infrastructure: As part of Stargate, OpenAI and Tata will develop local AI-ready data-center capacity designed for data residency and security, with OpenAI becoming the first customer of Tata Consultancy Services’ HyperVault. 100 MW initial capacity, potential to scale to 1 GW. ([openai.com](https://openai.com/openai-for-india))\\n\\n- 100 MW buildout and scale plan: In the initial phase, Tata Group’s HyperVault unit will develop AI infrastructure with 100 MW capacity, with an option to scale to 1 GW to support next-generation AI workloads. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- Enterprise ChatGPT deployment: Tata Group plans to deploy ChatGPT Enterprise across its employees over the coming years, starting with hundreds of thousands of TCS employees. ([openai.com](https://openai.com/openai-for-india))\\n\\n- Codex integration for software: TCS will leverage OpenAI’s Codex to standardize AI-native software development across teams. ([openai.com](https://openai.com/openai-for-india))\\n\\n- Agentic AI focus: The partnership will develop industry-specific agentic AI solutions by combining OpenAI’s agentic AI capabilities with TCS domain knowledge. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- Joint GTM and deployment: TCS and OpenAI will jointly enable Indian and global enterprises to deploy, integrate, and scale OpenAI platforms, driving AI-led transformation at scale. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- Upskilling and certifications: OpenAI Certifications will expand in India with TCS as the first participating organization outside the United States; more than 100,000 ChatGPT Edu licenses will be provided to help workforce skills. ([openai.com](https://openai.com/openai-for-india))\\n\\n- Social impact commitments: OpenAI Foundation and TCS will collaborate to provide AI training/resources to Indian youth and develop NGO toolkits, aiming to improve livelihoods for at least one million Indian youth. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- OpenAI presence in India: OpenAI plans to open new offices in Mumbai and Bengaluru later in 2026 to support local users and partners. ([openai.com](https://openai.com/openai-for-india))', 'model_provider': 'openai'}\n",
      "- General Catalyst commits $5 billion to invest in India over the next five years, announced at the India AI Impact Summit 2026 in New Delhi on February 19, 2026. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\n",
      "- This $5 billion pledge represents a fivefold increase from GC’s prior India earmark of about $500 million to $1 billion. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\n",
      "- The investment will target sectors including artificial intelligence, healthcare, defense technology, fintech, and consumer technology. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\n",
      "- The announcement comes less than two years after General Catalyst merged with local firm Venture Highway. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\n",
      "- Neeraj Arora serves as GC’s CEO for India, the Middle East & North Africa to lead the expanded push. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\n",
      "- GC is pursuing a platform-led model that combines traditional investing with a “creation” strategy, including roll-ups of companies in India. ([m.economictimes.com](https://m.economictimes.com/tech/technology/general-catalysts-hemant-taneja-on-5-billion-india-bet-and-its-shift-beyond-venture-capital-to-company-creation-in-the-ai-age/articleshow/128589856.cms))\n",
      "- GC views India’s biggest AI opportunity as large-scale real-world deployment rather than frontier-model development. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\n",
      "- GC’s India portfolio already includes Zepto, PB Health, Raphe, Jeh Aerospace, Pronto and Ayr Energy, with additional investments in Spinny, Farmart, and Loop Health noted in coverage. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\n",
      "- The commitment coincides with broad activity at the India AI Impact Summit, which has attracted participation from global players and AI initiatives (e.g., OpenAI, Anthropic, Google among others). ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\n",
      "{'event_id': '1276_2026-02-20', 'news_date': '2026-02-20', 'output': '- General Catalyst commits $5 billion to invest in India over the next five years, announced at the India AI Impact Summit 2026 in New Delhi on February 19, 2026. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- This $5 billion pledge represents a fivefold increase from GC’s prior India earmark of about $500 million to $1 billion. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- The investment will target sectors including artificial intelligence, healthcare, defense technology, fintech, and consumer technology. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- The announcement comes less than two years after General Catalyst merged with local firm Venture Highway. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- Neeraj Arora serves as GC’s CEO for India, the Middle East & North Africa to lead the expanded push. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- GC is pursuing a platform-led model that combines traditional investing with a “creation” strategy, including roll-ups of companies in India. ([m.economictimes.com](https://m.economictimes.com/tech/technology/general-catalysts-hemant-taneja-on-5-billion-india-bet-and-its-shift-beyond-venture-capital-to-company-creation-in-the-ai-age/articleshow/128589856.cms))\\n- GC views India’s biggest AI opportunity as large-scale real-world deployment rather than frontier-model development. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- GC’s India portfolio already includes Zepto, PB Health, Raphe, Jeh Aerospace, Pronto and Ayr Energy, with additional investments in Spinny, Farmart, and Loop Health noted in coverage. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- The commitment coincides with broad activity at the India AI Impact Summit, which has attracted participation from global players and AI initiatives (e.g., OpenAI, Anthropic, Google among others). ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))', 'model_provider': 'openai'}\n",
      "- WHAT IS NEW: Abu Dhabi’s G42 and MBZUAI, partnered with Cerebras and India’s C-DAC, announced an 8-exaflop national AI supercomputer to be deployed in India, announced on the sidelines of the India AI Impact Summit 2026. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\n",
      "\n",
      "- HOSTING AND GOVERNANCE: The system will be hosted in India and operate under India-defined governance with data remaining within national jurisdiction, as part of strengthening sovereign AI infrastructure under the India AI Mission. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\n",
      "\n",
      "- COMPUTE CAPACITY: The announced system is designed to deliver 8 exaflops of compute capacity, marking a step to exaflop-scale AI infrastructure in India. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\n",
      "\n",
      "- PARTNER ROLES: Delivery will be by G42 and Cerebras, with MBZUAI and India’s C-DAC as collaborating partners. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\n",
      "\n",
      "- ANNOUNCEMENT CONTEXT: The project was unveiled at the India AI Impact Summit 2026 in New Delhi. ([thenationalnews.com](https://www.thenationalnews.com/future/technology/2026/02/20/abu-dhabis-g42-and-mbzuai-join-us-firm-cerebras-to-build-india-ai-supercomputer/))\n",
      "\n",
      "- ACCESS AND USERS: Once operational, the supercomputer will be accessible to universities, startups, SMEs, and government ministries, aiming for broad public/private sector AI enablement. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\n",
      "\n",
      "- PURPOSE AND IMPACT: The initiative targets accelerating both training and inference for large-scale AI models tailored to Indian needs. ([techcrunch.com](https://techcrunch.com/2026/02/20/uaes-g42-teams-up-with-cerebras-to-deploy-8-exaflops-of-compute-in-india/))\n",
      "\n",
      "- RELEVANT PREVIOUS COLLABORATION: MBZUAI and G42 previously released the Hindi-English language model NANDA 87B (Dec 2025), highlighting prior collaboration between the parties. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\n",
      "\n",
      "- GEOPOLITICAL CONTEXT: The project follows broader India–UAE strategic alignment, including the December 2025 India–UAE Strategic Dialogue and the January 2026 visit of UAE leadership to India. ([thenationalnews.com](https://www.thenationalnews.com/future/technology/2026/02/20/abu-dhabis-g42-and-mbzuai-join-us-firm-cerebras-to-build-india-ai-supercomputer/))\n",
      "\n",
      "\n",
      "{'event_id': '1277_2026-02-20', 'news_date': '2026-02-20', 'output': '- WHAT IS NEW: Abu Dhabi’s G42 and MBZUAI, partnered with Cerebras and India’s C-DAC, announced an 8-exaflop national AI supercomputer to be deployed in India, announced on the sidelines of the India AI Impact Summit 2026. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- HOSTING AND GOVERNANCE: The system will be hosted in India and operate under India-defined governance with data remaining within national jurisdiction, as part of strengthening sovereign AI infrastructure under the India AI Mission. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- COMPUTE CAPACITY: The announced system is designed to deliver 8 exaflops of compute capacity, marking a step to exaflop-scale AI infrastructure in India. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- PARTNER ROLES: Delivery will be by G42 and Cerebras, with MBZUAI and India’s C-DAC as collaborating partners. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- ANNOUNCEMENT CONTEXT: The project was unveiled at the India AI Impact Summit 2026 in New Delhi. ([thenationalnews.com](https://www.thenationalnews.com/future/technology/2026/02/20/abu-dhabis-g42-and-mbzuai-join-us-firm-cerebras-to-build-india-ai-supercomputer/))\\n\\n- ACCESS AND USERS: Once operational, the supercomputer will be accessible to universities, startups, SMEs, and government ministries, aiming for broad public/private sector AI enablement. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- PURPOSE AND IMPACT: The initiative targets accelerating both training and inference for large-scale AI models tailored to Indian needs. ([techcrunch.com](https://techcrunch.com/2026/02/20/uaes-g42-teams-up-with-cerebras-to-deploy-8-exaflops-of-compute-in-india/))\\n\\n- RELEVANT PREVIOUS COLLABORATION: MBZUAI and G42 previously released the Hindi-English language model NANDA 87B (Dec 2025), highlighting prior collaboration between the parties. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- GEOPOLITICAL CONTEXT: The project follows broader India–UAE strategic alignment, including the December 2025 India–UAE Strategic Dialogue and the January 2026 visit of UAE leadership to India. ([thenationalnews.com](https://www.thenationalnews.com/future/technology/2026/02/20/abu-dhabis-g42-and-mbzuai-join-us-firm-cerebras-to-build-india-ai-supercomputer/))\\n\\n', 'model_provider': 'openai'}\n",
      "- Core development: Sarvam AI unveiled two indigenous LLMs, Sarvam-30B and Sarvam-105B, announced at the India AI Impact Summit 2026 in New Delhi, aimed at real-time use and advanced reasoning; MoE architecture with large context windows; open-sourcing planned. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\n",
      "\n",
      "- Model architecture: Both models use a mixture-of-experts design that activates only a fraction of parameters at inference to improve efficiency. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\n",
      "\n",
      "- Real-time capabilities: 30B targets production-ready, real-time conversational use with a 32,000-token context window; 105B targets more complex, multi-step reasoning with a 128,000-token window. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\n",
      "\n",
      "- Training from scratch: 30B was pre-trained from scratch on about 16 trillion tokens; 105B trained on trillions of tokens across multiple Indian languages. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\n",
      "\n",
      "- IndiaAI Mission and compute: Training leveraged India’s government-backed IndiaAI Mission compute, with infrastructure support from Yotta and technical support from Nvidia. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\n",
      "\n",
      "- Open-source plan: Sarvam stated it intends to open-source the 30B and 105B models, though it did not specify whether training data or full training code would be disclosed. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\n",
      "\n",
      "- Enterprise and ecosystem: The launch outlined an expanded enterprise stack, including Sarvam for Work and a conversational agent platform called Samvaad, plus a vision model for document understanding. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\n",
      "\n",
      "- Indus consumer app: Two days after the model announcements, Sarvam released Indus, a consumer AI chat app powered by the 105B model, available in beta on iOS, Android, and the web; initial rollout limited to India with a waitlist. ([techcrunch.com](https://techcrunch.com/2026/02/20/indias-sarvam-launches-indus-ai-chat-app-as-competition-heats-up/?utm_source=openai))\n",
      "\n",
      "- Benchmark and language focus: The 105B model is positioned to perform on benchmarks relevant to Indian languages and enterprise tasks, with claims of competitive performance against open/closed models of similar size. ([business-standard.com](https://www.business-standard.com/technology/tech-news/sarvam-105b-model-sovereign-ai-india-foundation-model-launch-impact-summit-126021900551_1.html?utm_source=openai))\n",
      "\n",
      "- Industry coverage: Coverage of the announcement and related products appeared in TechCrunch (Feb 18, 2026), Economic Times (ETtech, Feb 18, 2026), Fortune India (Feb 18, 2026), and The Times of India (Feb 19, 2026), among others. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\n",
      "{'event_id': '1278_2026-02-20', 'news_date': '2026-02-20', 'output': '- Core development: Sarvam AI unveiled two indigenous LLMs, Sarvam-30B and Sarvam-105B, announced at the India AI Impact Summit 2026 in New Delhi, aimed at real-time use and advanced reasoning; MoE architecture with large context windows; open-sourcing planned. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Model architecture: Both models use a mixture-of-experts design that activates only a fraction of parameters at inference to improve efficiency. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Real-time capabilities: 30B targets production-ready, real-time conversational use with a 32,000-token context window; 105B targets more complex, multi-step reasoning with a 128,000-token window. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Training from scratch: 30B was pre-trained from scratch on about 16 trillion tokens; 105B trained on trillions of tokens across multiple Indian languages. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- IndiaAI Mission and compute: Training leveraged India’s government-backed IndiaAI Mission compute, with infrastructure support from Yotta and technical support from Nvidia. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Open-source plan: Sarvam stated it intends to open-source the 30B and 105B models, though it did not specify whether training data or full training code would be disclosed. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Enterprise and ecosystem: The launch outlined an expanded enterprise stack, including Sarvam for Work and a conversational agent platform called Samvaad, plus a vision model for document understanding. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Indus consumer app: Two days after the model announcements, Sarvam released Indus, a consumer AI chat app powered by the 105B model, available in beta on iOS, Android, and the web; initial rollout limited to India with a waitlist. ([techcrunch.com](https://techcrunch.com/2026/02/20/indias-sarvam-launches-indus-ai-chat-app-as-competition-heats-up/?utm_source=openai))\\n\\n- Benchmark and language focus: The 105B model is positioned to perform on benchmarks relevant to Indian languages and enterprise tasks, with claims of competitive performance against open/closed models of similar size. ([business-standard.com](https://www.business-standard.com/technology/tech-news/sarvam-105b-model-sovereign-ai-india-foundation-model-launch-impact-summit-126021900551_1.html?utm_source=openai))\\n\\n- Industry coverage: Coverage of the announcement and related products appeared in TechCrunch (Feb 18, 2026), Economic Times (ETtech, Feb 18, 2026), Fortune India (Feb 18, 2026), and The Times of India (Feb 19, 2026), among others. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))', 'model_provider': 'openai'}\n",
      "- Fractal launches Vaidya 2.0, the next generation of its healthcare reasoning models, available at Vaidya.ai. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "\n",
      "- Vaidya 2.0 scores 50.1 on OpenAI HealthBench (hard), and Fractal says it is the first AI model to exceed 50 on this benchmark, outperforming GPT-5 and Google’s Gemini Pro 3. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "\n",
      "- Debuted at the India AI Impact Summit 2026 in New Delhi, with HealthBench (hard) performance highlighted among its claims. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "\n",
      "- Fractal describes Vaidya 2.0 as designed to power a “Health Care Operating System” of workflows that bridge raw data to healthcare action. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "\n",
      "- Key citizen-facing use cases highlighted for Vaidya 2.0 include Emergency Assist (rapid triage and decision support), Symptom Checker, and Patient Journey Assist. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "\n",
      "- The model shows strong performance on the MedExpert benchmark and introduces capabilities to support Doctor Assist, in addition to OpenAI HealthBench (hard) Health Data Tasks for administrators. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "\n",
      "- Fractal is positioned as part of India’s sovereign AI push under the ₹10,300+ crore India AI Mission, framing Vaidya 2.0 as the first in a family of verticalized foundation models for the Global South. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "\n",
      "- Vaidya 2.0 is described as a post-trained, reasoning- and agentic-based healthcare model rather than a pure knowledge-based foundation model. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "\n",
      "- The release reiterates that Vaidya 2.0 is being demonstrated at the India AI Impact Summit 2026, with the broader Vaidya suite showcased at the event. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\n",
      "{'event_id': '1279_2026-02-20', 'news_date': '2026-02-20', 'output': '- Fractal launches Vaidya 2.0, the next generation of its healthcare reasoning models, available at Vaidya.ai. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Vaidya 2.0 scores 50.1 on OpenAI HealthBench (hard), and Fractal says it is the first AI model to exceed 50 on this benchmark, outperforming GPT-5 and Google’s Gemini Pro 3. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Debuted at the India AI Impact Summit 2026 in New Delhi, with HealthBench (hard) performance highlighted among its claims. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Fractal describes Vaidya 2.0 as designed to power a “Health Care Operating System” of workflows that bridge raw data to healthcare action. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Key citizen-facing use cases highlighted for Vaidya 2.0 include Emergency Assist (rapid triage and decision support), Symptom Checker, and Patient Journey Assist. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- The model shows strong performance on the MedExpert benchmark and introduces capabilities to support Doctor Assist, in addition to OpenAI HealthBench (hard) Health Data Tasks for administrators. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Fractal is positioned as part of India’s sovereign AI push under the ₹10,300+ crore India AI Mission, framing Vaidya 2.0 as the first in a family of verticalized foundation models for the Global South. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Vaidya 2.0 is described as a post-trained, reasoning- and agentic-based healthcare model rather than a pure knowledge-based foundation model. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- The release reiterates that Vaidya 2.0 is being demonstrated at the India AI Impact Summit 2026, with the broader Vaidya suite showcased at the event. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))', 'model_provider': 'openai'}\n",
      "- Core development: Stanford HAI and AWS launched the Stanford and AWS Marketing Science Lab to advance AI-driven marketing measurement, including measurement techniques, causal inference, and AI-based measurement tools. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\n",
      "- Collaboration scope: The lab unites Stanford Institute for Human-Centered AI (HAI), Stanford Data Science, the Stanford Graduate School of Business, and Amazon Web Services (AWS). ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\n",
      "- Leadership: The lab is led by Guido Imbens (HAI-SDS Co-Director), Susan Athey (GSB), Wesley Hartmann (GSB), and Jiafeng (Kevin) Chen (Economics). ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\n",
      "- Announcement date: Public coverage and posts indicate the launch was announced around February 20, 2026. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\n",
      "- Focus areas: The initiative concentrates on marketing measurement, AI-powered measurement, causal inference methods, and analysis of B2B customer journeys. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\n",
      "- Expected outputs: Outcomes include published research, open-source code, and prototypes. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\n",
      "- Relevance to AI product measurement: The lab is described as an academic–industry initiative relevant to AI product measurement and adoption. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\n",
      "- Cloud-scale research angle: The collaboration emphasizes scalable tools and cloud-enabled experimentation, leveraging AWS infrastructure. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\n",
      "- Notable acknowledgement: Julia White, AWS Vice President and Chief Marketing Officer, is credited with helping spur the collaboration. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\n",
      "{'event_id': '1280_2026-02-20', 'news_date': '2026-02-20', 'output': '- Core development: Stanford HAI and AWS launched the Stanford and AWS Marketing Science Lab to advance AI-driven marketing measurement, including measurement techniques, causal inference, and AI-based measurement tools. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Collaboration scope: The lab unites Stanford Institute for Human-Centered AI (HAI), Stanford Data Science, the Stanford Graduate School of Business, and Amazon Web Services (AWS). ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Leadership: The lab is led by Guido Imbens (HAI-SDS Co-Director), Susan Athey (GSB), Wesley Hartmann (GSB), and Jiafeng (Kevin) Chen (Economics). ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Announcement date: Public coverage and posts indicate the launch was announced around February 20, 2026. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\\n- Focus areas: The initiative concentrates on marketing measurement, AI-powered measurement, causal inference methods, and analysis of B2B customer journeys. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Expected outputs: Outcomes include published research, open-source code, and prototypes. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Relevance to AI product measurement: The lab is described as an academic–industry initiative relevant to AI product measurement and adoption. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\\n- Cloud-scale research angle: The collaboration emphasizes scalable tools and cloud-enabled experimentation, leveraging AWS infrastructure. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\\n- Notable acknowledgement: Julia White, AWS Vice President and Chief Marketing Officer, is credited with helping spur the collaboration. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))', 'model_provider': 'openai'}\n",
      "- Gemini 3.1 Pro is announced as a smarter Gemini model, with an upgraded core intelligence designed for tasks where a simple answer isn’t enough. It’s described as a step forward in core reasoning for complex problem-solving. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\n",
      "\n",
      "- Rollout is moving from today across multiple product strands: developers in preview via the Gemini API (including Google AI Studio), Gemini CLI, Google Antigravity, and Android Studio; enterprises via Vertex AI and Gemini Enterprise; consumers via the Gemini app and NotebookLM. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\n",
      "\n",
      "- Access to 3.1 Pro is available through the Gemini API, Vertex AI, the Gemini app, and NotebookLM. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\n",
      "\n",
      "- In benchmarking, 3.1 Pro achieved a verified ARC-AGI-2 score of 77.1%, described as more than double the reasoning performance of 3 Pro. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\n",
      "\n",
      "- Code-based animation capability: 3.1 Pro can generate website-ready, animated SVGs directly from a text prompt. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\n",
      "\n",
      "- Complex system synthesis example: the model can bridge complex APIs to user-friendly designs, demonstrated by building a live aerospace dashboard that visualizes the ISS orbit. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\n",
      "\n",
      "- Interactive design example: 3.1 Pro can code a complex 3D starling murmuration with hand-tracking and a generative score that shifts based on movement. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\n",
      "\n",
      "- Overall framing: 3.1 Pro is a smarter baseline for complex problem solving and is being released in preview to validate updates and advance agentic workflows across consumer, developer, and enterprise products. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\n",
      "{'event_id': '1284_2026-02-20', 'news_date': '2026-02-20', 'output': '- Gemini 3.1 Pro is announced as a smarter Gemini model, with an upgraded core intelligence designed for tasks where a simple answer isn’t enough. It’s described as a step forward in core reasoning for complex problem-solving. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Rollout is moving from today across multiple product strands: developers in preview via the Gemini API (including Google AI Studio), Gemini CLI, Google Antigravity, and Android Studio; enterprises via Vertex AI and Gemini Enterprise; consumers via the Gemini app and NotebookLM. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Access to 3.1 Pro is available through the Gemini API, Vertex AI, the Gemini app, and NotebookLM. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- In benchmarking, 3.1 Pro achieved a verified ARC-AGI-2 score of 77.1%, described as more than double the reasoning performance of 3 Pro. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Code-based animation capability: 3.1 Pro can generate website-ready, animated SVGs directly from a text prompt. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Complex system synthesis example: the model can bridge complex APIs to user-friendly designs, demonstrated by building a live aerospace dashboard that visualizes the ISS orbit. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Interactive design example: 3.1 Pro can code a complex 3D starling murmuration with hand-tracking and a generative score that shifts based on movement. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Overall framing: 3.1 Pro is a smarter baseline for complex problem solving and is being released in preview to validate updates and advance agentic workflows across consumer, developer, and enterprise products. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))', 'model_provider': 'openai'}\n",
      "- OpenAI and Microsoft joined the UK’s AI Security Institute’s international coalition to safeguard AI development, with OpenAI pledging funding to the Alignment Project; total funding now over £27 million to support about 60 projects. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "\n",
      "- The Alignment Project is an international, UK-led effort to advance AI alignment research to ensure frontier AI systems are safe, secure, and under human control. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "\n",
      "- OpenAI is contributing £5.6 million to the Alignment Project, alongside ongoing support from Microsoft and other partners, contributing to the £27 million+ total funding. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "\n",
      "- The coalition supporting the Alignment Project includes a broad set of partners beyond OpenAI/Microsoft, such as CIFAR (Canadian Institute for Advanced Research), Australia’s AI Safety Institute, Schmidt Sciences, AWS, Anthropic, and several funds and UK bodies. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "\n",
      "- The Alignment Project combines grant funding for research, compute infrastructure access, and ongoing academic mentorship from the AI Security Institute to accelerate alignment work. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "\n",
      "- First Alignment Project grants have been awarded to 60 projects spanning eight countries, with a second funding round expected to open in the summer. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "\n",
      "- Announcements were made by UK Deputy Prime Minister David Lammy and AI Minister Kanishka Narayan at the AI Impact Summit in India, marking the close of that summit. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "\n",
      "- Mia Glaese, OpenAI VP of Research, emphasized that advancing alignment requires collaboration across independent teams and that OpenAI’s support complements its internal alignment work. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "\n",
      "- The program is framed as a mechanism to build public trust in AI and enable safer deployment of frontier AI technologies in public services and national renewal. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\n",
      "{'event_id': '1286_2026-02-20', 'news_date': '2026-02-20', 'output': '- OpenAI and Microsoft joined the UK’s AI Security Institute’s international coalition to safeguard AI development, with OpenAI pledging funding to the Alignment Project; total funding now over £27 million to support about 60 projects. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- The Alignment Project is an international, UK-led effort to advance AI alignment research to ensure frontier AI systems are safe, secure, and under human control. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- OpenAI is contributing £5.6 million to the Alignment Project, alongside ongoing support from Microsoft and other partners, contributing to the £27 million+ total funding. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- The coalition supporting the Alignment Project includes a broad set of partners beyond OpenAI/Microsoft, such as CIFAR (Canadian Institute for Advanced Research), Australia’s AI Safety Institute, Schmidt Sciences, AWS, Anthropic, and several funds and UK bodies. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- The Alignment Project combines grant funding for research, compute infrastructure access, and ongoing academic mentorship from the AI Security Institute to accelerate alignment work. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- First Alignment Project grants have been awarded to 60 projects spanning eight countries, with a second funding round expected to open in the summer. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- Announcements were made by UK Deputy Prime Minister David Lammy and AI Minister Kanishka Narayan at the AI Impact Summit in India, marking the close of that summit. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- Mia Glaese, OpenAI VP of Research, emphasized that advancing alignment requires collaboration across independent teams and that OpenAI’s support complements its internal alignment work. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- The program is framed as a mechanism to build public trust in AI and enable safer deployment of frontier AI technologies in public services and national renewal. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))', 'model_provider': 'openai'}\n",
      "- WHAT IS NEW — On February 20, 2026, PhonePe launched an AI-powered natural language search feature built on Microsoft Foundry that lets users initiate and complete in-app tasks, including payments, via voice or text. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\n",
      "- INTENT-BASED ROUTING — The feature replaces traditional navigation with intent-based routing, directing users to their desired action (e.g., \"Pay Hemanth 20 rupees\" pre-selects the recipient or surfaces contacts named Hemanth). ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\n",
      "- ACTION SURFACING — Commands like “Recharge FASTag” or “Gold price” navigate to the most relevant page or surface the appropriate options. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\n",
      "- PRIVACY/COMPUTE ARCHITECTURE — It uses a hybrid model of on-device and cloud inferencing, with personal and transactional data kept within the PhonePe environment. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\n",
      "- ROLLOUT DETAIL — The rollout is being implemented in phases across India, with access via the Global Search Bar, Help Center, and History tab in the PhonePe app. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\n",
      "- OFFICIAL VOICES — Rahul Chari (PhonePe CTO) described the launch as moving toward intent-based intelligent interfaces; Microsoft’s Puneet Chandok commented on Foundry’s role. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\n",
      "- TECHNOLOGY PARTNER — The AI capability is powered by Microsoft Foundry technology. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\n",
      "- CONTEXTUAL BACKDROP — The launch coincides with India’s AI ecosystem activity, with ET Online situating it around the AI Impact Summit 2026. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/industry/banking/finance/phonepe-rolls-out-ai-powered-feature-to-pay-via-voice-or-text/articleshow/128601184.cms?from=mdr))\n",
      "- COMPANY SCALE CONTEXT — PhonePe notes over 65 crore registered users and more than 4.7 crore merchants as of September 2025. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\n",
      "{'event_id': '1287_2026-02-20', 'news_date': '2026-02-20', 'output': '- WHAT IS NEW — On February 20, 2026, PhonePe launched an AI-powered natural language search feature built on Microsoft Foundry that lets users initiate and complete in-app tasks, including payments, via voice or text. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- INTENT-BASED ROUTING — The feature replaces traditional navigation with intent-based routing, directing users to their desired action (e.g., \"Pay Hemanth 20 rupees\" pre-selects the recipient or surfaces contacts named Hemanth). ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- ACTION SURFACING — Commands like “Recharge FASTag” or “Gold price” navigate to the most relevant page or surface the appropriate options. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- PRIVACY/COMPUTE ARCHITECTURE — It uses a hybrid model of on-device and cloud inferencing, with personal and transactional data kept within the PhonePe environment. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- ROLLOUT DETAIL — The rollout is being implemented in phases across India, with access via the Global Search Bar, Help Center, and History tab in the PhonePe app. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- OFFICIAL VOICES — Rahul Chari (PhonePe CTO) described the launch as moving toward intent-based intelligent interfaces; Microsoft’s Puneet Chandok commented on Foundry’s role. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- TECHNOLOGY PARTNER — The AI capability is powered by Microsoft Foundry technology. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- CONTEXTUAL BACKDROP — The launch coincides with India’s AI ecosystem activity, with ET Online situating it around the AI Impact Summit 2026. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/industry/banking/finance/phonepe-rolls-out-ai-powered-feature-to-pay-via-voice-or-text/articleshow/128601184.cms?from=mdr))\\n- COMPANY SCALE CONTEXT — PhonePe notes over 65 crore registered users and more than 4.7 crore merchants as of September 2025. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))', 'model_provider': 'openai'}\n",
      "- What is new: OpenAI has introduced Lockdown Mode for ChatGPT (an optional, advanced security setting) along with Elevated Risk labels for certain capabilities; the feature was announced on February 13, 2026, with consumer rollout planned in coming months. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\n",
      "\n",
      "- Who it’s for: Lockdown Mode is designed for a small set of high-security users (e.g., executives, security teams) and is not required by most users; it is available to ChatGPT Enterprise, Edu, Healthcare, and Teachers, with admins able to enable it in Workspace Settings. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\n",
      "\n",
      "- Core purpose: The mode aims to mitigate prompt-injection risks and data exfiltration by tightening how ChatGPT interacts with external systems. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\n",
      "\n",
      "- Web browsing in Lockdown Mode: Web browsing is limited to cached content, preventing live network requests from leaving OpenAI’s controlled network. This is intended to reduce potential data exfiltration via browsing. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\n",
      "\n",
      "- Other interaction constraints: Lockdown Mode deterministically disables certain tools and capabilities that could be exploited by adversaries; it tightens how ChatGPT can access apps and external sources. (OpenAI describes these as broad restrictions beyond standard protections.) ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\n",
      "\n",
      "- Availability and administration: Admins can tailor which apps and actions are allowed under Lockdown Mode for individual users within a workspace; OpenAI notes a consumer rollout is planned for the coming months. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\n",
      "\n",
      "- Elevated Risk labels: A separate feature assigns “Elevated Risk” labels to specific capabilities across ChatGPT, ChatGPT Atlas, and Codex to communicate higher-risk use cases and guide user decisions. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\n",
      "\n",
      "- Rationale and protections: The rollout builds on existing safeguards (sandboxing, URL-data exfiltration protections, monitoring, audit logs, and enterprise controls) to reduce risk when features interact with networks and external apps. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\n",
      "\n",
      "- Forbes interpretation: Forbes’ analysis frames Lockdown Mode as being “repurposed” to limit problematic mental-health outputs, illustrating how the feature could affect safety in specific use cases. ([forbes.com](https://www.forbes.com/sites/lanceeliot/2026/02/20/new-chatgpt-lockdown-mode-repurposed-to-stop-ai-from-giving-out-bad-mental-health-advice/?utm_source=openai))\n",
      "\n",
      "- Additional coverage and context: Other outlets (e.g., Yahoo Tech and Indian Express) summarize Lockdown Mode as a security upgrade that pairs with Elevated Risk labels to improve transparency about feature risks. ([tech.yahoo.com](https://tech.yahoo.com/ai/chatgpt/articles/chatgpt-now-lockdown-mode-enable-160050855.html/?utm_source=openai))\n",
      "{'event_id': '1288_2026-02-20', 'news_date': '2026-02-20', 'output': '- What is new: OpenAI has introduced Lockdown Mode for ChatGPT (an optional, advanced security setting) along with Elevated Risk labels for certain capabilities; the feature was announced on February 13, 2026, with consumer rollout planned in coming months. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Who it’s for: Lockdown Mode is designed for a small set of high-security users (e.g., executives, security teams) and is not required by most users; it is available to ChatGPT Enterprise, Edu, Healthcare, and Teachers, with admins able to enable it in Workspace Settings. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Core purpose: The mode aims to mitigate prompt-injection risks and data exfiltration by tightening how ChatGPT interacts with external systems. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Web browsing in Lockdown Mode: Web browsing is limited to cached content, preventing live network requests from leaving OpenAI’s controlled network. This is intended to reduce potential data exfiltration via browsing. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Other interaction constraints: Lockdown Mode deterministically disables certain tools and capabilities that could be exploited by adversaries; it tightens how ChatGPT can access apps and external sources. (OpenAI describes these as broad restrictions beyond standard protections.) ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Availability and administration: Admins can tailor which apps and actions are allowed under Lockdown Mode for individual users within a workspace; OpenAI notes a consumer rollout is planned for the coming months. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Elevated Risk labels: A separate feature assigns “Elevated Risk” labels to specific capabilities across ChatGPT, ChatGPT Atlas, and Codex to communicate higher-risk use cases and guide user decisions. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Rationale and protections: The rollout builds on existing safeguards (sandboxing, URL-data exfiltration protections, monitoring, audit logs, and enterprise controls) to reduce risk when features interact with networks and external apps. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Forbes interpretation: Forbes’ analysis frames Lockdown Mode as being “repurposed” to limit problematic mental-health outputs, illustrating how the feature could affect safety in specific use cases. ([forbes.com](https://www.forbes.com/sites/lanceeliot/2026/02/20/new-chatgpt-lockdown-mode-repurposed-to-stop-ai-from-giving-out-bad-mental-health-advice/?utm_source=openai))\\n\\n- Additional coverage and context: Other outlets (e.g., Yahoo Tech and Indian Express) summarize Lockdown Mode as a security upgrade that pairs with Elevated Risk labels to improve transparency about feature risks. ([tech.yahoo.com](https://tech.yahoo.com/ai/chatgpt/articles/chatgpt-now-lockdown-mode-enable-160050855.html/?utm_source=openai))', 'model_provider': 'openai'}\n",
      "- Meta plans to launch its first smartwatch in 2026, code-named Malibu 2, featuring health tracking and a built-in Meta AI assistant. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\n",
      "- The smartwatch revival follows a 2022 shutdown of a prior Meta smartwatch effort amid Reality Labs cost cuts; the project traces back roughly five years and included camera-equipped concepts. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\n",
      "- The device is slated for release later in 2026, according to the initial reporting on the Malibu 2 project. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\n",
      "- It would compete directly with established smartwatches such as the Apple Watch and other wearables. ([forbes.com](https://www.forbes.com/sites/andrewwilliams/2026/02/19/meta-smartwatch-makes-perfect-sense-amid-smart-glasses-strategy/?utm_source=openai))\n",
      "- Reported features include health-tracking capabilities and integration with Meta’s AI, rather than a generic, non-AI smartwatch. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\n",
      "- The Malibu 2 concept is discussed in the context of broader Meta wearables strategy, potentially enabling cross-device interactions with Ray-Ban smart glasses. ([forbes.com](https://www.forbes.com/sites/andrewwilliams/2026/02/19/meta-smartwatch-makes-perfect-sense-amid-smart-glasses-strategy/?utm_source=openai))\n",
      "- Meta has not publicly commented on the Malibu 2 plan when approached by reporters. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\n",
      "- The wearables backdrop includes Ray-Ban Display glasses, which reportedly shipped close to 6 million units in 2025, underscoring a growing AI-enabled wearable ecosystem. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\n",
      "- Separately, Meta reportedly delayed its Phoenix mixed-reality glasses to 2027 and paused international rollout of Ray-Ban Display glasses to prioritize US demand, signaling a staggered hardware roadmap. ([businessinsider.com](https://www.businessinsider.com/meta-delays-new-mixed-reality-glasses-code-named-phoenix-2025-12?utm_source=openai))\n",
      "{'event_id': '1289_2026-02-20', 'news_date': '2026-02-20', 'output': '- Meta plans to launch its first smartwatch in 2026, code-named Malibu 2, featuring health tracking and a built-in Meta AI assistant. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- The smartwatch revival follows a 2022 shutdown of a prior Meta smartwatch effort amid Reality Labs cost cuts; the project traces back roughly five years and included camera-equipped concepts. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- The device is slated for release later in 2026, according to the initial reporting on the Malibu 2 project. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- It would compete directly with established smartwatches such as the Apple Watch and other wearables. ([forbes.com](https://www.forbes.com/sites/andrewwilliams/2026/02/19/meta-smartwatch-makes-perfect-sense-amid-smart-glasses-strategy/?utm_source=openai))\\n- Reported features include health-tracking capabilities and integration with Meta’s AI, rather than a generic, non-AI smartwatch. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- The Malibu 2 concept is discussed in the context of broader Meta wearables strategy, potentially enabling cross-device interactions with Ray-Ban smart glasses. ([forbes.com](https://www.forbes.com/sites/andrewwilliams/2026/02/19/meta-smartwatch-makes-perfect-sense-amid-smart-glasses-strategy/?utm_source=openai))\\n- Meta has not publicly commented on the Malibu 2 plan when approached by reporters. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- The wearables backdrop includes Ray-Ban Display glasses, which reportedly shipped close to 6 million units in 2025, underscoring a growing AI-enabled wearable ecosystem. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- Separately, Meta reportedly delayed its Phoenix mixed-reality glasses to 2027 and paused international rollout of Ray-Ban Display glasses to prioritize US demand, signaling a staggered hardware roadmap. ([businessinsider.com](https://www.businessinsider.com/meta-delays-new-mixed-reality-glasses-code-named-phoenix-2025-12?utm_source=openai))', 'model_provider': 'openai'}\n",
      "- Core development: Lyria 3, Google DeepMind’s latest generative music model, is rolling out in beta inside the Gemini app, enabling creation of 30-second tracks from text prompts, photos, or videos, with auto lyrics and optional cover art; output is watermark-tagged via SynthID. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\n",
      "\n",
      "- Global beta availability and rollout: The feature is available to Gemini users 18+, with desktop access today and mobile rollout in the coming days; supported languages include English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\n",
      "\n",
      "- Output length and scope: Lyria 3 targets 30-second tracks, designed for short-form content (e.g., YouTube Shorts, TikTok, Reels). ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\n",
      "\n",
      "- Auto lyrics capability: Lyrics generation is built into the flow, removing the previous requirement to supply lyrics manually. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\n",
      "\n",
      "- Multimodal control: Users can steer generation with text plus visual prompts (images/videos) to influence genre, mood, tempo, and vocal tone. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\n",
      "\n",
      "- Copyright and safety safeguards: Outputs are filtered to discourage direct artist mimicry, with provenance tools and a reporting channel for rights concerns; SynthID watermarking supports identification of AI-generated audio. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\n",
      "\n",
      "- YouTube Dream Track integration: Lyria 3 is being extended to YouTube creators via Dream Track, expanding access beyond Gemini to creator workflows. ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\n",
      "\n",
      "- Creator-facing features (art and branding): Gemini generates custom cover art for tracks (e.g., via Nano Banana) to accompany AI-made songs. ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\n",
      "\n",
      "- Availability and access tier details: Free usage exists with plan-based limits; Google AI Plus, Pro, and Ultra subscribers are described as receiving higher generation ceilings. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\n",
      "{'event_id': '1291_2026-02-20', 'news_date': '2026-02-20', 'output': '- Core development: Lyria 3, Google DeepMind’s latest generative music model, is rolling out in beta inside the Gemini app, enabling creation of 30-second tracks from text prompts, photos, or videos, with auto lyrics and optional cover art; output is watermark-tagged via SynthID. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Global beta availability and rollout: The feature is available to Gemini users 18+, with desktop access today and mobile rollout in the coming days; supported languages include English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Output length and scope: Lyria 3 targets 30-second tracks, designed for short-form content (e.g., YouTube Shorts, TikTok, Reels). ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Auto lyrics capability: Lyrics generation is built into the flow, removing the previous requirement to supply lyrics manually. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Multimodal control: Users can steer generation with text plus visual prompts (images/videos) to influence genre, mood, tempo, and vocal tone. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Copyright and safety safeguards: Outputs are filtered to discourage direct artist mimicry, with provenance tools and a reporting channel for rights concerns; SynthID watermarking supports identification of AI-generated audio. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- YouTube Dream Track integration: Lyria 3 is being extended to YouTube creators via Dream Track, expanding access beyond Gemini to creator workflows. ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Creator-facing features (art and branding): Gemini generates custom cover art for tracks (e.g., via Nano Banana) to accompany AI-made songs. ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Availability and access tier details: Free usage exists with plan-based limits; Google AI Plus, Pro, and Ultra subscribers are described as receiving higher generation ceilings. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))', 'model_provider': 'openai'}\n",
      "- Qumis announces an oversubscribed seed round of $4.3 million led by MTech Capital, with American Family Ventures joining as a new strategic investor; total funding now sits at $6.75 million. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "\n",
      "- The round will be deployed to expand Qumis’ go-to-market team and deepen product capabilities around coverage intelligence for commercial insurance. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "\n",
      "- Qumis’ platform is described as attorney-trained AI for commercial insurance coverage intelligence that reads and reasons across complex policy documents to deliver structured, citation-backed insights with transparent reasoning. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "\n",
      "- Traction includes adoption by large brokers and carriers, notably NFP (an Aon company), with usage expanding from an initial team to hundreds of users across the organization. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "\n",
      "- The funding comes amid continuing AI investment in insurance, with most capital historically flowing to workflow automation and document processing—Qumis is pursuing a more specialized, coverage-focused AI approach. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "\n",
      "- Qumis is Chicago-based, founded in 2022, and built by coverage attorneys and AI experts to replace manual policy review with attorney-grade coverage insights. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "\n",
      "- Lead investor in the round is MTech Capital; American Family Ventures is a new strategic investor; all prior investors participated in this round. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "\n",
      "- The platform targets insurance teams across brokers, carriers, and coverage-focused law firms, offering policy analysis, policy comparisons, and real-time insights to support underwriting and claims. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "\n",
      "- No valuation for the seed round was disclosed in the public announcements. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\n",
      "{'event_id': '1292_2026-02-20', 'news_date': '2026-02-20', 'output': '- Qumis announces an oversubscribed seed round of $4.3 million led by MTech Capital, with American Family Ventures joining as a new strategic investor; total funding now sits at $6.75 million. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- The round will be deployed to expand Qumis’ go-to-market team and deepen product capabilities around coverage intelligence for commercial insurance. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- Qumis’ platform is described as attorney-trained AI for commercial insurance coverage intelligence that reads and reasons across complex policy documents to deliver structured, citation-backed insights with transparent reasoning. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- Traction includes adoption by large brokers and carriers, notably NFP (an Aon company), with usage expanding from an initial team to hundreds of users across the organization. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- The funding comes amid continuing AI investment in insurance, with most capital historically flowing to workflow automation and document processing—Qumis is pursuing a more specialized, coverage-focused AI approach. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- Qumis is Chicago-based, founded in 2022, and built by coverage attorneys and AI experts to replace manual policy review with attorney-grade coverage insights. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- Lead investor in the round is MTech Capital; American Family Ventures is a new strategic investor; all prior investors participated in this round. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- The platform targets insurance teams across brokers, carriers, and coverage-focused law firms, offering policy analysis, policy comparisons, and real-time insights to support underwriting and claims. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- No valuation for the seed round was disclosed in the public announcements. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))', 'model_provider': 'openai'}\n",
      "- OpenAI is developing a family of AI-powered devices, including a smart speaker and possibly smart glasses and a smart lamp, with a team of more than 200 people, signaling a shift from cloud/model-only products toward consumer hardware. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\n",
      "- The smart speaker would be the first device in the lineup, with an estimated retail price of $200–$300 and not expected to ship before February 2027 at the earliest. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\n",
      "- The speaker is described as including a camera to gather information about users and their surroundings. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\n",
      "- The smart glasses in the plan are not expected to reach mass production until 2028. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\n",
      "- The device family reportedly also includes a smart lamp as part of the initial concept set. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\n",
      "- OpenAI’s hardware push traces back to its $6.5 billion acquisition of io Products, the Jony Ive–founded hardware unit. ([bloomberg.com](https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal?utm_source=openai))\n",
      "- The move is framed as OpenAI aiming to capitalize on growing demand for physical AI and augmented reality rather than solely cloud/software offerings. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\n",
      "- Industry context cited in reports notes Meta’s Ray-Ban smart glasses have had success, and that Apple and Google are also pursuing wearables. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\n",
      "{'event_id': '1294_2026-02-20', 'news_date': '2026-02-20', 'output': '- OpenAI is developing a family of AI-powered devices, including a smart speaker and possibly smart glasses and a smart lamp, with a team of more than 200 people, signaling a shift from cloud/model-only products toward consumer hardware. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- The smart speaker would be the first device in the lineup, with an estimated retail price of $200–$300 and not expected to ship before February 2027 at the earliest. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- The speaker is described as including a camera to gather information about users and their surroundings. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- The smart glasses in the plan are not expected to reach mass production until 2028. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- The device family reportedly also includes a smart lamp as part of the initial concept set. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- OpenAI’s hardware push traces back to its $6.5 billion acquisition of io Products, the Jony Ive–founded hardware unit. ([bloomberg.com](https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal?utm_source=openai))\\n- The move is framed as OpenAI aiming to capitalize on growing demand for physical AI and augmented reality rather than solely cloud/software offerings. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- Industry context cited in reports notes Meta’s Ray-Ban smart glasses have had success, and that Apple and Google are also pursuing wearables. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))', 'model_provider': 'openai'}\n"
     ]
    }
   ],
   "source": [
    "openai_research_v2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "760c7daf-79bd-4db4-866d-771369644ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n"
     ]
    }
   ],
   "source": [
    "for i in research_output_7:\n",
    "    if i['news_date'] == '2026-02-20':\n",
    "        save_research(i)\n",
    "        print(\"✅ Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25fab8ff-db94-4860-a089-93a228174aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [{'event_id': '567_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Core development: The India AI Impact Summit 2026 is scheduled for February 16–20, 2026 in New Delhi, with the Bharat Mandapam Expo Arena and Sushma Swaraj Bhawan as primary venues; Prime Minister Modi is slated to inaugurate the AI Expo on February 16 at 5:00 PM, with the Expo open to the public from February 17. ([impactexpo.indiaai.gov.in](https://www.impactexpo.indiaai.gov.in/?utm_source=openai))\\n\\n- High-profile attendees: Reported participants include OpenAI CEO Sam Altman and Google CEO Sundar Pichai, among other tech leaders (e.g., Dario Amodei, Demis Hassabis); organizers anticipate 20 heads of state and 40+ CEOs. ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/tech-news/india-ai-impact-summit-2026-what-it-is-whos-coming-and-why-it-matters/articleshow/128207697.cms?utm_source=openai))\\n\\n- Attendee-availability uncertainty for Altman: Media reports vary on Altman’s confirmed attendance; some outlets say he is expected to visit, while others cite no confirmed listing. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/artificial-intelligence/openais-sam-altman-eyes-india-visit-as-global-ai-leaders-gather-in-new-delhi/articleshow/127470231.cms?utm_source=openai))\\n\\n- Nvidia attendance status: Reports have differed on Nvidia’s leader’s presence; Barron’s notes Jensen Huang is not attending, while other coverage has implied he could be part of the delegation. ([barrons.com](https://www.barrons.com/articles/alphabet-anthropic-stock-ceo-ai-summit-c1833be3?utm_source=openai))\\n\\n- Summit focus and structure: The event is framed around tangible collaboration and outcomes, organized conceptually around three Sutras (People, Planet, Progress) and seven Chakras, with a goal of moving from pilot projects to policy/action and signaling near-term partnerships and expansions. ([indianexpress.com](https://indianexpress.com/article/explained/explained-sci-tech/ai-impact-summit-begins-delhi-agenda-10533773/?utm_source=openai))\\n\\n- Global South leadership context: Coverage emphasizes that this is the first major global AI summit hosted in the Global South, signaling India’s role in shaping inclusive AI governance and deployment. ([apnews.com](https://apnews.com/article/f32aa15263349dadad1840dadc75ca83?utm_source=openai))\\n\\n- Pre-summit activities and governance: The organizers have launched a formal Call for Pre-Summit Events, and there have been multiple stakeholder consultations in 2025 as part of preparing the summit agenda. ([impact.indiaai.gov.in](https://impact.indiaai.gov.in/home/pre-summit-events?utm_source=openai))\\n\\n- Expo scale and sector focus: The India AI Impact Expo at Bharat Mandapam will feature AI products and solutions across industries (healthcare, education, governance, etc.), with the event highlighting partnerships, deployments, and industry uptake. ([impactexpo.indiaai.gov.in](https://www.impactexpo.indiaai.gov.in/?utm_source=openai))\\n\\n- Prime Minister Modi’s onsite role and program: In addition to inaugurating the expo, Modi is slated to address the main plenary (Feb 19) and engage with a wide slate of CEOs during the summit. ([m.economictimes.com](https://m.economictimes.com/ai/ai-insights/prime-minister-narendra-modi-inaugurates-india-ai-impact-expo-2026-at-bharat-mandapam-new-delhi-artificial-intelligence/articleshow/128420514.cms?utm_source=openai))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '585_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Doubao 2.0 launched on February 14, 2026 as an upgrade to ByteDance’s flagship Doubao AI chatbot; the Pro version adds advanced reasoning and multi-step task execution, with ByteDance claiming usage costs per token are reduced by roughly 10x. ([straitstimes.com](https://www.straitstimes.com/asia/east-asia/chinas-bytedance-releases-doubao-2-0-ai-model-for-agent-era//?utm_source=openai))\\n\\n- The release was timed ahead of the Lunar New Year holiday, a peak period for user engagement in China. ([straitstimes.com](https://www.straitstimes.com/asia/east-asia/chinas-bytedance-releases-doubao-2-0-ai-model-for-agent-era//?utm_source=openai))\\n\\n- The Pro variant is described as capable of complex reasoning and multi-step task execution that ByteDance positions against leading frontier models (GPT-5.2 and Gemini 3 Pro). ([straitstimes.com](https://www.straitstimes.com/asia/east-asia/chinas-bytedance-releases-doubao-2-0-ai-model-for-agent-era//?utm_source=openai))\\n\\n- Doubao 2.0 was developed by ByteDance’s Seed research team and built using Volcano Engine API services, with a focus on long-chain reasoning. ([scmp.com](https://www.scmp.com/tech/big-tech/article/3332365/bytedance-unveils-chinas-most-affordable-ai-coding-agent-just-us130-month?utm_source=openai))\\n\\n- Doubao remains China’s leading AI chatbot by user reach, with approximately 155 million weekly active users as of late December 2025. ([straitstimes.com](https://www.straitstimes.com/asia/east-asia/chinas-bytedance-releases-doubao-2-0-ai-model-for-agent-era//?utm_source=openai))\\n\\n- ByteDance previously expanded Doubao with Doubao-Seed-Code, a coding agent released in November 2025, priced at 9.9 yuan for the first month and 40 yuan monthly thereafter; it achieved SWE-Bench Verified status. ([scmp.com](https://www.scmp.com/tech/big-tech/article/3332365/bytedance-unveils-chinas-most-affordable-ai-coding-agent-just-us130-month?utm_source=openai))\\n\\n- Concurrently, ByteDance released Seedance 2.0, a video-generation model, around February 12–13, 2026, which circulated widely online and attracted copyright complaints. ([investing.com](https://www.investing.com/news/stock-market-news/disney-sends-ceaseanddesist-to-bytedance-over-aigenerated-videos-4507348?utm_source=openai))\\n\\n- The Seedance 2.0 controversy drew cease-and-desist actions from Disney and others, with ByteDance pledging to strengthen safeguards to curb IP risk and unauthorized likeness usage. ([investing.com](https://www.investing.com/news/stock-market-news/disney-sends-ceaseanddesist-to-bytedance-over-aigenerated-videos-4507348?utm_source=openai))\\n\\n- The IP backlash to Seedance 2.0 occurred within a broader domestic AI-ecosystem competition in China, which included Alibaba’s February 6, 2026 3 billion yuan Qwen coupon campaign to boost in-chat engagement. ([straitstimes.com](https://www.straitstimes.com/asia/east-asia/chinas-bytedance-releases-doubao-2-0-ai-model-for-agent-era//?utm_source=openai))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '592_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Core new development: Zhipu AI launched its GLM‑5 in overseas markets and announced GLM Coding Plan price adjustments, with domestic package prices rising about 30% (effective February 12, 2026) and overseas Coding Plan/API pricing rising roughly 30%–60% and 67%–100%, respectively. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))\\n- Domestic pricing detail: Domestic GLM package prices have increased by at least 30%, and existing subscribers will continue at their current rates; the changes took effect February 12, 2026. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))\\n- Overseas pricing detail: Overseas Coding Plan prices are up about 30%–60%, and overseas API usage fees are up about 67%–100%; overseas increases are higher than domestic ones. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))\\n- Claimed drivers: TrendForce attributes the price moves to rising demand for GLM‑5 and higher compute costs, contributing to a broader price-stabilization trend among Chinese LLM providers. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))\\n- Market context: TrendForce notes a broader price-stabilization trend across Chinese LLM providers, with several firms beginning to halt price cuts in 2025 and pursuing tiered pricing strategies. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))\\n- 2025 context referenced: The report mentions that other “Six Rising Tigers” (e.g., Moonshot AI, MiniMax, StepFun) had already raised certain API prices in 2025, while Baichuan Intelligence and 01.AI kept prices unchanged; Alibaba/Tencent/Baidu have been adopting tiered pricing. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))\\n- GLM‑5 profile: GLM‑5 is described as Zhipu AI’s next‑gen flagship large language model. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))\\n- Coding Plan focus: The GLM Coding Plan targets developer code generation and programming assistance use cases. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))\\n- Publication context: TrendForce published these observations on February 16, 2026, summarizing events surrounding GLM‑5’s overseas rollout and price adjustments. ([trendforce.com](https://www.trendforce.com/news/2026/02/16/news-rising-costs-and-demand-drive-chinas-llm-price-jump-zhipu-glm%E2%80%915-hikes-30-in-first-2026-increase/?utm_source=openai))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '594_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Core development: Blackstone-led financing into Neysa totaling up to $1.2 billion to build India’s AI infrastructure platform, with up to $600 million in equity from Blackstone and co-investors and up to $600 million of debt financing; Blackstone majority stake to be held post-transaction; announcement date February 16, 2026. ([blackstone.com](https://www.blackstone.com/news/press/blackstone-leads-funding-of-over-1-billion-to-neysa-to-work-towards-building-indias-leading-ai-infrastructure-platform/))\\n\\n- Investors: Equity participants include Blackstone plus co-investors Teachers’ Venture Growth, TVS Capital, 360 ONE Asset, and Nexus Venture Partners; debt component described as up to $600 million, to be raised concurrently. ([techcrunch.com](https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/))\\n\\n- Deal structure: The $1.2 billion capital raise is described as a split between primary equity and debt financing (roughly equal share each), enabling Neysa to deploy larger GPU capacity while Blackstone takes a majority stake. ([techcrunch.com](https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/))\\n\\n- Use of funds: Funds allocated to scale Neysa’s GPU capacity to over 20,000 GPUs in India and accelerate deployment across its AI infrastructure platform. ([blackstone.com](https://www.blackstone.com/news/press/blackstone-leads-funding-of-over-1-billion-to-neysa-to-work-towards-building-indias-leading-ai-infrastructure-platform/))\\n\\n- GPU capacity and current footprint: Neysa currently has about 1,200 GPUs live and plans to deploy more than 20,000 GPUs over time as demand accelerates. ([techcrunch.com](https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/))\\n\\n- Neysa platform and product details: Neysa operates an AI Acceleration Cloud platform (Velocis) that integrates GPU-based infrastructure with AI optimization and security tools to train, fine-tune, and deploy AI workloads. ([blackstone.com](https://www.blackstone.com/news/press/blackstone-leads-funding-of-over-1-billion-to-neysa-to-work-towards-building-indias-leading-ai-infrastructure-platform/))\\n\\n- Ownership and control: Blackstone will hold a majority stake in Neysa following the investment, with Neysa’s leadership continuing to drive growth via its CEO Sharad Sanghi. ([techcrunch.com](https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/))\\n\\n- Policy and market context: The investment aligns with India’s sovereign AI ambitions and IndiaAI Mission, including favorable policy signals such as a data-center tax holiday announced in the budget. ([blackstone.com](https://www.blackstone.com/news/press/blackstone-leads-funding-of-over-1-billion-to-neysa-to-work-towards-building-indias-leading-ai-infrastructure-platform/))\\n\\n- Blackstone’s broader infra strategy: The Neysa deal fits Blackstone’s global push into data center and AI infrastructure, building on its investments in data-center platforms and specialized AI infra players. ([techcrunch.com](https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/))\\n\\n- Reported valuation context: Indian press reports pegged Neysa’s enterprise valuation around $1.4 billion, with some outlets noting valuation not disclosed by Neysa; the dynamic is reflected across sources. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/funding/blackstone-leads-600-million-raise-in-ai-cloud-neysa-at-1-4-billion-enterprise-value/articleshow/128390049.cms))\\n\\n- Notable customers (context of traction): Neysa’s client base includes Justpay, Swiggy, and Perfios, underscoring demand from Indian enterprises and public-sector entities for sovereign AI compute. ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/business/india-business/blackstone-leads-1-2-billion-raise-for-homegrown-ai-firm-neysa/articleshow/128403035.cms))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '595_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- What is new: Surging AI memory demand is intensifying a global memory/chip supply squeeze, with AI data-center needs re-prioritizing memory production and driving higher memory costs and allocation constraints. ([businesstimes.com.sg](https://www.businesstimes.com.sg/international/global/memory-chip-squeeze-wreaks-havoc-markets-more-come/?utm_source=openai))\\n\\n- Why it matters: The shift in memory allocation toward AI workloads is reframing AI compute costs and driving capacity-planning decisions for hyperscalers and cloud providers. ([ibselectronics.com](https://www.ibselectronics.com/resources/news/ai-buildout-is-tightening-memory-supply-and-pricing-pressure-is-spreading-beyond-phones-and-pcs/))\\n\\n- Demand shift specifics: AI data centers are increasingly diverting memory capacity toward high-bandwidth memory (HBM) and server DRAM, tightening supply for conventional DRAM/NAND used by consumer devices and other sectors. ([ibselectronics.com](https://www.ibselectronics.com/resources/news/ai-buildout-is-tightening-memory-supply-and-pricing-pressure-is-spreading-beyond-phones-and-pcs/))\\n\\n- Foreseeable price impact (1Q26): TrendForce forecasts conventional DRAM contract prices rising about 55–60% QoQ in 1Q26, NAND Flash 33–38% QoQ, with server DRAM prices rising more than 60% QoQ. ([trendforce.com](https://www.trendforce.com/presscenter/news/20260105-12860.html?utm_source=openai))\\n\\n- Additional market signals: IDC described an “unprecedented” memory shortage in late 2025 with effects persisting into 2027, due to AI-data-center demand outstripping supply. ([ibselectronics.com](https://www.ibselectronics.com/resources/news/ai-buildout-is-tightening-memory-supply-and-pricing-pressure-is-spreading-beyond-phones-and-pcs/))\\n\\n- Evidence of downstream price moves: OEMs and consumers are already seeing higher memory costs (e.g., LPDDR5x shortages contributing to desktop PC price hikes; frameworked price changes cited by Reuters in early 2026). ([ibselectronics.com](https://www.ibselectronics.com/resources/news/ai-buildout-is-tightening-memory-supply-and-pricing-pressure-is-spreading-beyond-phones-and-pcs/))\\n\\n- 1Q26 memory-price trajectory: DRAM prices are expected to surge sharply, with conventional DRAM contract prices seen rising 90–95% QoQ in 1Q26 per DRAMeXchange TrendForce commentary; NAND prices also slated for double-digit increases. ([dramexchange.com](https://www.dramexchange.com/WeeklyResearch/Post/2/12604.html?utm_source=openai))\\n\\n- HBM/AI-memory focus and capacity reallocation: TrendForce and industry analyses note growing AI/HBM demand is accelerating capacity shifts from consumer/mobile memory to AI-grade memory, with HBM supply prioritized over general DRAM/NAND. ([trendforce.com](https://www.trendforce.com/presscenter/news/20260105-12860.html?utm_source=openai))\\n\\n- Market consequences and investor/industry response: The memory squeeze has produced broad market disruption, with memory-sector equities rallying and major players reassessing pricing, allocation, and long-term procurement strategies. ([businesstimes.com.sg](https://www.businesstimes.com.sg/international/global/memory-chip-squeeze-wreaks-havoc-markets-more-come/?utm_source=openai))\\n\\n- Outlook through 2026–2027: Analysts expect the tight memory supply and price volatility to persist as AI infrastructure buildout continues to outpace new memory-capacity additions, sustaining elevated pricing power for memory suppliers. ([ibselectronics.com](https://www.ibselectronics.com/resources/news/ai-buildout-is-tightening-memory-supply-and-pricing-pressure-is-spreading-beyond-phones-and-pcs/))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '596_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Core development: UK announces at the India AI Impact Summit (February 16, 2026) that it will champion AI to supercharge growth, unlock new jobs, and improve public services globally. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))\\n\\n- Leadership and participation: The Deputy Prime Minister, David Lammy, and AI Minister, Kanishka Narayan, lead the UK delegation, with plans for engagement on how AI can improve everyday life and governance. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))\\n\\n- Funding context: The announcement is part of the UK’s AI for Development (AI4D) programme, described as £58 million in total funding, with new initiatives being announced at the summit. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))\\n\\n- Asian AI4D Observatory: One of the three new AI4D initiatives, designed to support responsible AI innovation and governance across South and Southeast Asia. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))\\n\\n- AI4D Compute Hub: Another new AI4D initiative, to establish a Compute Hub at the University of Cape Town to provide compute power for African innovators. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))\\n\\n- African Language Hub: UK will announce new support for an African Language Hub, enabling AI to operate in 40 African languages. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))\\n\\n- Summit context: The UK frames this as part of ongoing collaboration with India and broader governance efforts, noting ties to Vision 2035 and recent high-level engagement. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))\\n\\n- Global governance and prior summits: The press release situates the India summit within a sequence that includes the Bletchley Park AI Safety Summit and previous summits in Seoul and Paris, linking policy dialogue to governance and safety standards. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))\\n\\n- Private investment context: The UK notes that, since summer 2024, it has attracted more than £100 billion of private investment into the UK’s AI sector, underscoring the policy push to translate investment into jobs and growth. ([gov.uk](https://www.gov.uk/government/news/uk-to-champion-how-ai-can-supercharge-growth-unlock-new-jobs-and-improve-public-services-at-ai-impact-summit-in-india))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '611_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Core development: A February 16, 2026 Reuters market-reaction piece (widely republished) reports AI spending fears have driven a sell-off in major tech stocks, erasing hundreds of billions in market value for firms including Microsoft, Amazon, Nvidia, Apple, and Alphabet. ([channelnewsasia.com](https://www.channelnewsasia.com/business/big-tech-stocks-lose-billions-ai-spending-fears-hit-valuations-5934031))\\n\\n- Microsoft effect: Microsoft shares are down about 17% year-to-date, wiping roughly $613 billion off its market value to around $2.98 trillion as of February 13, 2026, amid concerns about AI profitability and rising competition from rivals like Google and Anthropic. ([channelnewsasia.com](https://www.channelnewsasia.com/business/big-tech-stocks-lose-billions-ai-spending-fears-hit-valuations-5934031))\\n\\n- Amazon effect: Amazon has shed about 13.85% year-to-date, erasing roughly $343 billion in market value and leaving it valued at about $2.13 trillion; the company also signaled capex growth of more than 50% this year. ([channelnewsasia.com](https://www.channelnewsasia.com/business/big-tech-stocks-lose-billions-ai-spending-fears-hit-valuations-5934031))\\n\\n- Nvidia, Apple, Alphabet: Since the start of 2026, Nvidia’s, Apple’s and Alphabet’s market values declined by roughly $89.67 billion, $256.44 billion, and $87.96 billion respectively, with current valuations around Nvidia $4.44 trillion, Apple $3.76 trillion, and Alphabet $3.70 trillion. ([channelnewsasia.com](https://www.channelnewsasia.com/business/big-tech-stocks-lose-billions-ai-spending-fears-hit-valuations-5934031))\\n\\n- Alphabet capex context: Alphabet indicated up to about $185 billion in capital expenditure for 2026, underscoring ballooning AI-related spending that underpins investor concerns about near-term returns. ([investing.com](https://www.investing.com/news/stock-market-news/sp-nasdaq-futures-subdued-as-markets-digest-alphabets-ai-spending-plans-4487019?utm_source=openai))\\n\\n- Market psychology shift: The pullback is described as a broader shift in investor sentiment from rewarding long-term AI initiatives to demanding clearer near-term earnings visibility. ([channelnewsasia.com](https://www.channelnewsasia.com/business/big-tech-stocks-lose-billions-ai-spending-fears-hit-valuations-5934031))\\n\\n- Other tech winners/losers frame: While Big Tech softened, some peers like TSMC, Samsung Electronics, and Walmart reportedly added market value during the period, illustrating a rotation within tech/tech-adjacent stocks. ([marketscreener.com](https://www.marketscreener.com/news/big-tech-stocks-lose-billions-as-ai-spending-fears-hit-valuations-ce7e5ddbd180f72d?utm_source=openai))\\n\\n- Publication framing/date: The Reuters-derived report was published February 16, 2026, with the cited figures reflecting the prior Friday, February 13, 2026, as the point of reference for “year-to-date” declines. ([channelnewsasia.com](https://www.channelnewsasia.com/business/big-tech-stocks-lose-billions-ai-spending-fears-hit-valuations-5934031))\\n\\n- Source note: All figures and claims above trace back to Reuters reporting on Feb 16, 2026, as summarized by CNA (Reuters) and corroborated by additional Reuters mirrors. ([channelnewsasia.com](https://www.channelnewsasia.com/business/big-tech-stocks-lose-billions-ai-spending-fears-hit-valuations-5934031))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '613_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Ant Group released Ling-2.5-1T, a trillion-parameter general-purpose LLM, and Ring-2.5-1T, the world’s first hybrid linear-architecture thinking model, on February 16, 2026; both are available under open licenses on Hugging Face and ModelScope. ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))\\n- Ling-2.5-1T supports context lengths of up to 1,000,000 tokens and is designed for higher reasoning efficiency, fine-grained preference alignment, and native agent interaction. ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))\\n- On AIME 2026, Ling-2.5-1T reportedly matches frontier thinking models that typically require 15,000–23,000 tokens while using roughly 5,890 tokens. ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))\\n- Ring-2.5-1T is built on a hybrid linear architecture and targets advanced reasoning tasks; it reportedly achieved gold-tier results on IMO 2025 (35/42) and CMO 2025 (105/126). ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))\\n- Ming-Flash-Omni-2.0, a large-scale omni model unifying speech, audio, and music within a single architecture, was released by Ant Group on February 11, 2026. ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))\\n- Ling-2.5-1T and Ring-2.5-1T represent the latest evolution of Ant Group’s Ling 2.0 series, unveiled in October 2025. ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))\\n- The Ling family includes Ling non-thinking MoE LLMs, Ring thinking models, and Ming multimodal models, marking a comprehensive upgrade across the Ling (BaiLing) model family. ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))\\n- Both Ling-2.5-1T and Ring-2.5-1T are now openly licensed and hosted on Hugging Face and ModelScope, under the InclusionAI umbrella. ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))\\n- Release location and date: Hangzhou, China, February 16, 2026, with the Business Wire-distributed press release detailing the open licensing and model capabilities. ([businesswire.com](https://www.businesswire.com/news/home/20260215551663/en/))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '615_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- GLM-5 is a 745B-parameter frontier LLM released as open-source (MIT license) by Zhipu AI, built as a Mixture-of-Experts model with 256 experts and 8 active per token, featuring 44B active parameters per inference and a 200K-token context window. It uses DeepSeek Sparse Attention and was trained on Huawei Ascend hardware with MindSpore. ([glm5.net](https://glm5.net/))\\n\\n- The model was publicly released in February 2026 (reported Feb 11–12, 2026 in China press and by international outlets), with open weights available on Hugging Face and GitHub and the release framed as a major open-source milestone. ([scmp.com](https://www.scmp.com/tech/article/3343239/chinas-zhipu-ai-launches-new-major-model-glm-5-challenge-its-rivals))\\n\\n- GLM-5’s weights are openly accessible under MIT license on Hugging Face (zai-org/GLM-5) and are downloadable for commercial use and local deployment; the model card also confirms the MIT license. ([huggingface.co](https://huggingface.co/zai-org/GLM-5))\\n\\n- The release specifies 28.5 trillion tokens of pre-training data, substantially larger than prior GLM iterations, and it notes a corresponding scale-up from 355B (GLM-4.7) to 744B parameters. ([globenewswire.com](https://www.globenewswire.com/de/news-release/2026/02/13/3238012/0/en/index.html))\\n\\n- GLM-5 introduces DeepSeek Sparse Attention (DSA) to improve long-context processing efficiency and reduce deployment costs relative to dense attention. ([scmp.com](https://www.scmp.com/tech/article/3343239/chinas-zhipu-ai-launches-new-major-model-glm-5-challenge-its-rivals))\\n\\n- A native “Agent Mode” is highlighted, enabling autonomous prompt transformation and source-material-to-output workflows (e.g., generating professional documents in .docx/.pdf/.xlsx formats). ([globenewswire.com](https://www.globenewswire.com/de/news-release/2026/02/13/3238012/0/en/index.html))\\n\\n- Benchmarking signals position GLM-5 as competitively strong among open models for coding and agentic tasks, with SWE-bench Verified scores around 77.8% and BrowseComp scores around 75.9, alongside strong results on other agentic benchmarks. ([huggingface.co](https://huggingface.co/zai-org/GLM-5))\\n\\n- In internal testing, GLM-5 reportedly surpasses Gemini 3 Pro on coding/agentic tasks and approaches Claude Opus 4.5 in certain metrics, though Anthropic’s Claude remains ahead on some coding benchmarks according to the release materials. ([scmp.com](https://www.scmp.com/tech/article/3343239/chinas-zhipu-ai-launches-new-major-model-glm-5-challenge-its-rivals))\\n\\n- Availability includes access through Z.ai’s platform and WaveSpeed API, with open weights published to Hugging Face, enabling community-led hosting and experimentation. ([glm5.net](https://glm5.net/))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '617_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Qureos raises $5 million in a seed round to accelerate its AI-driven hiring platform, with the round closed on February 4, 2026 in Dubai, UAE. Lead investors are Prosus Ventures and Salica Oryx Fund. ([qureos.com](https://www.qureos.com/updates/qureos-raises-5-million-seed))\\n- The funds are intended to deepen Qureos’ AI capabilities and hiring workflows, expand the go-to-market team, and accelerate geographic expansion through enterprise and agency partnerships. ([qureos.com](https://www.qureos.com/updates/qureos-raises-5-million-seed))\\n- The seed round includes participation from Oraseya Capital, PlusVC, F6 Ventures, BDev Ventures, Sunny Side Venture Partners, and Daniel Tyre, with follow-on investments from COTU Ventures and Globivest. ([qureos.com](https://www.qureos.com/updates/qureos-raises-5-million-seed))\\n- Qureos’ product center is Iris, an AI recruiter assistant that automates sourcing, screening, and interviewing; the platform taps into 2,000+ job boards and can screen candidates in under 15 seconds. ([qureos.com](https://www.qureos.com/updates/qureos-raises-5-million-seed))\\n- The founders are Alexander Epure (CEO) and Usama Nini (Co-founder). ([qureos.com](https://www.qureos.com/updates/qureos-raises-5-million-seed))\\n- Qureos reports traction with more than 1,000 enterprise and public-sector organizations; notable clients include Qatar Airways, Dubai Economy and Tourism, and Union Properties. ([qureos.com](https://www.qureos.com/updates/qureos-raises-5-million-seed))\\n- The platform is UAE-founded and oriented to the Gulf region (MENA) but operates globally, with stated expansion to the United States. ([qureos.com](https://www.qureos.com/updates/qureos-raises-5-million-seed))\\n- Independent coverage corroborates the seed round: CB Insights lists a $5M seed led by Prosus Ventures in February 2026. ([cbinsights.com](https://www.cbinsights.com/investor/prosus-ventures?utm_source=openai))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '618_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Farsight Vision announced a €7.2 million seed financing round to accelerate product development and scale delivery of its AI vision platform (announced Feb 13, 2026). ([kyivpost.com](https://www.kyivpost.com/post/70012?utm_source=openai))\\n\\n- Lead investors in the round were Axon Enterprise (USA) and Estonia’s SmartCap Defence Fund. ([kyivpost.com](https://www.kyivpost.com/post/70012?utm_source=openai))\\n\\n- Other participants included Radix Ventures (Poland), Anker Capital (Switzerland), Final Frontier (Denmark), with Resist.UA (Ukraine) and a follow-on from Darkstar (Estonia). ([kyivpost.com](https://www.kyivpost.com/post/70012?utm_source=openai))\\n\\n- The seed round amount (€7.2M) equates to roughly $8.6M at the time of reporting. ([kyivpost.com](https://www.kyivpost.com/post/70012?utm_source=openai))\\n\\n- Funds will be used to automate defense robotic systems for logistics, navigation, and weapons control; deepen integration with UAV/UGV manufacturers and battle-management systems; and enhance electronic warfare asset deployments. ([kyivpost.com](https://www.kyivpost.com/post/70012?utm_source=openai))\\n\\n- Farsight Vision operates as a Ukrainian-Estonian company with a footprint in Ukraine and Estonia; the Tallinn incorporation occurred in July 2024, and Brave1-cluster ties are noted. ([kyivpost.com](https://www.kyivpost.com/post/70012?utm_source=openai))\\n\\n- The round supports expansion beyond Ukraine, including partnerships across NATO countries and its first commercial contract in Asia. ([kyivpost.com](https://www.kyivpost.com/post/70012?utm_source=openai))\\n\\n- The platform provides real-time 3D terrain modeling from drone data and serves as an integration layer for mission planning, UAV/UGV coordination, and GNSS-denied environments. ([ukrinform.net](https://www.ukrinform.net/rubric-economy/4090812-ukrainianestonian-defense-startup-raises-eur-72m-in-investment.html?utm_source=openai))\\n\\n- The investment underscores ongoing European defense-tech funding activity, with involvement from public-safety and defense-focused investors and government-related support. ([kyivpost.com](https://www.kyivpost.com/post/70012?utm_source=openai))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '627_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Ricursive Intelligence disclosed a $300 million Series A at a $4 billion post-money valuation, bringing total funding to $335 million (including a $35 million seed) and confirming a public launch just months earlier. ([prnewswire.com](https://www.prnewswire.com/news-releases/ricursive-intelligence-raises-300-million-series-a-at-4-billion-valuation-to-accelerate-ai-driven-semiconductor-design-302670061.html))\\n\\n- The Series A was led by Lightspeed Venture Partners, with participation from DST Global, NVentures (NVIDIA’s VC arm), Felicis Ventures, 49 Palms Ventures, Radical AI, and Sequoia Capital. ([prnewswire.com](https://www.prnewswire.com/news-releases/ricursive-intelligence-raises-300-million-series-a-at-4-billion-valuation-to-accelerate-ai-driven-semiconductor-design-302670061.html))\\n\\n- The round occurred roughly two months after Ricursive’s public debut, which followed a seed round announced in December 2025. ([techcrunch.com](https://techcrunch.com/2026/01/26/ai-chip-startup-ricursive-hits-4b-valuation-two-months-after-launch/))\\n\\n- Seed funding: Ricursive Intelligence announced a $35 million seed round in December 2025 led by Sequoia Capital, valued at about $750 million at close. ([wvnews.com](https://www.wvnews.com/news/around_the_web/partners/pr_newswire/subject/new_products_services/ricursive-intelligence-launches-frontier-ai-lab-to-transform-semiconductor-design-and-accelerate-path-toward-artificial/article_dc7c4516-de58-5ad4-a8cd-16e25b9ce3d8.html))\\n\\n- Founders and background: Co-founders Anna Goldie (CEO) and Azalia Mirhoseini (CTO) previously worked together at Google Brain and were involved in AlphaChip, a project used in Google TPUs. ([techcrunch.com](https://techcrunch.com/2026/02/16/how-ricursive-intelligence-raised-335m-at-a-4b-valuation-in-4-months/))\\n\\n- Core product focus: Ricursive is building an AI-driven platform to design and iteratively improve AI chips, aiming to close the recursive loop between AI models and the hardware that runs them. ([prnewswire.com](https://www.prnewswire.com/news-releases/ricursive-intelligence-raises-300-million-series-a-at-4-billion-valuation-to-accelerate-ai-driven-semiconductor-design-302670061.html))\\n\\n- Technical scope: The platform is described as handling chip design tasks from component placement to design verification, and it envisions generating a silicon substrate through AI-driven workflows. ([techcrunch.com](https://techcrunch.com/2026/02/16/how-ricursive-intelligence-raised-335m-at-a-4b-valuation-in-4-months/))\\n\\n- Market position and customers: Nvidia is an investor, and the company’s stated target customers are chip makers and semiconductor-technology firms seeking automated, accelerated chip design. ([techcrunch.com](https://techcrunch.com/2026/01/26/ai-chip-startup-ricursive-hits-4b-valuation-two-months-after-launch/))\\n\\n- Location and status: Ricursive Intelligence is based in Palo Alto, California, described as a frontier AI lab advancing AI-driven semiconductor design. ([prnewswire.com](https://www.prnewswire.com/news-releases/ricursive-intelligence-raises-300-million-series-a-at-4-billion-valuation-to-accelerate-ai-driven-semiconductor-design-302670061.html))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '630_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Core development: Alibaba releases Qwen3.5-397B-A17B, the first open-weight flagship in the Qwen3.5 family, designed for agentic tasks with multimodal inputs; only about 17 billion of the total 397 billion parameters are active per forward pass. ([deeplearning.ai](https://www.deeplearning.ai/the-batch/qwen-announces-new-open-weights-flagship-update/?utm_source=openai))\\n\\n- Hybrid architecture: Qwen3.5 uses a hybrid design that combines sparse Mixture-of-Experts with linear attention via Gated Delta Networks to boost inference speed. ([dig.watch](https://dig.watch/updates/qwen3-5-397b-multimodal-ai-model-launch?utm_source=openai))\\n\\n- Multimodal inputs: The model is a native vision-language system supporting text, image, and video inputs, enabling multimodal reasoning and interaction. ([dig.watch](https://dig.watch/updates/qwen3-5-397b-multimodal-ai-model-launch?utm_source=openai))\\n\\n- Language expansion: Qwen3.5 expands multilingual coverage from 119 to 201 languages and dialects. ([dig.watch](https://dig.watch/updates/qwen3-5-397b-multimodal-ai-model-launch?utm_source=openai))\\n\\n- Context window: Qwen3.5-Plus offers a hosted option with a 1,000,000-token context window (native Qwen3.5 models expose substantial context capabilities as part of the platform). ([dig.watch](https://dig.watch/updates/qwen3-5-397b-multimodal-ai-model-launch?utm_source=openai))\\n\\n- Open weights availability: Weights for Qwen3.5 are openly available on HuggingFace and ModelScope for developers and organizations. ([deeplearning.ai](https://www.deeplearning.ai/the-batch/qwen-announces-new-open-weights-flagship-update/?utm_source=openai))\\n\\n- Efficiency and cost: Alibaba states Qwen3.5 is ~60% cheaper to run and delivers eightfold efficiency on large workloads relative to prior generations. ([mlq.ai](https://mlq.ai/news/alibaba-launches-qwen-35-ai-model-with-superior-efficiency-and-agentic-features/?utm_source=openai))\\n\\n- Hosted tooling and ecosystem: The Qwen3.5-Plus hosting via Alibaba Cloud Model Studio provides tool-use capabilities and large-context support for agentic workflows. ([dig.watch](https://dig.watch/updates/qwen3-5-397b-multimodal-ai-model-launch?utm_source=openai))\\n\\n- Additional technical context: Alibaba emphasizes asynchronous reinforcement learning and FP8 data pipelines as part of the training/inference efficiency story. ([dig.watch](https://dig.watch/updates/qwen3-5-397b-multimodal-ai-model-launch?utm_source=openai))',\n",
    "  'model_provider': 'openai'},\n",
    " {'event_id': '631_2026-02-16',\n",
    "  'news_date': '2026-02-16',\n",
    "  'output': '- Medicomp Systems unveiled a Model Context Protocol (MCP) layer to safely expose its APIs to AI models, enabling context-aware, clinically grounded AI workflows (diagnostic prompting, chart summarization, coding crosswalks, etc.). ([medicomp.com](https://medicomp.com/medicomp-systems-unveils-new-ai-enablement-tools-focused-on-delivering-clinically-validated-evidence-based-intelligence/))\\n\\n- The MCP layer grounds AI outputs in Medicomp’s clinical knowledge foundation, leveraging the Quippe Clinical Knowledge Graph and the MEDCIN graph database to enable clinically validated reasoning and prevent unvalidated data from being saved or exchanged. ([medicomp.com](https://medicomp.com/medicomp-systems-unveils-new-ai-enablement-tools-focused-on-delivering-clinically-validated-evidence-based-intelligence/))\\n\\n- Core elements include clinically validating outputs from conversational and ambient AI, recalling and manipulating data in clinical notes via natural language, and converting narrative text into trustworthy structured data across medical domains. ([medicomp.com](https://medicomp.com/medicomp-systems-unveils-new-ai-enablement-tools-focused-on-delivering-clinically-validated-evidence-based-intelligence/))\\n\\n- The MCP architecture aims to reduce variability and risk of unstructured AI output by removing PHI access from large language models and embedding AI interactions within existing clinical workflows. ([medicomp.com](https://medicomp.com/medicomp-systems-unveils-new-ai-enablement-tools-focused-on-delivering-clinically-validated-evidence-based-intelligence/))\\n\\n- Live capabilities highlighted by Medicomp include recalling lab results, filtering entire charts by problem, and analyzing charts against quality measures using voice commands or natural language. ([medicomp.com](https://medicomp.com/medicomp-systems-unveils-new-ai-enablement-tools-focused-on-delivering-clinically-validated-evidence-based-intelligence/))\\n\\n- Medicomp ties these capabilities to its Alchemy product, described as the first tooling to validate, clean, and normalize clinical data at scale, now integrated with MCP-enabled workflows. ([medicomp.com](https://medicomp.com/medicomp-systems-unveils-new-ai-enablement-tools-focused-on-delivering-clinically-validated-evidence-based-intelligence/))\\n\\n- Select MCP-enabled interactions are already live with customers, with broader expansion planned for 2026 and beyond, and live previews scheduled for ViVE 2026 and HIMSS26. ([medicomp.com](https://medicomp.com/medicomp-systems-unveils-new-ai-enablement-tools-focused-on-delivering-clinically-validated-evidence-based-intelligence/))\\n\\n- Quippe’s clinical data foundation rests on MEDCIN’s clinical knowledge graph, which comprises over 430,000 clinical concepts and hundreds of millions of relevancy links, plus about 10 million code mappings, enabling AI-enabled workflows across care domains. ([medicomp.com](https://medicomp.com/quippe-clinical-data-engine?utm_source=openai))',\n",
    "  'model_provider': 'openai'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be8e885a-009c-411c-898d-af3697425855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_research(research_json):\n",
    "    supabase.table('research_assistant').insert({\n",
    "        'event_id': research_json['event_id'],\n",
    "        'model_provider': research_json['model_provider'],\n",
    "        'news_date': research_json['news_date'],\n",
    "        'output': research_json['output']\n",
    "    }).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a3f166b-43f9-4311-8007-92681948922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n",
      "✅ Saved\n"
     ]
    }
   ],
   "source": [
    "for i in research_output_6:\n",
    "    save_research(i)\n",
    "    print(\"✅ Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2759ff57-79a7-4e87-9472-6f9100178185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event_id': '671_2026-02-18', 'news_date': '2026-02-18', 'output': '- Core development: NVIDIA and Meta announced a multiyear, multigenerational strategic partnership spanning on‑premises, cloud and AI infrastructure to deploy NVIDIA CPUs and millions of Blackwell and Rubin GPUs, with Spectrum-X Ethernet integrated for FBOSS; Mark Zuckerberg said the goal is to deliver “personal superintelligence” through expanded clusters using the Vera Rubin platform. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/Meta-Builds-AI-Infrastructure-With-NVIDIA/default.aspx))\\n\\n- Hyperscale data centers: Meta will build hyperscale data centers optimized for both training and inference in support of its long‑term AI infrastructure roadmap. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/Meta-Builds-AI-Infrastructure-With-NVIDIA/default.aspx))\\n\\n- Scale of deployment: The pact enables large‑scale deployment of NVIDIA CPUs and millions of NVIDIA Blackwell and Rubin GPUs across Meta’s infrastructure. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/Meta-Builds-AI-Infrastructure-With-NVIDIA/default.aspx))\\n\\n- Networking backbone: Meta will integrate NVIDIA Spectrum‑X Ethernet switches for its Facebook Open Switching System (FBOSS) platform to support AI‑scale networking. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/Meta-Builds-AI-Infrastructure-With-NVIDIA/default.aspx))\\n\\n- Grace and Vera CPUs: The collaboration will expand deployment of Arm‑based NVIDIA Grace CPUs for production workloads, including the first large‑scale Grace‑only deployment, with potential Vera CPU deployments in 2027. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/Meta-Builds-AI-Infrastructure-With-NVIDIA/default.aspx))\\n\\n- Unified architecture: Meta will deploy GB300‑based systems and create a unified architecture spanning on‑prem data centers and NVIDIA Cloud Partner deployments to simplify operations and boost performance. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/Meta-Builds-AI-Infrastructure-With-NVIDIA/default.aspx))\\n\\n- Privacy‑preserving AI: Meta has adopted NVIDIA Confidential Computing for WhatsApp private processing and will extend privacy‑preserving AI capabilities to additional Meta use cases. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/Meta-Builds-AI-Infrastructure-With-NVIDIA/default.aspx))\\n\\n- Codesign effort: Engineering teams at NVIDIA and Meta will engage in deep codesign to optimize next‑generation AI models across Meta’s core workloads. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/Meta-Builds-AI-Infrastructure-With-NVIDIA/default.aspx))\\n\\n- Rubin platform details: The Rubin platform comprises technologies including the Vera Rubin NVL72 rack‑scale system, Rubin GPU, NVLink 6 switch, ConnectX‑9 SuperNICs, BlueField‑4 DPU, Spectrum‑6 Ethernet, and accompanying confidential computing/RA S capabilities to enable agentic AI at scale. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/NVIDIA-Kicks-Off-the-Next-Generation-of-AI-With-Rubin--Six-New-Chips-One-Incredible-AI-Supercomputer/default.aspx))\\n\\n- Rubin rollout timeline: Rubin‑based products will be available from partners in the second half of 2026, with early deployments by AWS, Google Cloud, Microsoft, OCI, CoreWeave, and others. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2026/NVIDIA-Kicks-Off-the-Next-Generation-of-AI-With-Rubin--Six-New-Chips-One-Incredible-AI-Supercomputer/default.aspx))', 'model_provider': 'openai'}\n",
      "{'event_id': '678_2026-02-18', 'news_date': '2026-02-18', 'output': '- Gartner’s Feb 18, 2026 press release reports that 91% of customer service leaders feel executive pressure to implement AI in 2026, signaling urgent AI-enabled transformation. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))\\n- The release notes AI-driven transformation is reshaping frontline service models, with leaders emphasizing how AI and human expertise must work together. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))\\n- Nearly 80% of organizations plan to transition at least some frontline agents into new roles due to automation of routine tasks. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))\\n- 84% of leaders plan to add new skills to the agent role and adjust hiring profiles to support this shift. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))\\n- The survey analyzed 321 customer service and support leaders and was conducted in October 2025. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))\\n- Top 2026 priorities identified by respondents are improving customer satisfaction, boosting operational efficiency, and increasing self-service success. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))\\n- AI use aims include supporting first-contact resolution, reducing customer effort, and guiding customers through more seamless service journeys. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))\\n- As self-service scales, 58% of leaders aim to upskill agents into knowledge management specialists to support AI systems and customer self-service. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))\\n- Gartner cites the report title for the underlying data: 2026 Survey Results: Service and Support Leaders’ Goals and Game Plans. ([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2026-02-18-gartner-survey-finds-ninety-one-percent-of-customer-service-leaders-under-pressure-to-implement-ai-in-2026))', 'model_provider': 'openai'}\n",
      "{'event_id': '680_2026-02-18', 'news_date': '2026-02-18', 'output': '- Claude Sonnet 4.6 announced; core upgrade across coding, computer use, long-context reasoning, agent planning, knowledge work, and design, with a 1M token context window in beta. ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))\\n- For Free and Pro plans, Claude Sonnet 4.6 is the default model in Claude AI and Claude Cowork; pricing remains the same as Sonnet 4.5 (from $3/$15 per million tokens). ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))\\n- The 1M token context window can hold entire codebases, lengthy contracts, or dozens of research papers in a single request. ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))\\n- Safety evaluations report Sonnet 4.6 as as safe as or safer than other recent Claude models, with notes on strong safety behaviors. ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))\\n- On the Claude Developer Platform, Sonnet 4.6 supports adaptive thinking and extended thinking, plus context compaction in beta. ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))\\n- API updates include web search and fetch tools that automatically write and execute code to filter and process results; code execution, memory, programmatic tool calling, tool search, and tool use examples are generally available. ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))\\n- Claude in Excel users gain MCP connector support, enabling Claude to work with external data tools (e.g., S&P Global, LSEG, Daloopa, PitchBook, Moody’s, FactSet) from Excel. ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))\\n- Claude Sonnet 4.6 is available now across Claude plans, Claude Cowork, Claude Code, the API, and major cloud platforms; the free tier has been upgraded to Sonnet 4.6 by default. ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))\\n- Early customers report improvements in frontend code and financial analysis, with better visuals and fewer rounds of iteration compared to prior models. ([anthropic.com](https://www.anthropic.com/news/claude-sonnet-4-6))', 'model_provider': 'openai'}\n",
      "{'event_id': '681_2026-02-18', 'news_date': '2026-02-18', 'output': '- Kana emerges from stealth with a $15 million seed round led by Mayfield to build configurable, \"loosely coupled\" AI agents for marketers, with a focus on human-in-the-loop workflows and synthetic-data capabilities. ([techcrunch.com](https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/?utm_source=openai))\\n- The platform targets marketing tasks such as data analysis, audience targeting, campaign management, customer engagement, media planning, and optimization of AI-driven chatbots. ([techcrunch.com](https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/?utm_source=openai))\\n- Kana’s agents are designed to be assembled and tailored on the fly, can be integrated with legacy marketing stacks, and execute autonomous tracking, optimization, and reporting. ([techcrunch.com](https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/?utm_source=openai))\\n- A core capability is synthetic data generation to augment third-party data sources for market research and audience targeting. ([techcrunch.com](https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/?utm_source=openai))\\n- The platform is built to work with existing systems such as CRMs, CDPs, DSPs, and data warehouses. ([kana.ai](https://www.kana.ai/?utm_source=openai))\\n- Founders Tom Chavez (CEO) and Vivek Vaidya (CTO) bring prior ad-tech experience from Rapt (acquired by Microsoft) and Krux (acquired by Salesforce); Kana was incubated in the venture studio super{set} for nine months. ([techcrunch.com](https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/?utm_source=openai))\\n- Mayfield managing partner Navin Chaddha is joining Kana’s board as part of the seed round. ([techcrunch.com](https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/?utm_source=openai))\\n- The funding will be used to expand engineering, product, and go-to-market teams. ([techcrunch.com](https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/?utm_source=openai))\\n- Kana positions its approach as a flexible, agent-based alternative to monolithic marketing tools, aiming to reduce lock-in and accelerate customization for brands. ([techcrunch.com](https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/?utm_source=openai))', 'model_provider': 'openai'}\n",
      "{'event_id': '682_2026-02-18', 'news_date': '2026-02-18', 'output': '- Core new development: Ineffable Intelligence, a London-based AI startup led by David Silver, is reportedly close to raising a $1 billion seed round led by Sequoia, valuing the company at about $4 billion, per Financial Times reporting cited by The Economic Times on February 18, 2026. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/artificial-intelligence/former-google-deepmind-scientist-to-raise-1-billion-led-by-sequoia-for-superhuman-intelligence/articleshow/128513567.cms?from=mdr))\\n\\n- Seed-round milestone: If finalized, the deal would mark Europe’s largest-ever seed round to date. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/artificial-intelligence/former-google-deepmind-scientist-to-raise-1-billion-led-by-sequoia-for-superhuman-intelligence/articleshow/128513567.cms?from=mdr))\\n\\n- Lead and potential co-investors: Sequoia Capital is leading; Nvidia, Google, and Microsoft are said to be negotiating to participate. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/artificial-intelligence/former-google-deepmind-scientist-to-raise-1-billion-led-by-sequoia-for-superhuman-intelligence/articleshow/128513567.cms?from=mdr))\\n\\n- Focus and technology: The round is tied to Ineffable Intelligence’s emphasis on reinforcement learning to pursue “superhuman intelligence,” distinct from conventional large-language-model approaches. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/artificial-intelligence/former-google-deepmind-scientist-to-raise-1-billion-led-by-sequoia-for-superhuman-intelligence/articleshow/128513567.cms?from=mdr))\\n\\n- Founder background: David Silver is a former Google DeepMind lead (known for AlphaGo, AlphaZero, MuZero) who has left DeepMind to pursue his own venture. ([fortune.com](https://fortune.com/2026/01/30/google-deepmind-ai-researcher-david-silver-leaves-to-found-ai-startup-ineffable-intelligence/?queryly=related_article&utm_source=openai))\\n\\n- Formation and leadership timeline: Ineffable Intelligence was formed in November 2025, and Silver was appointed director on January 16, 2026. ([fortune.com](https://fortune.com/2026/01/30/google-deepmind-ai-researcher-david-silver-leaves-to-found-ai-startup-ineffable-intelligence/?queryly=related_article&utm_source=openai))\\n\\n- Location confirmation: The startup is based in London, aligning with the FT/ET reporting on the European seed-capital wake. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/artificial-intelligence/former-google-deepmind-scientist-to-raise-1-billion-led-by-sequoia-for-superhuman-intelligence/articleshow/128513567.cms?from=mdr))\\n\\n- Negotiation status: Terms are not finalized; negotiations are ongoing and could change. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/artificial-intelligence/former-google-deepmind-scientist-to-raise-1-billion-led-by-sequoia-for-superhuman-intelligence/articleshow/128513567.cms?from=mdr))\\n\\n- Related reporting context: The Economic Times’ coverage notes the FT as the original source for these seed-round claims; the Fortune piece corroborates the founder’s departure and formation timeline. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/artificial-intelligence/former-google-deepmind-scientist-to-raise-1-billion-led-by-sequoia-for-superhuman-intelligence/articleshow/128513567.cms?from=mdr))', 'model_provider': 'openai'}\n",
      "{'event_id': '683_2026-02-18', 'news_date': '2026-02-18', 'output': '- NPCI and Nvidia announce a collaboration to build a payments-native, sovereign AI foundation model for India’s payments ecosystem, leveraging Nvidia Nemotron open models and NPCI’s FiMI and UPI Help Assistant as starting points. ([business-standard.com](https://www.business-standard.com/industry/news/npci-partners-with-nvidia-to-build-sovereign-ai-infra-for-payments-126021801153_1.html?utm_source=openai))\\n- The effort aims to evolve from use-case agents to a foundational AI layer for payments, with emphasis on trust, resilience, security, multilingual capability, and alignment with India’s data sovereignty and regulatory requirements (MoE-era architectures under exploration). ([business-standard.com](https://www.business-standard.com/industry/news/npci-partners-with-nvidia-to-build-sovereign-ai-infra-for-payments-126021801153_1.html?utm_source=openai))\\n- Yotta and Nvidia outline deploying APAC’s largest DGX Cloud cluster in India: 20,736 NVIDIA Blackwell Ultra GPUs, with investments reportedly exceeding $2 billion and go-live targeted for August 2026. ([yotta.com](https://yotta.com/press-releases/yotta-to-deploy-20000-nvidia-blackwell-ultra-gpus/?utm_source=openai))\\n- The four-year engagement between Yotta and Nvidia is valued at over $1 billion to establish the DGX Cloud cluster within Yotta’s HGX B300 Blackwell Ultra supercluster (Greater Noida, with Navi Mumbai capacity). ([crnasia.com](https://www.crnasia.com/india/news/2026/yotta-to-deploy-20-736-nvidia-blackwell-ultra-gpus-in-over-2-billion-supercluster?utm_source=openai))\\n- Nvidia DGX Cloud Lepton will be expanded to include Yotta as a cloud partner; Lepton marketplace will connect developers to Nvidia’s global compute ecosystem, hosting DGX Cloud resources via Yotta’s infrastructure. ([investor.nvidia.com](https://investor.nvidia.com/news/press-release-details/2025/NVIDIA-Announces-DGX-Cloud-Lepton-to-Connect-Developers-to-NVIDIAs-Global-Compute-Ecosystem/default.aspx?utm_source=openai))\\n- As part of the Shakti Cloud initiative, Yotta/NVIDIA launched a project to train an Indian-language LLM on DGX Cloud Lepton, developed under the IndiaAI Mission and targeting sovereign AI capabilities for India (e.g., Sarvam’s involvement). ([yotta.com](https://yotta.com/media/yotta-and-nvidia-launch-shakti-cloud-on-dgx-cloud-lepton-to-power-indias-sovereign-ai-ambitions/?utm_source=openai))\\n- NPCI’s existing AI stack includes FiMI (Financial Model for India) and the UPI Help Assistant, with the new collaboration intended to scale these capabilities into a foundational AI platform for payments. ([business-standard.com](https://www.business-standard.com/industry/news/npci-partners-with-nvidia-to-build-sovereign-ai-infra-for-payments-126021801153_1.html?utm_source=openai))\\n- The collaboration leverages Nvidia’s Nemotron family and NeMo framework, with architecture discussions including MoE to support high-volume, low-latency payment environments and multilingual data expansion. ([nvidianews.nvidia.com](https://nvidianews.nvidia.com/news/nvidia-launches-family-of-open-reasoning-ai-models-for-developers-and-enterprises-to-build-agentic-ai-platforms?utm_source=openai))\\n- The India AI Impact Summit 2026 served as the public venue for these announcements, with coverage noting NPCI/Nvidia activities around the February 18, 2026 timeframe. ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/city/ahmedabad/conference-on-ai-for-governance-held-in-gnagar/articleshow/125919935.cms?utm_source=openai))', 'model_provider': 'openai'}\n",
      "{'event_id': '685_2026-02-18', 'news_date': '2026-02-18', 'output': '- World Labs secures $200 million from Autodesk as part of a $1 billion funding round to integrate World Labs’ world models into Autodesk’s 3D workflows (announcement published Feb 18, 2026). ([techcrunch.com](https://techcrunch.com/2026/02/18/world-labs-lands-200m-from-autodesk-to-bring-world-models-into-3d-workflows/))\\n- The $1B round includes backers such as AMD, Emerson Collective, Fidelity Management & Research Company, Nvidia, and others, with Autodesk contributing $200M. ([techcrunch.com](https://techcrunch.com/2026/02/18/world-labs-lands-200m-from-autodesk-to-bring-world-models-into-3d-workflows/))\\n- Autodesk will serve as an adviser to World Labs and the two companies will collaborate at the research and model level, starting with entertainment use cases; data sharing is not part of the agreement. ([techcrunch.com](https://techcrunch.com/2026/02/18/world-labs-lands-200m-from-autodesk-to-bring-world-models-into-3d-workflows/))\\n- World Labs’ first commercial world model product, Marble, launched in November 2025, enabling text/image/video prompts to create editable, downloadable 3D environments across freemium and paid tiers. ([techcrunch.com](https://techcrunch.com/2025/11/12/fei-fei-lis-world-labs-speeds-up-the-world-model-race-with-marble-its-first-commercial-product/))\\n- Marble generates persistent, downloadable 3D environments rather than on-the-fly worlds, with export options including Gaussian splats, meshes, or videos. ([techcrunch.com](https://techcrunch.com/2025/11/12/fei-fei-lis-world-labs-speeds-up-the-world-model-race-with-marble-its-first-commercial-product/))\\n- Marble includes AI-native editing tools and a hybrid 3D editor; features like Chisel (coarse layout editing) and composer mode let users structure spaces before detailing. ([techcrunch.com](https://techcrunch.com/2025/11/12/fei-fei-lis-world-labs-speeds-up-the-world-model-race-with-marble-its-first-commercial-product/))\\n- World Labs sits in a broader “world models”/spatial intelligence category, with competitors like Google DeepMind and Runway; initial go-to-market emphasis is on gaming and interactive entertainment. ([techcrunch.com](https://techcrunch.com/2026/02/18/world-labs-lands-200m-from-autodesk-to-bring-world-models-into-3d-workflows/))\\n- The latest round’s impact on World Labs’ valuation was not disclosed; Bloomberg reported a month prior that the company was targeting a valuation around $5 billion. ([techcrunch.com](https://techcrunch.com/2026/02/18/world-labs-lands-200m-from-autodesk-to-bring-world-models-into-3d-workflows/))\\n- Autodesk’s involvement aligns with its broader AI strategy, including neural CAD and expanding AI features across its design and workflows portfolio. ([techcrunch.com](https://techcrunch.com/2026/02/18/world-labs-lands-200m-from-autodesk-to-bring-world-models-into-3d-workflows/))', 'model_provider': 'openai'}\n",
      "{'event_id': '686_2026-02-18', 'news_date': '2026-02-18', 'output': '- Zyphra announced ZUNA, a 380M-parameter diffusion autoencoder EEG foundation model aimed at advancing thought-to-text capabilities in noninvasive BCIs. ([prnewswire.com](https://www.prnewswire.com/news-releases/zyphra-releases-zuna---bci-foundation-model-advancing-towards-thought-to-text-302691176.html?utm_source=openai))\\n- ZUNA is designed to denoise, reconstruct missing EEG channels, and upsample scalp signals given a subset of channels, enabling higher-fidelity brain data from partial measurements. ([huggingface.co](https://huggingface.co/Zyphra/ZUNA?utm_source=openai))\\n- The model was trained on approximately 2 million channel-hours of EEG data drawn from publicly available sources. ([huggingface.co](https://huggingface.co/Zyphra/ZUNA?utm_source=openai))\\n- ZUNA is engineered to work across a wide range of EEG systems, from consumer headsets to 256-electrode research setups, without retraining. ([prnewswire.com](https://www.prnewswire.com/news-releases/zyphra-releases-zuna---bci-foundation-model-advancing-towards-thought-to-text-302691176.html?utm_source=openai))\\n- In evaluations, ZUNA outperforms spherical-spline interpolation (the industry-standard method in MNE) at higher scaling/dropout scenarios. ([prnewswire.com](https://www.prnewswire.com/news-releases/zyphra-releases-zuna---bci-foundation-model-advancing-towards-thought-to-text-302691176.html?utm_source=openai))\\n- ZUNA is released as open-source software under the Apache 2.0 license; model weights are available on Hugging Face, with inference code on GitHub and a pip package (zuna). ([prnewswire.com](https://www.prnewswire.com/news-releases/zyphra-releases-zuna---bci-foundation-model-advancing-towards-thought-to-text-302691176.html?utm_source=openai))\\n- Zyphra positions ZUNA as laying a technical foundation for future thought-to-text models that would interpret brain signals noninvasively via BCIs. ([prnewswire.com](https://www.prnewswire.com/news-releases/zyphra-releases-zuna---bci-foundation-model-advancing-towards-thought-to-text-302691176.html?utm_source=openai))\\n- The release invites collaboration with researchers and organizations; contact information is provided in the announcement. ([prnewswire.com](https://www.prnewswire.com/news-releases/zyphra-releases-zuna---bci-foundation-model-advancing-towards-thought-to-text-302691176.html?utm_source=openai))\\n- ZUNA’s technical design includes 4D spatial embeddings (electrode coordinates in space plus time) within a diffusion/transformer framework to handle heterogeneous electrode layouts. ([prnewswire.com](https://www.prnewswire.com/news-releases/zyphra-releases-zuna---bci-foundation-model-advancing-towards-thought-to-text-302691176.html?utm_source=openai))', 'model_provider': 'openai'}\n",
      "{'event_id': '691_2026-02-18', 'news_date': '2026-02-18', 'output': '- Core development: Microsoft says it is on pace to invest $50 billion by the end of the decade to expand AI across the Global South, announced at the AI Impact Summit in New Delhi on February 18, 2026. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))\\n- Investment framework: The $50 billion commitment will be deployed through a five-part program focused on infrastructure, skilling, multilingual AI development, local AI innovations, and measuring AI adoption. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))\\n- Global South definition: Microsoft notes the Global South consists of developing, emerging, or lower-income countries, primarily in the southern hemisphere. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))\\n- India-specific commitments: In India, the company will train 5.6 million people in 2025 and aims to equip 20 million Indians with AI skills by 2030, including through Elevate for Educators to support two million teachers across more than 200,000 institutions. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))\\n- India’s prior investment: Microsoft announced $17.5 billion in AI investments in India last year as part of its broader India cloud/AI expansion. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))\\n- Global South datacenter spend: The company said it invested more than $8 billion in datacenter infrastructure serving the Global South in its last fiscal year. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))\\n- Internet access and outreach: Microsoft aims to extend internet access to 250 million people in underserved communities, including 100 million in Africa, with 117 million Africans already reached through partnerships. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))\\n- AI diffusion gap: Microsoft highlighted an AI adoption gap, noting that in the second half of 2025, 25% of the global north working-age population used AI versus 14% in the Global South. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))\\n- Multilingual and research initiatives: The plan includes expanding multilingual AI systems and collaboration with Indian institutions on AI evaluation/tools and content provenance standards with C2PA, including support for multiple Indic languages. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/tech/technology/microsoft-says-on-pace-to-invest-50-billion-by-2030-end-across-global-south/articleshow/128492661.cms/))', 'model_provider': 'openai'}\n",
      "{'event_id': '695_2026-02-18', 'news_date': '2026-02-18', 'output': '- On February 17, 2026, JFB Construction Holdings and XTEND announced a definitive all-stock merger to form a Nasdaq-listed XTEND AI Robotics (XTND) with an implied value of about $1.5 billion and a closing targeted for mid-2026. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/17/3239376/0/en/jfb-and-xtend-announce-1-5b-business-combination-to-establish-a-nasdaq-listed-us-leader-in-ai-driven-autonomous-defense-robotics.html?utm_source=openai))\\n\\n- Post-close, XTEND shareholders are expected to own roughly 70% and JFB about 30% of XTEND AI Robotics on a fully diluted basis, with the combined company trading on Nasdaq under the ticker XTND. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/17/3239376/0/en/JFB-and-XTEND-Announce-1-5B-Business-Combination-to-Establish-a-Nasdaq-Listed-US-Leader-in-AI-Driven-Autonomous-Defense-Robotics.html?utm_source=openai))\\n\\n- The combined company will be headquartered in Tampa, Florida, with an established production facility there. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/17/3239376/0/en/JFB-and-XTEND-Announce-1-5B-Business-Combination-to-Establish-a-Nasdaq-Listed-US-Leader-in-AI-Driven-Autonomous-Defense-Robotics.html?utm_source=openai))\\n\\n- XTEND AI Robotics will be an AI-driven autonomous defense and security robotics company anchored by XTEND’s AI XTEND Operating System (XOS), enabling remote, multi-domain drone missions with immediate readiness. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/17/3239376/0/en/JFB-and-XTEND-Announce-1-5B-Business-Combination-to-Establish-a-Nasdaq-Listed-US-Leader-in-AI-Driven-Autonomous-Defense-Robotics.html?utm_source=openai))\\n\\n- Strategic investors named in the merger include Eric Trump, Unusual Machines, American Ventures, Protego Ventures, Aliya Capital, and Agostinelli Group. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/17/3239376/0/en/JFB-and-XTEND-Announce-1-5B-Business-Combination-to-Establish-a-Nasdaq-Listed-US-Leader-in-AI-Driven-Autonomous-Defense-Robotics.html?utm_source=openai))\\n\\n- JFB completed a concurrent private placement of 802,000 shares at $12.50 per share, generating approximately $10.0 million gross and about $9.2 million net proceeds, earmarked to support the investment in XTEND. ([stocktitan.net](https://www.stocktitan.net/sec-filings/JFB/425-jfb-construction-holdings-business-combination-communication-db5f1f93727a.html?utm_source=openai))\\n\\n- The transaction envisions a two-step structure with a Form S-4 registration; the closing is expected in mid-2026, subject to customary conditions and regulatory approvals (including CFIUS) and Nasdaq listing. ([stocktitan.net](https://www.stocktitan.net/sec-filings/JFB/425-jfb-construction-holdings-business-combination-communication-db5f1f93727a.html?utm_source=openai))\\n\\n- Advisors: Stifel is the exclusive financial advisor and capital markets advisor to XTEND; Paul Hastings LLP is legal counsel to XTEND; Dominari Securities is the exclusive placement agent to JFB. ([paulhastings.com](https://www.paulhastings.com/news/paul-hastings-advising-xtend-on-usd1-5-billion-business-combination-with-jfb?utm_source=openai))\\n\\n- Market reaction to the announcement saw JFB’s stock trading down materially as investors weighed the strategic pivot and valuation implications. ([investing.com](https://www.investing.com/news/stock-market-news/jfb-construction-stock-plunges-after-merger-with-defense-tech-firm-xtend-93CH-4509308?utm_source=openai))', 'model_provider': 'openai'}\n",
      "{'event_id': '696_2026-02-18', 'news_date': '2026-02-18', 'output': '- The core new development: The U.S. military reportedly used Anthropic’s Claude in the Maduro operation in Venezuela (via Anthropic’s Palantir channel), and the Pentagon is reviewing its partnership with Anthropic amid dispute over permissible uses. ([yahoo.com](https://www.yahoo.com/news/articles/us-used-anthropics-claude-during-234152188.html?utm_source=openai))\\n\\n- Key point of contention: The DoD is seeking rights to use AI models for “all lawful use cases,” including on classified networks, pushing four major vendors (including Anthropic) to loosen usage restrictions. ([yahoo.com](https://www.yahoo.com/news/articles/us-used-anthropics-claude-during-234152188.html?utm_source=openai))\\n\\n- Anthropic’s position: The company is pushing carve-outs to prohibit fully autonomous weapons and mass domestic surveillance, and has not agreed to an “all lawful uses” contract as drafted by the DoD. ([axios.com](https://www.axios.com/2026/02/13/anthropic-claude-maduro-raid-pentagon?utm_source=openai))\\n\\n- Government procurement context: DoD awarded up to $200 million in contracts for AI development to Anthropic and peers (Google, OpenAI, xAI) as part of accelerating frontier-AI capabilities for national security. ([cnbc.com](https://www.cnbc.com/2025/07/14/anthropic-google-openai-xai-granted-up-to-200-million-from-dod.html?utm_source=openai))\\n\\n- Government-targeted product line: Anthropic has publicly launched Claude Gov (June 2025) as a government/intelligence-focused variant with looser guardrails for handling classified or sensitive tasks. ([theverge.com](https://www.theverge.com/ai-artificial-intelligence/680465/anthropic-claude-gov-us-government-military-ai-model-launch?utm_source=openai))\\n\\n- Operational implications: The Maduro raid reports underscore tensions about whether Claude can or should be used in high-stakes, classified operations, given Anthropic’s safeguard policies. ([theguardian.com](https://www.theguardian.com/technology/2026/feb/14/us-military-anthropic-ai-model-claude-venezuela-raid?utm_source=openai))\\n\\n- Status and risk to the contract: By mid-February 2026, DoD officials were signaling a potential reevaluation of the Anthropic relationship, with talk of terminating or reworking the $200 million agreement. ([semafor.com](https://www.semafor.com/article/02/17/2026/palantir-partnership-is-at-heart-of-anthropic-pentagon-rift?utm_source=openai))\\n\\n- Market context among peers: OpenAI, Google, and xAI have faced different negotiation stances on “all lawful uses,” highlighting a broader industry negotiation trend for government deployments. ([cnbc.com](https://www.cnbc.com/2025/07/14/anthropic-google-openai-xai-granted-up-to-200-million-from-dod.html?utm_source=openai))\\n\\n- Company response: Anthropic has stated it is engaging in productive conversations on usage policies and is not commenting on specific operations, emphasizing its safety and governance posture. ([axios.com](https://www.axios.com/2026/02/13/anthropic-claude-maduro-raid-pentagon?utm_source=openai))', 'model_provider': 'openai'}\n",
      "{'event_id': '700_2026-02-18', 'news_date': '2026-02-18', 'output': '- Yotta Data Services plans to build Asia’s largest AI computing hub in India, using Nvidia’s Blackwell Ultra GPUs, with a total project cost above $2 billion and a four-year Nvidia DGX Cloud engagement worth over $1 billion; the facility is expected to go live by August 2026. ([livemint.com](https://www.livemint.com/companies/news/indian-firm-yotta-to-build-2-billion-data-centre-with-nvidias-blackwell-chips-one-of-asias-largest-ai-hubs-11771389615200.html?utm_source=openai))\\n\\n- The AI hub will be hosted at Yotta’s Greater Noida hyperscale campus (60 MW D2), with capacity scalable to 250 MW, and additional capacity from Navi Mumbai (scalable to about 2 GW). ([yotta.com](https://yotta.com/press-releases/yotta-to-deploy-20000-nvidia-blackwell-ultra-gpus/?utm_source=openai))\\n\\n- The deployment includes 20,736 liquid-cooled Nvidia Blackwell Ultra GPUs as the core compute for the supercluster, targeting go-live by August 2026. ([yotta.com](https://yotta.com/press-releases/yotta-to-deploy-20000-nvidia-blackwell-ultra-gpus/?utm_source=openai))\\n\\n- Nvidia will anchor a four-year DGX Cloud engagement within Yotta’s infrastructure, creating one of Asia-Pacific’s largest DGX Cloud clusters in India, valued at over $1 billion. ([business-standard.com](https://www.business-standard.com/technology/tech-news/nvidia-yotta-partner-to-deploy-apac-s-largest-dgx-cloud-cluster-in-india-126021800363_1.html/?utm_source=openai))\\n\\n- The DGX Cloud cluster is planned to operate inside Yotta’s infrastructure, reflecting a major APAC DGX Cloud deployment in India. ([business-standard.com](https://www.business-standard.com/technology/tech-news/nvidia-yotta-partner-to-deploy-apac-s-largest-dgx-cloud-cluster-in-india-126021800363_1.html/?utm_source=openai))\\n\\n- The AI supercluster uses Nvidia’s reference architecture and includes 800 Gbps Quantum-X800 InfiniBand networking, advanced liquid cooling, and more than 40 petabytes of high-performance storage to support frontier-scale workloads. ([business-standard.com](https://www.business-standard.com/technology/tech-news/nvidia-yotta-partner-to-deploy-apac-s-largest-dgx-cloud-cluster-in-india-126021800363_1.html/?utm_source=openai))\\n\\n- Shakti Studio AI platform will integrate Nvidia Nemotron open models, NIM microservices, and access to Nvidia AI Enterprise software. ([business-standard.com](https://www.business-standard.com/technology/tech-news/nvidia-yotta-partner-to-deploy-apac-s-largest-dgx-cloud-cluster-in-india-126021800363_1.html/?utm_source=openai))\\n\\n- Over 10,000 Nvidia GPUs are currently in production at Yotta, with about 8,000 more GPUs expected to go live in the next quarter, as part of a plan to scale beyond 80,000 Nvidia GPUs by FY27. ([yotta.com](https://yotta.com/press-releases/yotta-to-deploy-20000-nvidia-blackwell-ultra-gpus/?utm_source=openai))\\n\\n- Separately, Nvidia and Yotta have previously indicated initiatives to scale Yotta’s GPU infrastructure and provide sovereign AI capabilities through India-focused programs like IndiaAI Mission. ([business-standard.com](https://www.business-standard.com/technology/tech-news/nvidia-yotta-partner-to-deploy-apac-s-largest-dgx-cloud-cluster-in-india-126021800363_1.html/?utm_source=openai))', 'model_provider': 'openai'}\n",
      "{'event_id': '703_2026-02-18', 'news_date': '2026-02-18', 'output': '- Cogent Security announced a $42 million Series A led by Bain Capital Ventures, with Greylock Partners and Definition participating; total funding now $53 million. The news was reported as Fortune’s exclusive on February 18, 2026. ([fortune.com](https://fortune.com/2026/02/18/exclusive-bain-and-greylock-bet-42-million-that-ai-agents-can-finally-fix-cybersecuritys-messiest-bottleneck//?utm_source=openai))\\n\\n- Enrique Salem will join Cogent’s Board of Directors as part of the round, per the company’s disclosures. ([cogent.com](https://www.cogent.com/blog/cogent-security-raises-42m-series-a?utm_source=openai))\\n\\n- Cogent is presenting an AI-native vulnerability-management platform that uses autonomous AI agents to handle end-to-end remediation tasks, including investigation, ownership assignment, risk assessment, remediation steps, and tracking to verified completion. ([cogent.com](https://www.cogent.com/blog/cogent-security-raises-42m-series-a?utm_source=openai))\\n\\n- All agent actions are designed to be traceable and auditable, operating under configurable approval gates and policy enforcement. ([cogent.com](https://www.cogent.com/blog/cogent-security-raises-42m-series-a?utm_source=openai))\\n\\n- The company reports an average 97% reduction in exposure windows for critical risks among paying customers. ([cogent.com](https://www.cogent.com/blog/cogent-security-raises-42m-series-a?utm_source=openai))\\n\\n- Dozens of Fortune 1000 and Global 2000 enterprises are already customers, with Cogent aiming to expand deployments significantly in the near term. ([fortune.com](https://fortune.com/2026/02/18/exclusive-bain-and-greylock-bet-42-million-that-ai-agents-can-finally-fix-cybersecuritys-messiest-bottleneck//?utm_source=openai))\\n\\n- The funding round follows Cogent’s July 2025 launch from stealth, with the new capital intended to accelerate product development and enterprise deployments. ([businesswire.com](https://www.businesswire.com/news/home/20250714138382/en/Cogent-Security-Launches-From-Stealth-With-%2411M-From-Greylock-Partners-to-Transform-Vulnerability-Management-With-Agentic-AI?utm_source=openai))\\n\\n- The round’s investors include Bain Capital Ventures (lead) and Greylock Partners, with Definition participating; founders and executives from OpenAI, Abnormal Security, and Datadog also invested personally. ([fortune.com](https://fortune.com/2026/02/18/exclusive-bain-and-greylock-bet-42-million-that-ai-agents-can-finally-fix-cybersecuritys-messiest-bottleneck//?utm_source=openai))\\n\\n- Cogent plans to use the proceeds to expand beyond vulnerability management into broader security operations and IT automation workloads, and to scale its go-to-market team. ([fortune.com](https://fortune.com/2026/02/18/exclusive-bain-and-greylock-bet-42-million-that-ai-agents-can-finally-fix-cybersecuritys-messiest-bottleneck//?utm_source=openai))\\n\\n- Context: Cogent positions its AI agents to address the “execution gap” in vulnerability management, a problem driven by tens of thousands of new CVEs annually and faster attacker times, according to the company’s materials. ([cogent.com](https://www.cogent.com/blog/cogent-security-raises-42m-series-a?utm_source=openai))', 'model_provider': 'openai'}\n",
      "{'event_id': '704_2026-02-18', 'news_date': '2026-02-18', 'output': '- Circuit announced a $30 million funding round from individual investors, disclosed on February 18, 2026, described as one of Texas’s largest angel rounds. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- The round’s investor roster includes Jim Breyer, Charlie Amato, Lew Cirne, Niccolo De Masi, Tom Long, Gary Petersen, Gary Rieschel, and Craig Robins. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- Circuit was founded by Silicon Labs veterans, including former CEO Tyson Tuttle, who serves as co-founder and CEO. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- Circuit is an Austin-based AI platform aimed at manufacturing and service organizations, turning technical documentation into guided execution workflows. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- The platform translates documents like manuals, CAD files, and exploded views into actionable workflows and integrates with enterprise tools such as ERPs, quoting tools, and CRMs. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- Circuit relies on proprietary reasoning to interpret configuration logic, compatibility rules, and technical dependencies to guide user actions. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- Notable early adopters cited by Circuit include Culligan and Four Hands, with reported benefits like faster quoting, fewer errors, and rapid ramp of new hires. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- The new funds are earmarked for continued product development, expanded customer deployments, and hiring across engineering and go-to-market teams. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- Deloitte and The Manufacturing Institute are cited in Circuit’s release as estimating up to 1.9 million manufacturing jobs could be unfilled by 2033, highlighting market demand for scalable expertise. ([prnewswire.com](https://www.prnewswire.com/news-releases/circuit-raises-30m-to-bring-purpose-built-ai-into-manufacturing-and-service-operations-302689905.html?utm_source=openai))\\n- Independent coverage from CityBiz corroborates the $30 million round and lists the same high-profile angels/early investors, with the report published around the same date. ([citybiz.co](https://www.citybiz.co/article/808066/austin-ai-startup-circuit-raises-30m/?utm_source=openai))', 'model_provider': 'openai'}\n",
      "{'event_id': '709_2026-02-18', 'news_date': '2026-02-18', 'output': '- GPT‑5.3‑Codex‑Spark is OpenAI’s ultra‑fast real‑time coding model—a smaller variant of GPT‑5.3‑Codex designed for near‑instant interactive coding, with a 128k context window and text‑only input/output, released as a research preview and governed by separate rate limits. ([openai.com](https://openai.com/index/introducing-gpt-5-3-codex-spark/?utm_source=openai))\\n\\n- Spark reportedly delivers 1000+ tokens per second when served on Cerebras Wafer Scale Engine 3 (WSE‑3), marking the first production deployment of OpenAI workloads on Cerebras hardware as part of a new Cerebras partnership. ([openai.com](https://openai.com/index/introducing-gpt-5-3-codex-spark/?utm_source=openai))\\n\\n- Availability: Spark is rolling out today as a research preview for ChatGPT Pro users, accessible via the Codex app, the CLI, and the VS Code extension; API access is limited to a small set of design partners during the preview. ([openai.com](https://openai.com/index/introducing-gpt-5-3-codex-spark/?utm_source=openai))\\n\\n- Latency optimizations: End‑to‑end latency improvements include an 80% reduction in client/server roundtrip overhead, a 30% reduction in per‑token overhead, and a 50% faster time‑to‑first‑token, with a persistent WebSocket path enabled by default. ([openai.com](https://openai.com/index/introducing-gpt-5-3-codex-spark/?utm_source=openai))\\n\\n- Real‑time collaboration focus: Spark is engineered for real‑time coding workflows, enabling targeted edits, rapid refactoring of logic, and immediate feedback in live coding scenarios. ([openai.com](https://openai.com/index/introducing-gpt-5-3-codex-spark/?utm_source=openai))\\n\\n- Contextual and safety posture: Spark is text‑only with a 128k context window and uses the same safety training as mainline models; it did not reach the Preparedness Framework’s high capability threshold for cybersecurity or biology in evaluation. ([openai.com](https://openai.com/index/introducing-gpt-5-3-codex-spark/?utm_source=openai))\\n\\n- Model relationship: Spark is described as a lean, faster variant of GPT‑5.3‑Codex intended specifically for rapid interaction, complementary to the flagship Codex model. ([openai.com](https://openai.com/index/introducing-gpt-5-3-codex-spark/?utm_source=openai))\\n\\n- Deployment context and partner news: Spark’s Cerebras deployment signals OpenAI’s diversification away from Nvidia hardware and marks a milestone in the OpenAI–Cerebras collaboration announced earlier in January. ([openai.com](https://openai.com/index/introducing-gpt-5-3-codex-spark/?utm_source=openai))\\n\\n- Coverage and timing: The announcement and speed claims were widely reported by outlets such as TechCrunch, Ars Technica, Forbes, and Tom’s Hardware, noting the Cerebras‑powered inference and the 1,000+ token/second capability. ([techcrunch.com](https://techcrunch.com/2026/02/12/a-new-version-of-openais-codex-is-powered-by-a-new-dedicated-chip/?utm_source=openai))', 'model_provider': 'openai'}\n"
     ]
    }
   ],
   "source": [
    "for i in research_output_6:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b56b3-74ac-4249-b962-d642c3fb302e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08cc43-f141-4684-90cd-440eeb92266d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c256f-30fb-4be1-b390-a578ce0383ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
