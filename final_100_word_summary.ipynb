{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e03c6762-d549-41b9-9626-a13c036d513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32c74859-d3a7-4b4a-8733-73fb62957b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49f987bc-22b0-494b-b4fa-95c2c021a289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32742f35-b225-4c11-b482-439da97a654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_anthropic = anthropic.Anthropic(api_key = os.getenv('CLAUDE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e043985-348f-4979-a55b-f7d77253c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0bcadd75-0e0e-43bb-bcba-abe684a14a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bd8ca7c-5faa-470b-abbd-b44c53dd0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "601f417d-fddd-42c3-a980-36c0eeb1b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase_api_key = os.environ.get(\"SUPBASE_KEY\")\n",
    "supabase_url = os.environ.get(\"SUPABASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8265b097-8e0e-4e4d-a4b4-cd3365b45c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase: Client = create_client(supabase_url, supabase_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b68170f0-a428-4492-867e-14edb0c29f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "researched_data = [{'event_id': '299_2026-02-08',\n",
    "  'news_date': '2026-02-08',\n",
    "  'output': '- Verified: The earbuds rumor centers on an internal code name for OpenAI’s first consumer hardware device being Sweetpea. Multiple credible outlets report this codename as part of the leak cycle about the device. ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n\\n- Verified: Several credible outlets note that the project is not officially confirmed and remains a leak/rumor at this time. TechCrunch explicitly describes the details as coming from leaks and “tipsters,” not an official OpenAI confirmation; Axios likewise characterizes the information as rumors shared at Davos. ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n\\n- Verified: The same reporting that mentions Sweetpea also references a potential second consumer device codenamed Gumdrop in the rumor mill. ([axios.com](https://www.axios.com/2026/01/23/openai-device-earbuds-sweetpea-altman))\\n\\n- Added confirmed hardware context: OpenAI disclosed at Davos that it is building a new AI device, though details remain scarce. Timeline given by OpenAI officials in these discussions points to a likely release in the second half of 2026. ([axios.com](https://www.axios.com/2026/01/23/openai-device-earbuds-sweetpea-altman))\\n\\n- Confirmed: OpenAI’s prior hardware efforts are linked to its 2025 acquisition of Jony Ive’s design firm io (the deal was reported to be around $6.5 billion). Ive is associated with leading the hardware design work for the product family. ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n\\n- Confirmed: OpenAI’s hardware plans discussed publicly have included a screen-free, pocketable device concept as part of the early product narrative. ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n\\n- Confirmed: Reported design descriptions for the Sweetpea concept include a main unit described as metal and egg-shaped, with two pill-shaped modules that would sit behind the ear. These details appear in multiple outlets drawing on the same leaks. ([indianexpress.com](https://indianexpress.com/article/technology/tech-news-technology/openai-x-jony-ive-wireless-earbuds-unique-design-launch-2026-10471143/))\\n\\n- Confirmed (design details corroborated by multiple outlets): The rumored hardware would reportedly use a 2-nanometer-class processor (with Exynos as a favored reference) for on-device AI tasks, aligned with the “phone-like” compute ambitions discussed in the leaks. ([indianexpress.com](https://indianexpress.com/article/technology/tech-news-technology/openai-x-jony-ive-wireless-earbuds-unique-design-launch-2026-10471143/))\\n\\n- Confirmed (manufacturing partner context): Reports mention Foxconn as a manufacturing partner for the OpenAI devices, with some mention of Luxshare as a possibility; this is described in the leakage coverage and echoed by outlets citing Asian reporting. ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n\\n- Confirmed: First-year shipment targets cited in the leaks are in the 40–50 million units range, with September 2026 as a possible launch window in at least some outlets. ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n\\n- Confirmed (scope/roadmap detail in leaks): Some leakage coverage claims OpenAI is planning a broader hardware roadmap (up to five devices by 2028), with Sweetpea at the front of that lineup. This detail appears in multiple leak-focused outlets. ([androidauthority.com](https://www.androidauthority.com/openai-earbuds-3631925/))\\n\\n- Not corroborated by credible outlets (branding name caveat): The claim that the consumer-facing name will be “Dime” lacks confirmation from established major outlets. Some blogs and tech sites have floated “Dime” as branding based on patent filings or rumor chatter, but there is no widely credited report in outlets like TechCrunch, Axios, or The Indian Express confirming “Dime.” Examples of circulating but less-established sources include Gizmochina and other aggregators. ([gizmochina.com](https://www.gizmochina.com/2026/02/07/openais-first-hardware-device-ai-earbuds-strategy-shift-and-launch-timeline/?utm_source=openai))\\n\\n- Note on the current status of confirmation: The available reporting from January–February 2026 consistently describes the information as leaks/rumors rather than official confirmation; OpenAI executives acknowledged work on a hardware device but kept specifics (design, branding, features) under wraps. ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n\\nSources referenced above (examples of main reporting):\\n- TechCrunch: OpenAI aims to ship its first device in 2026, and it could be earbuds (codename Sweetpea; design, chip, and unit targets discussed). ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n- Indian Express: OpenAI’s first product could be ChatGPT-powered earbuds; codename Sweetpea; design details and 2nm Samsung Exynos chip mentioned. ([indianexpress.com](https://indianexpress.com/article/technology/tech-news-technology/openai-x-jony-ive-wireless-earbuds-unique-design-launch-2026-10471143/))\\n- Android Authority: OpenAI earbuds leak with Sweetpea codename; design description; BOM/production cost hints; September launch target; five-device roadmap mentioned. ([androidauthority.com](https://www.androidauthority.com/openai-earbuds-3631925/))\\n- Axios: OpenAI’s secret device coming; Davos timeline; mentions Sweetpea and Gumdrop leaks; timeline for second half of 2026. ([axios.com](https://www.axios.com/2026/01/23/openai-device-earbuds-sweetpea-altman))\\n- The Verge: OpenAI hardware prototype discussions tied to Jony Ive and the hardware program (context around the hardware push). ([theverge.com](https://www.theverge.com/news/827607/openai-hardware-prototype-chatgpt-jony-ive-sam-altman?utm_source=openai))\\n- (Caveat on Dime branding) Gizmochina / other aggregators noting a claimed consumer name Dime; these are not widely corroborated by major outlets. ([gizmochina.com](https://www.gizmochina.com/2026/02/07/openais-first-hardware-device-ai-earbuds-strategy-shift-and-launch-timeline/?utm_source=openai))\\n\\nNotes:\\n- All statements above about Sweetpea, the rumored features, and the general timeline are based on published reporting as of February 8, 2026; several items (notably the consumer-name “Dime”) are not yet verified by major, high-profile outlets and are reported only by a subset of non-primary sources. ([techcrunch.com](https://techcrunch.com/2026/01/21/openai-aims-to-ship-its-first-device-in-2026-and-it-could-be-earbuds/))\\n\\nIf you’d like, I can add direct excerpts or align these points to a formal, source-by-source bibliography.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d44e9e36-e1ff-4ed8-8950-2107a64a5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = supabase.table('research_assistant')\\\n",
    "    .select('id, event_id, news_date, output')\\\n",
    ".eq('news_date', '2026-02-20')\\\n",
    "    .order('created_at', desc=False)\\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fdbc9a0a-2921-4ec0-bddb-d27f5d63799b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 211,\n",
       "  'event_id': '1274_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Core development: Nvidia is close to finalizing roughly a $30 billion equity investment in OpenAI, replacing the previously announced up-to-$100 billion multi-year data-center compute pact. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Financing scope: OpenAI is seeking more than $100 billion in the current funding round, with the round valuing OpenAI at about $830 billion. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Likely investors: SoftBank and Amazon are also expected to participate in the round. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Investment structure: The deal would be a direct equity stake in OpenAI, not a commitment for OpenAI to buy Nvidia hardware under a compute arrangement. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Use of proceeds: OpenAI plans to reinvest much of the new capital into Nvidia hardware and to purchase Nvidia chips. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Replacement of prior pact: This arrangement would replace the September announcement of a up-to-$100 billion multi-year commitment to support OpenAI’s use of Nvidia chips in data centers. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Company response: Nvidia declined to comment on the Reuters report. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))\\n\\n- Timing and status: The Reuters report notes the deal is not final and could close soon, with coverage dated February 19–20, 2026. ([thestar.com.my](https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports))'},\n",
       " {'id': 212,\n",
       "  'event_id': '1275_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Core development: OpenAI and Tata Group announce a multi-dimensional strategic partnership to speed AI-driven transformation across Tata Group, other Indian and global enterprises, and to build AI infrastructure in India (Enterprise ChatGPT for Tata, agentic AI, and HyperVault data-center initiatives). ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- OpenAI for India launch: OpenAI launches OpenAI for India to expand sovereign AI capabilities, accelerate enterprise adoption, and upskill the workforce, with India hosting OpenAI-led initiatives alongside Tata Group. ([openai.com](https://openai.com/openai-for-india))\\n\\n- Sovereign AI infrastructure: As part of Stargate, OpenAI and Tata will develop local AI-ready data-center capacity designed for data residency and security, with OpenAI becoming the first customer of Tata Consultancy Services’ HyperVault. 100 MW initial capacity, potential to scale to 1 GW. ([openai.com](https://openai.com/openai-for-india))\\n\\n- 100 MW buildout and scale plan: In the initial phase, Tata Group’s HyperVault unit will develop AI infrastructure with 100 MW capacity, with an option to scale to 1 GW to support next-generation AI workloads. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- Enterprise ChatGPT deployment: Tata Group plans to deploy ChatGPT Enterprise across its employees over the coming years, starting with hundreds of thousands of TCS employees. ([openai.com](https://openai.com/openai-for-india))\\n\\n- Codex integration for software: TCS will leverage OpenAI’s Codex to standardize AI-native software development across teams. ([openai.com](https://openai.com/openai-for-india))\\n\\n- Agentic AI focus: The partnership will develop industry-specific agentic AI solutions by combining OpenAI’s agentic AI capabilities with TCS domain knowledge. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- Joint GTM and deployment: TCS and OpenAI will jointly enable Indian and global enterprises to deploy, integrate, and scale OpenAI platforms, driving AI-led transformation at scale. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- Upskilling and certifications: OpenAI Certifications will expand in India with TCS as the first participating organization outside the United States; more than 100,000 ChatGPT Edu licenses will be provided to help workforce skills. ([openai.com](https://openai.com/openai-for-india))\\n\\n- Social impact commitments: OpenAI Foundation and TCS will collaborate to provide AI training/resources to Indian youth and develop NGO toolkits, aiming to improve livelihoods for at least one million Indian youth. ([tata.com](https://www.tata.com/newsroom/business/tata-openai-partnership))\\n\\n- OpenAI presence in India: OpenAI plans to open new offices in Mumbai and Bengaluru later in 2026 to support local users and partners. ([openai.com](https://openai.com/openai-for-india))'},\n",
       " {'id': 213,\n",
       "  'event_id': '1276_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- General Catalyst commits $5 billion to invest in India over the next five years, announced at the India AI Impact Summit 2026 in New Delhi on February 19, 2026. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- This $5 billion pledge represents a fivefold increase from GC’s prior India earmark of about $500 million to $1 billion. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- The investment will target sectors including artificial intelligence, healthcare, defense technology, fintech, and consumer technology. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- The announcement comes less than two years after General Catalyst merged with local firm Venture Highway. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- Neeraj Arora serves as GC’s CEO for India, the Middle East & North Africa to lead the expanded push. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- GC is pursuing a platform-led model that combines traditional investing with a “creation” strategy, including roll-ups of companies in India. ([m.economictimes.com](https://m.economictimes.com/tech/technology/general-catalysts-hemant-taneja-on-5-billion-india-bet-and-its-shift-beyond-venture-capital-to-company-creation-in-the-ai-age/articleshow/128589856.cms))\\n- GC views India’s biggest AI opportunity as large-scale real-world deployment rather than frontier-model development. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- GC’s India portfolio already includes Zepto, PB Health, Raphe, Jeh Aerospace, Pronto and Ayr Energy, with additional investments in Spinny, Farmart, and Loop Health noted in coverage. ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))\\n- The commitment coincides with broad activity at the India AI Impact Summit, which has attracted participation from global players and AI initiatives (e.g., OpenAI, Anthropic, Google among others). ([techcrunch.com](https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/))'},\n",
       " {'id': 214,\n",
       "  'event_id': '1277_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- WHAT IS NEW: Abu Dhabi’s G42 and MBZUAI, partnered with Cerebras and India’s C-DAC, announced an 8-exaflop national AI supercomputer to be deployed in India, announced on the sidelines of the India AI Impact Summit 2026. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- HOSTING AND GOVERNANCE: The system will be hosted in India and operate under India-defined governance with data remaining within national jurisdiction, as part of strengthening sovereign AI infrastructure under the India AI Mission. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- COMPUTE CAPACITY: The announced system is designed to deliver 8 exaflops of compute capacity, marking a step to exaflop-scale AI infrastructure in India. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- PARTNER ROLES: Delivery will be by G42 and Cerebras, with MBZUAI and India’s C-DAC as collaborating partners. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- ANNOUNCEMENT CONTEXT: The project was unveiled at the India AI Impact Summit 2026 in New Delhi. ([thenationalnews.com](https://www.thenationalnews.com/future/technology/2026/02/20/abu-dhabis-g42-and-mbzuai-join-us-firm-cerebras-to-build-india-ai-supercomputer/))\\n\\n- ACCESS AND USERS: Once operational, the supercomputer will be accessible to universities, startups, SMEs, and government ministries, aiming for broad public/private sector AI enablement. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- PURPOSE AND IMPACT: The initiative targets accelerating both training and inference for large-scale AI models tailored to Indian needs. ([techcrunch.com](https://techcrunch.com/2026/02/20/uaes-g42-teams-up-with-cerebras-to-deploy-8-exaflops-of-compute-in-india/))\\n\\n- RELEVANT PREVIOUS COLLABORATION: MBZUAI and G42 previously released the Hindi-English language model NANDA 87B (Dec 2025), highlighting prior collaboration between the parties. ([mbzuai.ac.ae](https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/))\\n\\n- GEOPOLITICAL CONTEXT: The project follows broader India–UAE strategic alignment, including the December 2025 India–UAE Strategic Dialogue and the January 2026 visit of UAE leadership to India. ([thenationalnews.com](https://www.thenationalnews.com/future/technology/2026/02/20/abu-dhabis-g42-and-mbzuai-join-us-firm-cerebras-to-build-india-ai-supercomputer/))\\n\\n'},\n",
       " {'id': 215,\n",
       "  'event_id': '1278_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Core development: Sarvam AI unveiled two indigenous LLMs, Sarvam-30B and Sarvam-105B, announced at the India AI Impact Summit 2026 in New Delhi, aimed at real-time use and advanced reasoning; MoE architecture with large context windows; open-sourcing planned. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Model architecture: Both models use a mixture-of-experts design that activates only a fraction of parameters at inference to improve efficiency. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Real-time capabilities: 30B targets production-ready, real-time conversational use with a 32,000-token context window; 105B targets more complex, multi-step reasoning with a 128,000-token window. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Training from scratch: 30B was pre-trained from scratch on about 16 trillion tokens; 105B trained on trillions of tokens across multiple Indian languages. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- IndiaAI Mission and compute: Training leveraged India’s government-backed IndiaAI Mission compute, with infrastructure support from Yotta and technical support from Nvidia. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Open-source plan: Sarvam stated it intends to open-source the 30B and 105B models, though it did not specify whether training data or full training code would be disclosed. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Enterprise and ecosystem: The launch outlined an expanded enterprise stack, including Sarvam for Work and a conversational agent platform called Samvaad, plus a vision model for document understanding. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Indus consumer app: Two days after the model announcements, Sarvam released Indus, a consumer AI chat app powered by the 105B model, available in beta on iOS, Android, and the web; initial rollout limited to India with a waitlist. ([techcrunch.com](https://techcrunch.com/2026/02/20/indias-sarvam-launches-indus-ai-chat-app-as-competition-heats-up/?utm_source=openai))\\n\\n- Benchmark and language focus: The 105B model is positioned to perform on benchmarks relevant to Indian languages and enterprise tasks, with claims of competitive performance against open/closed models of similar size. ([business-standard.com](https://www.business-standard.com/technology/tech-news/sarvam-105b-model-sovereign-ai-india-foundation-model-launch-impact-summit-126021900551_1.html?utm_source=openai))\\n\\n- Industry coverage: Coverage of the announcement and related products appeared in TechCrunch (Feb 18, 2026), Economic Times (ETtech, Feb 18, 2026), Fortune India (Feb 18, 2026), and The Times of India (Feb 19, 2026), among others. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))'},\n",
       " {'id': 216,\n",
       "  'event_id': '1279_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Fractal launches Vaidya 2.0, the next generation of its healthcare reasoning models, available at Vaidya.ai. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Vaidya 2.0 scores 50.1 on OpenAI HealthBench (hard), and Fractal says it is the first AI model to exceed 50 on this benchmark, outperforming GPT-5 and Google’s Gemini Pro 3. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Debuted at the India AI Impact Summit 2026 in New Delhi, with HealthBench (hard) performance highlighted among its claims. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Fractal describes Vaidya 2.0 as designed to power a “Health Care Operating System” of workflows that bridge raw data to healthcare action. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Key citizen-facing use cases highlighted for Vaidya 2.0 include Emergency Assist (rapid triage and decision support), Symptom Checker, and Patient Journey Assist. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- The model shows strong performance on the MedExpert benchmark and introduces capabilities to support Doctor Assist, in addition to OpenAI HealthBench (hard) Health Data Tasks for administrators. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Fractal is positioned as part of India’s sovereign AI push under the ₹10,300+ crore India AI Mission, framing Vaidya 2.0 as the first in a family of verticalized foundation models for the Global South. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- Vaidya 2.0 is described as a post-trained, reasoning- and agentic-based healthcare model rather than a pure knowledge-based foundation model. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))\\n\\n- The release reiterates that Vaidya 2.0 is being demonstrated at the India AI Impact Summit 2026, with the broader Vaidya suite showcased at the event. ([fractal.ai](https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0))'},\n",
       " {'id': 217,\n",
       "  'event_id': '1280_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Core development: Stanford HAI and AWS launched the Stanford and AWS Marketing Science Lab to advance AI-driven marketing measurement, including measurement techniques, causal inference, and AI-based measurement tools. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Collaboration scope: The lab unites Stanford Institute for Human-Centered AI (HAI), Stanford Data Science, the Stanford Graduate School of Business, and Amazon Web Services (AWS). ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Leadership: The lab is led by Guido Imbens (HAI-SDS Co-Director), Susan Athey (GSB), Wesley Hartmann (GSB), and Jiafeng (Kevin) Chen (Economics). ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Announcement date: Public coverage and posts indicate the launch was announced around February 20, 2026. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\\n- Focus areas: The initiative concentrates on marketing measurement, AI-powered measurement, causal inference methods, and analysis of B2B customer journeys. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Expected outputs: Outcomes include published research, open-source code, and prototypes. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))\\n- Relevance to AI product measurement: The lab is described as an academic–industry initiative relevant to AI product measurement and adoption. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\\n- Cloud-scale research angle: The collaboration emphasizes scalable tools and cloud-enabled experimentation, leveraging AWS infrastructure. ([edtechinnovationhub.com](https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai))\\n- Notable acknowledgement: Julia White, AWS Vice President and Chief Marketing Officer, is credited with helping spur the collaboration. ([linkedin.com](https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai))'},\n",
       " {'id': 218,\n",
       "  'event_id': '1284_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Gemini 3.1 Pro is announced as a smarter Gemini model, with an upgraded core intelligence designed for tasks where a simple answer isn’t enough. It’s described as a step forward in core reasoning for complex problem-solving. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Rollout is moving from today across multiple product strands: developers in preview via the Gemini API (including Google AI Studio), Gemini CLI, Google Antigravity, and Android Studio; enterprises via Vertex AI and Gemini Enterprise; consumers via the Gemini app and NotebookLM. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Access to 3.1 Pro is available through the Gemini API, Vertex AI, the Gemini app, and NotebookLM. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- In benchmarking, 3.1 Pro achieved a verified ARC-AGI-2 score of 77.1%, described as more than double the reasoning performance of 3 Pro. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Code-based animation capability: 3.1 Pro can generate website-ready, animated SVGs directly from a text prompt. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Complex system synthesis example: the model can bridge complex APIs to user-friendly designs, demonstrated by building a live aerospace dashboard that visualizes the ISS orbit. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Interactive design example: 3.1 Pro can code a complex 3D starling murmuration with hand-tracking and a generative score that shifts based on movement. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))\\n\\n- Overall framing: 3.1 Pro is a smarter baseline for complex problem solving and is being released in preview to validate updates and advance agentic workflows across consumer, developer, and enterprise products. ([blog.google](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/))'},\n",
       " {'id': 219,\n",
       "  'event_id': '1286_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- OpenAI and Microsoft joined the UK’s AI Security Institute’s international coalition to safeguard AI development, with OpenAI pledging funding to the Alignment Project; total funding now over £27 million to support about 60 projects. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- The Alignment Project is an international, UK-led effort to advance AI alignment research to ensure frontier AI systems are safe, secure, and under human control. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- OpenAI is contributing £5.6 million to the Alignment Project, alongside ongoing support from Microsoft and other partners, contributing to the £27 million+ total funding. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- The coalition supporting the Alignment Project includes a broad set of partners beyond OpenAI/Microsoft, such as CIFAR (Canadian Institute for Advanced Research), Australia’s AI Safety Institute, Schmidt Sciences, AWS, Anthropic, and several funds and UK bodies. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- The Alignment Project combines grant funding for research, compute infrastructure access, and ongoing academic mentorship from the AI Security Institute to accelerate alignment work. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- First Alignment Project grants have been awarded to 60 projects spanning eight countries, with a second funding round expected to open in the summer. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- Announcements were made by UK Deputy Prime Minister David Lammy and AI Minister Kanishka Narayan at the AI Impact Summit in India, marking the close of that summit. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- Mia Glaese, OpenAI VP of Research, emphasized that advancing alignment requires collaboration across independent teams and that OpenAI’s support complements its internal alignment work. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))\\n\\n- The program is framed as a mechanism to build public trust in AI and enable safer deployment of frontier AI technologies in public services and national renewal. ([gov.uk](https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development))'},\n",
       " {'id': 220,\n",
       "  'event_id': '1287_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- WHAT IS NEW — On February 20, 2026, PhonePe launched an AI-powered natural language search feature built on Microsoft Foundry that lets users initiate and complete in-app tasks, including payments, via voice or text. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- INTENT-BASED ROUTING — The feature replaces traditional navigation with intent-based routing, directing users to their desired action (e.g., \"Pay Hemanth 20 rupees\" pre-selects the recipient or surfaces contacts named Hemanth). ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- ACTION SURFACING — Commands like “Recharge FASTag” or “Gold price” navigate to the most relevant page or surface the appropriate options. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- PRIVACY/COMPUTE ARCHITECTURE — It uses a hybrid model of on-device and cloud inferencing, with personal and transactional data kept within the PhonePe environment. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- ROLLOUT DETAIL — The rollout is being implemented in phases across India, with access via the Global Search Bar, Help Center, and History tab in the PhonePe app. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- OFFICIAL VOICES — Rahul Chari (PhonePe CTO) described the launch as moving toward intent-based intelligent interfaces; Microsoft’s Puneet Chandok commented on Foundry’s role. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- TECHNOLOGY PARTNER — The AI capability is powered by Microsoft Foundry technology. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))\\n- CONTEXTUAL BACKDROP — The launch coincides with India’s AI ecosystem activity, with ET Online situating it around the AI Impact Summit 2026. ([economictimes.indiatimes.com](https://economictimes.indiatimes.com/industry/banking/finance/phonepe-rolls-out-ai-powered-feature-to-pay-via-voice-or-text/articleshow/128601184.cms?from=mdr))\\n- COMPANY SCALE CONTEXT — PhonePe notes over 65 crore registered users and more than 4.7 crore merchants as of September 2025. ([phonepe.com](https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/))'},\n",
       " {'id': 221,\n",
       "  'event_id': '1288_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- What is new: OpenAI has introduced Lockdown Mode for ChatGPT (an optional, advanced security setting) along with Elevated Risk labels for certain capabilities; the feature was announced on February 13, 2026, with consumer rollout planned in coming months. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Who it’s for: Lockdown Mode is designed for a small set of high-security users (e.g., executives, security teams) and is not required by most users; it is available to ChatGPT Enterprise, Edu, Healthcare, and Teachers, with admins able to enable it in Workspace Settings. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Core purpose: The mode aims to mitigate prompt-injection risks and data exfiltration by tightening how ChatGPT interacts with external systems. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Web browsing in Lockdown Mode: Web browsing is limited to cached content, preventing live network requests from leaving OpenAI’s controlled network. This is intended to reduce potential data exfiltration via browsing. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Other interaction constraints: Lockdown Mode deterministically disables certain tools and capabilities that could be exploited by adversaries; it tightens how ChatGPT can access apps and external sources. (OpenAI describes these as broad restrictions beyond standard protections.) ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Availability and administration: Admins can tailor which apps and actions are allowed under Lockdown Mode for individual users within a workspace; OpenAI notes a consumer rollout is planned for the coming months. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Elevated Risk labels: A separate feature assigns “Elevated Risk” labels to specific capabilities across ChatGPT, ChatGPT Atlas, and Codex to communicate higher-risk use cases and guide user decisions. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Rationale and protections: The rollout builds on existing safeguards (sandboxing, URL-data exfiltration protections, monitoring, audit logs, and enterprise controls) to reduce risk when features interact with networks and external apps. ([openai.com](https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai))\\n\\n- Forbes interpretation: Forbes’ analysis frames Lockdown Mode as being “repurposed” to limit problematic mental-health outputs, illustrating how the feature could affect safety in specific use cases. ([forbes.com](https://www.forbes.com/sites/lanceeliot/2026/02/20/new-chatgpt-lockdown-mode-repurposed-to-stop-ai-from-giving-out-bad-mental-health-advice/?utm_source=openai))\\n\\n- Additional coverage and context: Other outlets (e.g., Yahoo Tech and Indian Express) summarize Lockdown Mode as a security upgrade that pairs with Elevated Risk labels to improve transparency about feature risks. ([tech.yahoo.com](https://tech.yahoo.com/ai/chatgpt/articles/chatgpt-now-lockdown-mode-enable-160050855.html/?utm_source=openai))'},\n",
       " {'id': 222,\n",
       "  'event_id': '1289_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Meta plans to launch its first smartwatch in 2026, code-named Malibu 2, featuring health tracking and a built-in Meta AI assistant. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- The smartwatch revival follows a 2022 shutdown of a prior Meta smartwatch effort amid Reality Labs cost cuts; the project traces back roughly five years and included camera-equipped concepts. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- The device is slated for release later in 2026, according to the initial reporting on the Malibu 2 project. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- It would compete directly with established smartwatches such as the Apple Watch and other wearables. ([forbes.com](https://www.forbes.com/sites/andrewwilliams/2026/02/19/meta-smartwatch-makes-perfect-sense-amid-smart-glasses-strategy/?utm_source=openai))\\n- Reported features include health-tracking capabilities and integration with Meta’s AI, rather than a generic, non-AI smartwatch. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- The Malibu 2 concept is discussed in the context of broader Meta wearables strategy, potentially enabling cross-device interactions with Ray-Ban smart glasses. ([forbes.com](https://www.forbes.com/sites/andrewwilliams/2026/02/19/meta-smartwatch-makes-perfect-sense-amid-smart-glasses-strategy/?utm_source=openai))\\n- Meta has not publicly commented on the Malibu 2 plan when approached by reporters. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- The wearables backdrop includes Ray-Ban Display glasses, which reportedly shipped close to 6 million units in 2025, underscoring a growing AI-enabled wearable ecosystem. ([aol.com](https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai))\\n- Separately, Meta reportedly delayed its Phoenix mixed-reality glasses to 2027 and paused international rollout of Ray-Ban Display glasses to prioritize US demand, signaling a staggered hardware roadmap. ([businessinsider.com](https://www.businessinsider.com/meta-delays-new-mixed-reality-glasses-code-named-phoenix-2025-12?utm_source=openai))'},\n",
       " {'id': 223,\n",
       "  'event_id': '1291_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Core development: Lyria 3, Google DeepMind’s latest generative music model, is rolling out in beta inside the Gemini app, enabling creation of 30-second tracks from text prompts, photos, or videos, with auto lyrics and optional cover art; output is watermark-tagged via SynthID. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Global beta availability and rollout: The feature is available to Gemini users 18+, with desktop access today and mobile rollout in the coming days; supported languages include English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Output length and scope: Lyria 3 targets 30-second tracks, designed for short-form content (e.g., YouTube Shorts, TikTok, Reels). ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Auto lyrics capability: Lyrics generation is built into the flow, removing the previous requirement to supply lyrics manually. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Multimodal control: Users can steer generation with text plus visual prompts (images/videos) to influence genre, mood, tempo, and vocal tone. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Copyright and safety safeguards: Outputs are filtered to discourage direct artist mimicry, with provenance tools and a reporting channel for rights concerns; SynthID watermarking supports identification of AI-generated audio. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- YouTube Dream Track integration: Lyria 3 is being extended to YouTube creators via Dream Track, expanding access beyond Gemini to creator workflows. ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Creator-facing features (art and branding): Gemini generates custom cover art for tracks (e.g., via Nano Banana) to accompany AI-made songs. ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Availability and access tier details: Free usage exists with plan-based limits; Google AI Plus, Pro, and Ultra subscribers are described as receiving higher generation ceilings. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))'},\n",
       " {'id': 224,\n",
       "  'event_id': '1292_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- Qumis announces an oversubscribed seed round of $4.3 million led by MTech Capital, with American Family Ventures joining as a new strategic investor; total funding now sits at $6.75 million. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- The round will be deployed to expand Qumis’ go-to-market team and deepen product capabilities around coverage intelligence for commercial insurance. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- Qumis’ platform is described as attorney-trained AI for commercial insurance coverage intelligence that reads and reasons across complex policy documents to deliver structured, citation-backed insights with transparent reasoning. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- Traction includes adoption by large brokers and carriers, notably NFP (an Aon company), with usage expanding from an initial team to hundreds of users across the organization. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- The funding comes amid continuing AI investment in insurance, with most capital historically flowing to workflow automation and document processing—Qumis is pursuing a more specialized, coverage-focused AI approach. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- Qumis is Chicago-based, founded in 2022, and built by coverage attorneys and AI experts to replace manual policy review with attorney-grade coverage insights. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- Lead investor in the round is MTech Capital; American Family Ventures is a new strategic investor; all prior investors participated in this round. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- The platform targets insurance teams across brokers, carriers, and coverage-focused law firms, offering policy analysis, policy comparisons, and real-time insights to support underwriting and claims. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))\\n\\n- No valuation for the seed round was disclosed in the public announcements. ([globenewswire.com](https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai))'},\n",
       " {'id': 225,\n",
       "  'event_id': '1294_2026-02-20',\n",
       "  'news_date': '2026-02-20',\n",
       "  'output': '- OpenAI is developing a family of AI-powered devices, including a smart speaker and possibly smart glasses and a smart lamp, with a team of more than 200 people, signaling a shift from cloud/model-only products toward consumer hardware. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- The smart speaker would be the first device in the lineup, with an estimated retail price of $200–$300 and not expected to ship before February 2027 at the earliest. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- The speaker is described as including a camera to gather information about users and their surroundings. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- The smart glasses in the plan are not expected to reach mass production until 2028. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- The device family reportedly also includes a smart lamp as part of the initial concept set. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- OpenAI’s hardware push traces back to its $6.5 billion acquisition of io Products, the Jony Ive–founded hardware unit. ([bloomberg.com](https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal?utm_source=openai))\\n- The move is framed as OpenAI aiming to capitalize on growing demand for physical AI and augmented reality rather than solely cloud/software offerings. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))\\n- Industry context cited in reports notes Meta’s Ray-Ban smart glasses have had success, and that Apple and Google are also pursuing wearables. ([channelnewsasia.com](https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai))'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "96329ecd-d624-4f2f-ab04-7bf615736d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary_7 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b83f613c-2649-4e2e-a88e-568e1ae23ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_article_builder(researched_data):\n",
    "    final_news_article = []\n",
    "    for i in researched_data:\n",
    "        response = client_anthropic.messages.create(\n",
    "            model = \"claude-sonnet-4-5\",\n",
    "            max_tokens = 800,\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\":  f\"\"\"\n",
    "                You are a tech journalist at Krux — a news platform that helps GenZ stay informed about AI & tech in under 60 seconds.\n",
    "\n",
    "                CRITICAL CONSTRAINT: The article body MUST be 85-100 words (excluding headline). Count carefully before finalizing.\n",
    "\n",
    "                TASK: Write a news article using ONLY the information provided by our research assistant.\n",
    "                \n",
    "                Follow this structure:\n",
    "                \n",
    "                === STEP 1: HEADLINE (Under 10 words) ===\n",
    "                Objective: Hook the reader instantly\n",
    "                - Punchy, attention-grabbing and clickbait\n",
    "                - Focus on the most surprising/important angle\n",
    "                \n",
    "                **ARTICLE BODY** (85-100 words TOTAL)\n",
    "\n",
    "                Opening (20-30 words):\n",
    "                - If rumour: clarify in first sentence, then proceed assuming the things stated by research assistant are facts\n",
    "                - Lead with the core news hook\n",
    "                \n",
    "                Middle (40-50 words):\n",
    "                - Sharp, conversational, slightly witty tone\n",
    "                - Present key facts from research assistant\n",
    "                - Use most/all provided information\n",
    "                - NO links or source references in body\n",
    "                - Explain it in a simple way such that a non-tech person who has no background about this also understands its impact\n",
    "                \n",
    "                Closing (20-25 words):\n",
    "                - Forward-looking strategic perspective\n",
    "                - What could this mean for industry/users/tech landscape?\n",
    "                - Frame as analysis, NOT opinion\n",
    "                - Grounded in facts presented\n",
    "                \n",
    "                === VERIFICATION CHECKLIST ===\n",
    "                Before outputting, verify:\n",
    "                ☑ Article body is 85-100 words (count manually)\n",
    "                ☑ Headline is under 10 words\n",
    "                ☑ No URLs in article body\n",
    "                ☑ All key facts from research included\n",
    "                ☑ There should be no em-dashes in the article\n",
    "                \n",
    "                HARD CONSTRAINTS:\n",
    "                - Total article: 100 words max (headline excluded). If the Article is NOT 100 words, re-generate it to meet the 100 word\n",
    "                requirement.\n",
    "                - Sources with URLs listed at end under \"Sources:\"\n",
    "\n",
    "                \n",
    "                OUTPUT FORMAT NEEDS TO BE IN A STRICT JSON FORMAT:\n",
    "                {{\"headline\": \"...\", \"output\": \"...\", \"sources\": [{{\"name\": \"...\", \"url\": \"...\"}}]}}\n",
    "\n",
    "                Here is the information we have gathered from the research assistant:\n",
    "                \n",
    "                {i['output']}\n",
    "            \"\"\"\n",
    "            }]\n",
    "        )\n",
    "\n",
    "        final_output = response.content[0].text\n",
    "\n",
    "        cleaned = final_output.strip()\n",
    "\n",
    "        if cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned.split(\"\\n\", 1)[1].rsplit(\"```\", 1)[0].strip()\n",
    "\n",
    "        article_json = json.loads(cleaned)\n",
    "\n",
    "        article_json['model_provider'] = 'claude'\n",
    "        article_json['news_date'] = i['news_date']\n",
    "        article_json['event_id'] = i['event_id']\n",
    "\n",
    "        print(article_json)\n",
    "\n",
    "        final_summary_7.append(article_json)\n",
    "\n",
    "        # save_article(article_json)\n",
    "\n",
    "        print(\"✔️ Saved!\")\n",
    "        \n",
    "        \n",
    "\n",
    "    #     final_news_article.append(json_format)\n",
    "\n",
    "    # return final_news_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "294234fb-43a3-4d5a-9d3a-7f9956e0d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [{\n",
    "  \"id\": 223,\n",
    "  \"event_id\": \"1291_2026-02-20\",\n",
    "  \"news_date\": \"2026-02-20\",\n",
    "  \"output\": \"- Core development: Lyria 3, Google DeepMind's latest generative music model, is rolling out in beta inside the Gemini app, enabling creation of 30-second tracks from text prompts, photos, or videos, with auto lyrics and optional cover art; output is watermark-tagged via SynthID. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Global beta availability and rollout: The feature is available to Gemini users 18+, with desktop access today and mobile rollout in the coming days; supported languages include English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Output length and scope: Lyria 3 targets 30-second tracks, designed for short-form content (e.g., YouTube Shorts, TikTok, Reels). ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Auto lyrics capability: Lyrics generation is built into the flow, removing the previous requirement to supply lyrics manually. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Multimodal control: Users can steer generation with text plus visual prompts (images/videos) to influence genre, mood, tempo, and vocal tone. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- Copyright and safety safeguards: Outputs are filtered to discourage direct artist mimicry, with provenance tools and a reporting channel for rights concerns; SynthID watermarking supports identification of AI-generated audio. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai))\\n\\n- YouTube Dream Track integration: Lyria 3 is being extended to YouTube creators via Dream Track, expanding access beyond Gemini to creator workflows. ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Creator-facing features (art and branding): Gemini generates custom cover art for tracks (e.g., via Nano Banana) to accompany AI-made songs. ([techcrunch.com](https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai))\\n\\n- Availability and access tier details: Free usage exists with plan-based limits; Google AI Plus, Pro, and Ultra subscribers are described as receiving higher generation ceilings. ([blog.google](https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai)) - Google DeepMind launched Lyria 3, its most capable generative music model to date, in beta within the Gemini app on February 18, 2026, enabling users to generate music tracks complete with vocals and lyrics from text, photo, or video prompts.\\n\\n- Lyria 3 produces dynamic 30-second tracks with crystal-clear 48kHz stereo audio.\\n\\n- Beta rollout began on Gemini desktop that day, expanding to the Gemini app globally over the following days for all users aged 18+ across 8 languages.\\n\\n- Users access the feature via \\\"Create Music\\\" in the Gemini tools menu or directly at gemini.google.com/music.\\n\\n- Provides granular controls including tempo settings, specific vocal styles, and precise lyrics input.\\n\\n- Every generated track embeds SynthID, Google's invisible watermark for AI content identification.\\n\\n- Lyria 3 is also available via YouTube's Dream Track for creators in the US, with expansion to more countries planned.\\n\\n- Model designed for original expression; prompts naming artists provide broad stylistic inspiration rather than direct mimicry.\",\n",
    "  \"model_provider\": 'openai'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1370ec93-e040-44bf-ae03-9de4378a5119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'headline': \"Google's Lyria 3 Turns Text Into 30-Second Songs\", 'output': \"Google DeepMind just launched Lyria 3, a music generation AI inside the Gemini app that creates 30-second tracks with vocals and lyrics from text, photos, or videos. Rolling out globally to users 18+ in eight languages, it targets short-form content like YouTube Shorts and TikTok. The tool auto-generates lyrics, lets you tweak tempo and vocal style, and even makes custom cover art. Every track gets SynthID watermarking to flag AI-made audio. Available free with usage caps, it's also powering YouTube's Dream Track for creators. This could reshape how anyone makes shareable audio, lowering the barrier from studio to smartphone.\", 'sources': [{'name': 'Google Blog', 'url': 'https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai'}, {'name': 'TechCrunch', 'url': 'https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai'}], 'model_provider': 'claude', 'news_date': '2026-02-20', 'event_id': '1291_2026-02-20'}\n",
      "✔️ Saved!\n"
     ]
    }
   ],
   "source": [
    "claude_article_builder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "47f1c8d5-c064-4b8f-8440-d79177ca63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_article(article_json):\n",
    "    supabase.table('hundred_word_articles').insert({\n",
    "        'event_id': article_json['event_id'],\n",
    "        'model_provider': article_json['model_provider'],\n",
    "        'news_date': article_json['news_date'],\n",
    "        'sources': json.dumps(article_json['sources']),\n",
    "        'output': article_json['output'],\n",
    "        'headline': article_json['headline']\n",
    "    }).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8745f6a8-e17e-46d3-a663-5dced58ef734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': 'Nvidia Ditches $100B Chip Deal for $30B OpenAI Stake',\n",
       "  'output': \"Nvidia is swapping its massive $100 billion multi-year chip supply agreement for a cleaner $30 billion direct equity investment in OpenAI. This shift makes Nvidia an actual owner, not just a supplier, in the AI giant currently valued at $830 billion. OpenAI's hunting for over $100 billion total this round, with SoftBank and Amazon joining the party. Plot twist: OpenAI plans to spend much of that fresh cash buying Nvidia chips anyway. This move signals Nvidia wants skin in the game beyond hardware sales, positioning itself as a stakeholder in AI's future rather than just the picks-and-shovels provider during the gold rush.\",\n",
       "  'sources': [{'name': 'The Star',\n",
       "    'url': 'https://www.thestar.com.my/tech/tech-news/2026/02/20/nvidia-openai-near-30-billion-investment-in-place-of-unfinished-100-billion-deal-ft-reports'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1274_2026-02-20'},\n",
       " {'headline': \"OpenAI and Tata Group Join Forces for India's AI Revolution\",\n",
       "  'output': \"OpenAI and Tata Group have announced a massive strategic partnership to accelerate AI transformation across India and beyond. The deal includes deploying ChatGPT Enterprise to hundreds of thousands of TCS employees, building sovereign AI data centers starting at 100 MW (scalable to 1 GW), and developing industry-specific agentic AI solutions. TCS becomes OpenAI's first HyperVault customer, ensuring data stays local and secure. The partnership also brings 100,000 ChatGPT Edu licenses and AI training for one million Indian youth. With new OpenAI offices opening in Mumbai and Bengaluru by 2026, this positions India as a global AI powerhouse while giving enterprises tools to compete in the AI-first economy.\",\n",
       "  'sources': [{'name': 'Tata Newsroom',\n",
       "    'url': 'https://www.tata.com/newsroom/business/tata-openai-partnership'},\n",
       "   {'name': 'OpenAI', 'url': 'https://openai.com/openai-for-india'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1275_2026-02-20'},\n",
       " {'headline': 'General Catalyst Drops $5 Billion Bet on India',\n",
       "  'output': \"General Catalyst just pledged $5 billion to India over five years, a massive fivefold jump from its previous $500 million to $1 billion commitment. Announced at the India AI Impact Summit, the funds will flow into AI, healthcare, defense tech, fintech, and consumer startups. GC isn't chasing cutting-edge AI model development. Instead, it's betting on deploying AI solutions at scale in the real world, where India's vast market shines. With CEO Neeraj Arora steering the charge and a portfolio already featuring Zepto and PB Health, this signals India's emergence as a global AI deployment powerhouse, not just a talent hub.\",\n",
       "  'sources': [{'name': 'TechCrunch',\n",
       "    'url': 'https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/'},\n",
       "   {'name': 'Economic Times',\n",
       "    'url': 'https://m.economictimes.com/tech/technology/general-catalysts-hemant-taneja-on-5-billion-india-bet-and-its-shift-beyond-venture-capital-to-company-creation-in-the-ai-age/articleshow/128589856.cms'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1276_2026-02-20'},\n",
       " {'headline': 'India Gets 8-Exaflop AI Supercomputer From UAE Partnership',\n",
       "  'output': \"Abu Dhabi's G42 and MBZUAI, teaming up with Cerebras and India's C-DAC, just announced an 8-exaflop AI supercomputer for India at the India AI Impact Summit 2026. That's mind-blowing computing power for training massive AI models tailored to Indian needs. The system will be hosted entirely in India with full data sovereignty, meaning all your data stays within national borders under Indian governance. Once live, universities, startups, SMEs, and government ministries get access to this beast. This positions India as a serious player in sovereign AI infrastructure, reducing dependence on foreign cloud giants while accelerating homegrown AI innovation at scale.\",\n",
       "  'sources': [{'name': 'MBZUAI',\n",
       "    'url': 'https://mbzuai.ac.ae/news/uae-to-deploy-8-exaflop-supercomputer-in-india-to-strengthen-local-sovereign-ai-infrastructure/'},\n",
       "   {'name': 'The National News',\n",
       "    'url': 'https://www.thenationalnews.com/future/technology/2026/02/20/abu-dhabis-g42-and-mbzuai-join-us-firm-cerebras-to-build-india-ai-supercomputer/'},\n",
       "   {'name': 'TechCrunch',\n",
       "    'url': 'https://techcrunch.com/2026/02/20/uaes-g42-teams-up-with-cerebras-to-deploy-8-exaflops-of-compute-in-india/'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1277_2026-02-20'},\n",
       " {'headline': \"India's Sarvam AI Drops Two Homegrown LLMs, Goes Open-Source\",\n",
       "  'output': \"Sarvam AI just unveiled two made-in-India language models at the India AI Impact Summit: Sarvam-30B for real-time chat and Sarvam-105B for complex reasoning. Both use mixture-of-experts architecture, activating only some parameters to stay efficient while handling massive context windows (32K and 128K tokens). Trained from scratch on trillions of tokens across Indian languages using government-backed compute, they rival global models but understand local languages better. Sarvam plans to open-source both and launched Indus, a consumer chat app powered by 105B. This could make advanced AI accessible across India's linguistic diversity, challenging Western-dominated models with sovereign, multilingual alternatives.\",\n",
       "  'sources': [{'name': 'TechCrunch',\n",
       "    'url': 'https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/'},\n",
       "   {'name': 'TechCrunch',\n",
       "    'url': 'https://techcrunch.com/2026/02/20/indias-sarvam-launches-indus-ai-chat-app-as-competition-heats-up/?utm_source=openai'},\n",
       "   {'name': 'Business Standard',\n",
       "    'url': 'https://www.business-standard.com/technology/tech-news/sarvam-105b-model-sovereign-ai-india-foundation-model-launch-impact-summit-126021900551_1.html?utm_source=openai'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1278_2026-02-20'},\n",
       " {'headline': \"Fractal's Vaidya 2.0 Beats GPT-5 on Healthcare Benchmark\",\n",
       "  'output': \"Fractal just launched Vaidya 2.0, a healthcare AI model that's crushing the competition. It scored 50.1 on OpenAI's notoriously tough HealthBench test, becoming the first model to cross 50 and outperforming both GPT-5 and Google's Gemini Pro 3. Think of it as an AI doctor's assistant that can triage emergencies, check symptoms, and guide patients through treatment. Unlike typical AI models that just recall medical facts, Vaidya 2.0 actually reasons through complex healthcare scenarios. Part of India's $1.2 billion AI push, it's designed specifically for healthcare systems in developing regions, bridging the gap between raw patient data and actual medical action.\",\n",
       "  'sources': [{'name': 'Fractal',\n",
       "    'url': 'https://fractal.ai/about-us/media/fractal-launches-vaidya-2.0'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1279_2026-02-20'},\n",
       " {'headline': 'Stanford and AWS Team Up for AI Marketing Lab',\n",
       "  'output': \"Stanford HAI and AWS just launched the Stanford and AWS Marketing Science Lab to revolutionize how companies measure marketing effectiveness using AI. The collaboration brings together Stanford's Institute for Human-Centered AI, Data Science department, Graduate School of Business, and AWS cloud infrastructure. Led by top economists including Nobel laureate Guido Imbens and Susan Athey, the lab will tackle causal inference, AI measurement tools, and B2B customer journey analysis. Think smarter ad spend decisions powered by algorithms instead of guesswork. The initiative plans to release published research, open-source code, and prototypes, potentially reshaping how businesses justify their marketing budgets and adopt AI tools at scale.\",\n",
       "  'sources': [{'name': 'LinkedIn',\n",
       "    'url': 'https://www.linkedin.com/posts/activity-7429646063973593088-KKyW?utm_source=openai'},\n",
       "   {'name': 'EdTech Innovation Hub',\n",
       "    'url': 'https://www.edtechinnovationhub.com/news/stanford-hai-and-aws-launch-marketing-science-lab-focused-on-ai-measurement?utm_source=openai'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1280_2026-02-20'},\n",
       " {'headline': 'Google Drops Gemini 3.1 Pro With Wild Reasoning Upgrade',\n",
       "  'output': 'Google just launched Gemini 3.1 Pro, a significantly smarter AI model built for complex problems that need more than quick answers. It scored 77.1% on the ARC-AGI-2 benchmark, literally doubling the reasoning power of its predecessor. The upgrade rolls out today across the Gemini app, NotebookLM, API, and enterprise tools. What makes it wild? It can generate animated website code from text, build live aerospace dashboards tracking the ISS, and even code 3D bird simulations with hand-tracking. This positions Google to compete harder in agentic AI workflows where models actually solve multi-step problems autonomously, not just chat.',\n",
       "  'sources': [{'name': 'Google Blog',\n",
       "    'url': 'https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1284_2026-02-20'},\n",
       " {'headline': \"OpenAI and Microsoft Join UK's £27M AI Safety Push\",\n",
       "  'output': \"OpenAI and Microsoft have officially joined the UK's AI Security Institute's international coalition to keep AI development safe and under human control. The Alignment Project, a UK-led initiative, now boasts over £27 million in funding supporting roughly 60 research projects across eight countries. OpenAI is chipping in £5.6 million, joining partners like Anthropic, AWS, and Canada's CIFAR. Think of it as a global insurance policy: researchers get grants, computing power, and mentorship to ensure future AI systems don't go rogue. With a second funding round opening this summer, the coalition aims to build public trust and enable safer AI deployment in critical services worldwide.\",\n",
       "  'sources': [{'name': 'gov.uk',\n",
       "    'url': 'https://www.gov.uk/government/news/openai-and-microsoft-join-uks-international-coalition-to-safeguard-ai-development'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1286_2026-02-20'},\n",
       " {'headline': 'PhonePe Lets You Pay Friends Just By Talking',\n",
       "  'output': 'PhonePe just launched AI-powered voice and text search built on Microsoft Foundry, letting its 650 million users skip menus entirely. Say \"Pay Hemanth 20 rupees\" and it auto-selects the contact, or ask \"Gold price\" to jump straight there. The feature uses intent-based routing instead of traditional navigation, understanding what you want and taking you there instantly. It runs on a hybrid on-device and cloud model, keeping your transaction data locked within PhonePe\\'s environment. Rolling out in phases across India via the search bar, help center, and history tab, it signals a shift toward conversational interfaces in fintech.',\n",
       "  'sources': [{'name': 'PhonePe Press Release',\n",
       "    'url': 'https://www.phonepe.com/press/phonepe-launches-ai-powered-search-built-using-microsoft-foundry/'},\n",
       "   {'name': 'Economic Times',\n",
       "    'url': 'https://economictimes.indiatimes.com/industry/banking/finance/phonepe-rolls-out-ai-powered-feature-to-pay-via-voice-or-text/articleshow/128601184.cms?from=mdr'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1287_2026-02-20'},\n",
       " {'headline': \"ChatGPT's New Lockdown Mode Blocks Live Web Browsing\",\n",
       "  'output': \"OpenAI just dropped Lockdown Mode for ChatGPT, a high-security setting rolling out to Enterprise, Edu, Healthcare, and Teachers accounts, with consumer access coming soon. Designed for executives and security teams worried about data leaks, it tackles prompt-injection attacks by blocking live web requests and restricting external app access. Instead of browsing the open internet, ChatGPT can only pull cached content within OpenAI's network. Admins can customize which tools stay active per user. Paired with new Elevated Risk labels flagging dangerous features, this upgrade could reshape how organizations trust AI with sensitive workflows and confidential information.\",\n",
       "  'sources': [{'name': 'OpenAI',\n",
       "    'url': 'https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/?utm_source=openai'},\n",
       "   {'name': 'Forbes',\n",
       "    'url': 'https://www.forbes.com/sites/lanceeliot/2026/02/20/new-chatgpt-lockdown-mode-repurposed-to-stop-ai-from-giving-out-bad-mental-health-advice/?utm_source=openai'},\n",
       "   {'name': 'Yahoo Tech',\n",
       "    'url': 'https://tech.yahoo.com/ai/chatgpt/articles/chatgpt-now-lockdown-mode-enable-160050855.html/?utm_source=openai'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1288_2026-02-20'},\n",
       " {'headline': \"Meta's Smartwatch Is Back: 2026 AI Wearable Incoming\",\n",
       "  'output': \"Meta is reviving its smartwatch ambitions with Malibu 2, slated for late 2026. The device will pack health tracking and a built-in Meta AI assistant, taking on the Apple Watch directly. This marks a comeback after Meta killed a similar project in 2022 during Reality Labs budget cuts. The smartwatch fits into Meta's broader wearables strategy, potentially syncing with its Ray-Ban smart glasses, which shipped nearly 6 million units in 2025. Meta hasn't officially commented. If successful, the AI-powered watch could anchor an ecosystem where your glasses, wrist, and phone work together seamlessly, pushing wearables beyond fitness into ambient computing.\",\n",
       "  'sources': [{'name': 'AOL',\n",
       "    'url': 'https://www.aol.com/articles/meta-reboots-smartwatch-plan-aims-232800969.html?utm_source=openai'},\n",
       "   {'name': 'Forbes',\n",
       "    'url': 'https://www.forbes.com/sites/andrewwilliams/2026/02/19/meta-smartwatch-makes-perfect-sense-amid-smart-glasses-strategy/?utm_source=openai'},\n",
       "   {'name': 'Business Insider',\n",
       "    'url': 'https://www.businessinsider.com/meta-delays-new-mixed-reality-glasses-code-named-phoenix-2025-12?utm_source=openai'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1289_2026-02-20'},\n",
       " {'headline': \"Google's Lyria 3 Turns Text Into Music in Gemini\",\n",
       "  'output': 'Google DeepMind just dropped Lyria 3 in beta, letting Gemini users create 30-second tracks from text, photos, or videos with auto-generated lyrics and cover art. Think of it as Instagram for your ears: describe a vibe or upload a sunset pic, and get a custom soundtrack perfect for TikTok or Reels. The AI handles genre, mood, tempo, and vocals while blocking artist copycats. Each track gets watermarked via SynthID so you can spot AI audio. Available now on desktop (mobile coming soon) for users 18+ in eight languages, with YouTube Dream Track integration expanding creator access. As AI music tools proliferate, expect short-form content to become hyper-personalized sonic experiences.',\n",
       "  'sources': [{'name': 'blog.google',\n",
       "    'url': 'https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai'},\n",
       "   {'name': 'techcrunch.com',\n",
       "    'url': 'https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1291_2026-02-20'},\n",
       " {'headline': 'Insurance Startup Qumis Raises $4.3M for Lawyer-Level AI',\n",
       "  'output': 'Chicago-based Qumis just closed an oversubscribed $4.3 million seed round led by MTech Capital, bringing total funding to $6.75 million. The startup uses attorney-trained AI to read complex commercial insurance policies and deliver citation-backed insights with transparent reasoning, replacing tedious manual reviews. Major brokers like NFP, an Aon company, have already scaled from pilot teams to hundreds of users. While most insurance AI tackles workflow automation, Qumis is betting on specialized coverage intelligence. The funds will expand its go-to-market team and deepen product capabilities, positioning it as AI moves beyond document processing into nuanced legal interpretation for underwriting and claims.',\n",
       "  'sources': [{'name': 'globenewswire.com',\n",
       "    'url': 'https://www.globenewswire.com/news-release/2026/02/19/3241222/0/en/Qumis-Raises-4-3M-to-Bring-Attorney-Grade-Coverage-Intelligence-to-Commercial-Insurance.html?utm_source=openai'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1292_2026-02-20'},\n",
       " {'headline': 'OpenAI Building Smart Speakers, Glasses After $6.5B Acquisition',\n",
       "  'output': \"OpenAI is jumping into consumer hardware with a team of over 200 people developing AI-powered devices, including smart speakers, glasses, and even a smart lamp. This follows their massive $6.5 billion acquisition of io Products, Jony Ive's design firm. The first product, a camera-equipped smart speaker priced at $200 to $300, won't ship until February 2027 at the earliest, while smart glasses are slated for 2028. This pivot from pure software to physical products puts OpenAI in direct competition with Meta's successful Ray-Ban glasses and upcoming wearables from Apple and Google, as AI companies race to embed intelligence into everyday objects around your home.\",\n",
       "  'sources': [{'name': 'Channel News Asia',\n",
       "    'url': 'https://www.channelnewsasia.com/business/openai-developing-ai-devices-including-smart-speaker-information-reports-5943236?utm_source=openai'},\n",
       "   {'name': 'Bloomberg',\n",
       "    'url': 'https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal?utm_source=openai'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1294_2026-02-20'},\n",
       " {'headline': \"Google's Lyria 3 Turns Text Into 30-Second Songs\",\n",
       "  'output': \"Google DeepMind just launched Lyria 3, a music generation AI inside the Gemini app that creates 30-second tracks with vocals and lyrics from text, photos, or videos. Rolling out globally to users 18+ in eight languages, it targets short-form content like YouTube Shorts and TikTok. The tool auto-generates lyrics, lets you tweak tempo and vocal style, and even makes custom cover art. Every track gets SynthID watermarking to flag AI-made audio. Available free with usage caps, it's also powering YouTube's Dream Track for creators. This could reshape how anyone makes shareable audio, lowering the barrier from studio to smartphone.\",\n",
       "  'sources': [{'name': 'Google Blog',\n",
       "    'url': 'https://blog.google/innovation-and-ai/products/gemini-app/lyria-3?utm_source=openai'},\n",
       "   {'name': 'TechCrunch',\n",
       "    'url': 'https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/?utm_source=openai'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1291_2026-02-20'},\n",
       " {'headline': \"Google's Lyria 3 Turns Text Into 30-Second Songs\",\n",
       "  'output': 'Google DeepMind just dropped Lyria 3, a generative music model now live in beta inside the Gemini app. Users aged 18+ can create 30-second tracks with vocals and auto-generated lyrics from text, photos, or videos. The tool offers controls for tempo, mood, and vocal style, producing crystal-clear stereo audio perfect for TikTok, Reels, and YouTube Shorts. Every track gets SynthID watermarking to tag AI-generated content, and artist-name prompts deliver stylistic inspiration without direct mimicry. Lyria 3 is also heading to YouTube Dream Track for creators. As AI-generated music floods short-form platforms, expect debates around authenticity, copyright, and creator compensation to intensify across the industry.',\n",
       "  'sources': [{'name': 'Google Blog',\n",
       "    'url': 'https://blog.google/innovation-and-ai/products/gemini-app/lyria-3'},\n",
       "   {'name': 'TechCrunch',\n",
       "    'url': 'https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/'}],\n",
       "  'model_provider': 'claude',\n",
       "  'news_date': '2026-02-20',\n",
       "  'event_id': '1291_2026-02-20'}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5d1cf0b-b3c1-4303-bc09-d38eec6036e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n"
     ]
    }
   ],
   "source": [
    "for i in final_summary_7:\n",
    "    if i['news_date'] >= '2026-02-17':\n",
    "        save_article(i)\n",
    "        print(\"✔️ Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e496c4a9-17c2-49ce-9b18-d28de5dd883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n",
      "✔️ Saved!\n"
     ]
    }
   ],
   "source": [
    "for i in final_summary_3:\n",
    "    save_article(i)\n",
    "    print(\"✔️ Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8ad5329-f047-435e-8ae4-17bb53f76751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail: 102\n",
      "Fail: 107\n",
      "Pass: 100\n",
      "Pass: 100\n",
      "Pass: 97\n",
      "Fail: 101\n",
      "Fail: 104\n",
      "Pass: 97\n",
      "Fail: 104\n",
      "Pass: 97\n",
      "Pass: 95\n",
      "Pass: 100\n",
      "Fail: 109\n",
      "Pass: 100\n",
      "Fail: 104\n",
      "Pass: 99\n",
      "Fail: 0.4375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fail = []\n",
    "pas = 0\n",
    "\n",
    "for i in final_summary_7:\n",
    "    words = i['output'].split()\n",
    "    word_count = len(words)\n",
    "    if word_count > 100:\n",
    "        print(f\"Fail: {word_count}\")\n",
    "        fail.append(word_count)\n",
    "    else:\n",
    "        print(f\"Pass: {word_count}\")\n",
    "        pas +=1\n",
    "\n",
    "print(f\"Fail: {len(fail)/len(final_summary_7)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "741c45ac-ad5f-4d35-9583-ad2eb2fd10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0483c482-a5cf-4796-b32a-c5e1d4f2f9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "564c7d1d-2082-4629-a59f-db04f7e646e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_article_builder(researched_data):\n",
    "    final_news_article = []\n",
    "    for i in researched_data:\n",
    "        response = client_anthropic.messages.create(\n",
    "            model = \"claude-sonnet-4-5\",\n",
    "            max_tokens = 800,\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\":  f\"\"\"\n",
    "                You are a tech journalist at Krux — a news platform that helps GenZ stay informed about AI & tech in under 60 seconds.\n",
    "\n",
    "                CRITICAL CONSTRAINT: The article body MUST be 85-100 words (excluding headline). Count carefully before finalizing.\n",
    "\n",
    "                TASK: Write a news article using ONLY the information provided by our research assistant. The research assistant will give \n",
    "                you outputs from 2 different types:\n",
    "                1. Blogs/Articles/etc\n",
    "                2. X/Twitter\n",
    "\n",
    "                You need to ingest everything and take out the most relevant points to carefully write an article. By following this structure:\n",
    "                \n",
    "                === STEP 1: HEADLINE (Under 10 words) ===\n",
    "                Objective: Hook the reader instantly\n",
    "                - Punchy, attention-grabbing and clickbait\n",
    "                - Focus on the most surprising/important angle\n",
    "                \n",
    "                **ARTICLE BODY** (85-100 words TOTAL)\n",
    "\n",
    "                Opening (20-30 words):\n",
    "                - If rumour: clarify in first sentence, then proceed assuming the things stated by research assistant are facts\n",
    "                - Lead with the core news hook\n",
    "                \n",
    "                Middle (40-50 words):\n",
    "                - Sharp, conversational, slightly witty tone\n",
    "                - Present key facts from research assistant\n",
    "                - Use most/all provided information\n",
    "                - NO links or source references in body\n",
    "                - Explain it in a simple way such that a non-tech person who has no background about this also understands its impact\n",
    "                \n",
    "                Closing (20-25 words):\n",
    "                - Forward-looking strategic perspective\n",
    "                - What could this mean for industry/users/tech landscape?\n",
    "                - Frame as analysis, NOT opinion\n",
    "                - Grounded in facts presented\n",
    "                \n",
    "                === VERIFICATION CHECKLIST ===\n",
    "                Before outputting, verify:\n",
    "                ☑ Article body is 85-100 words (count manually)\n",
    "                ☑ Headline is under 10 words\n",
    "                ☑ No URLs in article body\n",
    "                ☑ All key facts from research included\n",
    "                ☑ There should be no em-dashes in the article\n",
    "                \n",
    "                HARD CONSTRAINTS:\n",
    "                - Total article: 100 words max (headline excluded). If the Article is NOT 100 words, re-generate it to meet the 100 word\n",
    "                requirement.\n",
    "                - Sources with URLs listed at end under \"Sources:\"\n",
    "\n",
    "                \n",
    "                OUTPUT FORMAT NEEDS TO BE IN A STRICT JSON FORMAT:\n",
    "                {{\"headline\": \"...\", \"output\": \"...\", \"sources\": [{{\"name\": \"...\", \"url\": \"...\"}}]}}\n",
    "\n",
    "                Here is the information we have gathered from the research assistant:\n",
    "\n",
    "                \n",
    "                Research output from news/blogs: {i['deep_research_output']}\n",
    "\n",
    "                Research output from X/Twitter: {i['x_output']}\n",
    "            \"\"\"\n",
    "            }]\n",
    "        )\n",
    "\n",
    "        final_output = response.content[0].text\n",
    "\n",
    "        cleaned = final_output.strip()\n",
    "\n",
    "        if cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned.split(\"\\n\", 1)[1].rsplit(\"```\", 1)[0].strip()\n",
    "\n",
    "        article_json = json.loads(cleaned)\n",
    "\n",
    "        article_json['model_provider'] = 'claude'\n",
    "        article_json['news_date'] = i['news_date']\n",
    "        article_json['event_id'] = i['event_id']\n",
    "\n",
    "        print(article_json)\n",
    "\n",
    "        final_summary_7.append(article_json)\n",
    "\n",
    "        # save_article(article_json)\n",
    "\n",
    "        print(\"✔️ Saved!\")\n",
    "        \n",
    "        \n",
    "\n",
    "    #     final_news_article.append(json_format)\n",
    "\n",
    "    # return final_news_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "09119929-73d5-4739-a924-9c8be8655b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [{\n",
    "    \"id\": 224,\n",
    "    \"event_id\": \"1291_2026-02-20\",\n",
    "    \"news_date\": \"2026-02-20\",\n",
    "    \"x_output\": \"- Sarvam AI released two new large language models, Sarvam 30B and Sarvam 105B, on February 18, 2026.\\n\\n- Both models use Mixture of Experts (MoE) architecture and are built from scratch.\\n\\n- Sarvam 30B activates 1B non-embedded parameters per token.\\n\\n- Sarvam 30B was pretrained on 16 trillion tokens spanning code, web, multilingual, and mathematical data.\\n\\n- Sarvam 30B supports a 32K context window for long-running agentic interactions.\\n\\n- Sarvam 30B targets real-time applications like conversational AI and high-throughput workflows.\\n\\n- Sarvam 105B activates 9B parameters per token.\\n\\n- Sarvam 105B supports a 128K context window.\\n\\n- Sarvam 105B handles complex reasoning, agentic task completion, tool use, coding, mathematics, and science.\\n\\n- Sarvam AI builds full-stack generative AI for population-scale use.\",\n",
    "    \"deep_research_output\": \"- Core development: Sarvam AI unveiled two indigenous LLMs, Sarvam-30B and Sarvam-105B, announced at the India AI Impact Summit 2026 in New Delhi, aimed at real-time use and advanced reasoning; MoE architecture with large context windows; open-sourcing planned. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Model architecture: Both models use a mixture-of-experts design that activates only a fraction of parameters at inference to improve efficiency. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Real-time capabilities: 30B targets production-ready, real-time conversational use with a 32,000-token context window; 105B targets more complex, multi-step reasoning with a 128,000-token window. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Training from scratch: 30B was pre-trained from scratch on about 16 trillion tokens; 105B trained on trillions of tokens across multiple Indian languages. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- IndiaAI Mission and compute: Training leveraged India's government-backed IndiaAI Mission compute, with infrastructure support from Yotta and technical support from Nvidia. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Open-source plan: Sarvam stated it intends to open-source the 30B and 105B models, though it did not specify whether training data or full training code would be disclosed. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Enterprise and ecosystem: The launch outlined an expanded enterprise stack, including Sarvam for Work and a conversational agent platform called Samvaad, plus a vision model for document understanding. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\\n\\n- Indus consumer app: Two days after the model announcements, Sarvam released Indus, a consumer AI chat app powered by the 105B model, available in beta on iOS, Android, and the web; initial rollout limited to India with a waitlist. ([techcrunch.com](https://techcrunch.com/2026/02/20/indias-sarvam-launches-indus-ai-chat-app-as-competition-heats-up/?utm_source=openai))\\n\\n- Benchmark and language focus: The 105B model is positioned to perform on benchmarks relevant to Indian languages and enterprise tasks, with claims of competitive performance against open/closed models of similar size. ([business-standard.com](https://www.business-standard.com/technology/tech-news/sarvam-105b-model-sovereign-ai-india-foundation-model-launch-impact-summit-126021900551_1.html?utm_source=openai))\\n\\n- Industry coverage: Coverage of the announcement and related products appeared in TechCrunch (Feb 18, 2026), Economic Times (ETtech, Feb 18, 2026), Fortune India (Feb 18, 2026), and The Times of India (Feb 19, 2026), among others. ([techcrunch.com](https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/))\"\n",
    "  }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "48c44b9d-4205-46cb-ac7a-0cabdb0452ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'headline': 'Indian Startup Sarvam AI Drops Two Homegrown LLMs', 'output': \"Sarvam AI just unveiled two indigenous large language models, Sarvam-30B and Sarvam-105B, at India's AI Impact Summit 2026. Both were trained from scratch on trillions of tokens across multiple Indian languages using government-backed compute infrastructure. The 30B model targets real-time conversations with a 32,000-token context window, while the 105B handles complex reasoning with a massive 128,000-token window. Both use mixture-of-experts architecture, activating only needed parameters for efficiency. Sarvam plans to open-source both models and launched Indus, a consumer chat app powered by the 105B. This positions India to compete in the global AI race with sovereign, multilingual models tailored for local needs.\", 'sources': [{'name': 'TechCrunch', 'url': 'https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/'}, {'name': 'TechCrunch', 'url': 'https://techcrunch.com/2026/02/20/indias-sarvam-launches-indus-ai-chat-app-as-competition-heats-up/?utm_source=openai'}, {'name': 'Business Standard', 'url': 'https://www.business-standard.com/technology/tech-news/sarvam-105b-model-sovereign-ai-india-foundation-model-launch-impact-summit-126021900551_1.html?utm_source=openai'}], 'model_provider': 'claude', 'news_date': '2026-02-20', 'event_id': '1291_2026-02-20'}\n",
      "✔️ Saved!\n"
     ]
    }
   ],
   "source": [
    "claude_article_builder(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde6cef4-3044-4b69-892b-df2c61370bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "  {\n",
    "    \"headline\": \"India's Sarvam AI Drops Two Homegrown LLMs, Goes Open-Source\",\n",
    "    \"output\": \"Sarvam AI just unveiled two made-in-India language models at the India AI Impact Summit: \n",
    "    Sarvam-30B for real-time chat and Sarvam-105B for complex reasoning. Both use mixture-of-experts architecture, \n",
    "    activating only some parameters to stay efficient while handling massive context windows (32K and 128K tokens). \n",
    "    Trained from scratch on trillions of tokens across Indian languages using government-backed compute, they \n",
    "    rival global models but understand local languages better. Sarvam plans to open-source both and launched Indus, \n",
    "    a consumer chat app powered by 105B. This could make advanced AI accessible across India's linguistic diversity, \n",
    "    challenging Western-dominated models with sovereign, multilingual alternatives.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"Stanford and AWS Team Up for AI Marketing Lab\",\n",
    "    \"output\": \"Stanford HAI and AWS just launched the Stanford and AWS Marketing Science Lab to revolutionize how companies measure marketing effectiveness using AI. The collaboration brings together Stanford's Institute for Human-Centered AI, Data Science department, Graduate School of Business, and AWS cloud infrastructure. Led by top economists including Nobel laureate Guido Imbens and Susan Athey, the lab will tackle causal inference, AI measurement tools, and B2B customer journey analysis. Think smarter ad spend decisions powered by algorithms instead of guesswork. The initiative plans to release published research, open-source code, and prototypes, potentially reshaping how businesses justify their marketing budgets and adopt AI tools at scale.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"ChatGPT's New Lockdown Mode Blocks Live Web Browsing\",\n",
    "    \"output\": \"OpenAI just dropped Lockdown Mode for ChatGPT, a high-security setting rolling out to Enterprise, Edu, Healthcare, and Teachers accounts, with consumer access coming soon. Designed for executives and security teams worried about data leaks, it tackles prompt-injection attacks by blocking live web requests and restricting external app access. Instead of browsing the open internet, ChatGPT can only pull cached content within OpenAI's network. Admins can customize which tools stay active per user. Paired with new Elevated Risk labels flagging dangerous features, this upgrade could reshape how organizations trust AI with sensitive workflows and confidential information.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"Google's Lyria 3 Turns Text Into Music in Gemini\",\n",
    "    \"output\": \"Google DeepMind just dropped Lyria 3 in beta, letting Gemini users create 30-second tracks from text, photos, or videos with auto-generated lyrics and cover art. Think of it as Instagram for your ears: describe a vibe or upload a sunset pic, and get a custom soundtrack perfect for TikTok or Reels. The AI handles genre, mood, tempo, and vocals while blocking artist copycats. Each track gets watermarked via SynthID so you can spot AI audio. Available now on desktop (mobile coming soon) for users 18+ in eight languages, with YouTube Dream Track integration expanding creator access. As AI music tools proliferate, expect short-form content to become hyper-personalized sonic experiences.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"Insurance Startup Qumis Raises $4.3M for Lawyer-Level AI\",\n",
    "    \"output\": \"Chicago-based Qumis just closed an oversubscribed $4.3 million seed round led by MTech Capital, bringing total funding to $6.75 million. The startup uses attorney-trained AI to read complex commercial insurance policies and deliver citation-backed insights with transparent reasoning, replacing tedious manual reviews. Major brokers like NFP, an Aon company, have already scaled from pilot teams to hundreds of users. While most insurance AI tackles workflow automation, Qumis is betting on specialized coverage intelligence. The funds will expand its go-to-market team and deepen product capabilities, positioning it as AI moves beyond document processing into nuanced legal interpretation for underwriting and claims.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"OpenAI and Tata Group Join Forces for India's AI Revolution\",\n",
    "    \"output\": \"OpenAI and Tata Group have announced a massive strategic partnership to accelerate AI transformation across India and beyond. The deal includes deploying ChatGPT Enterprise to hundreds of thousands of TCS employees, building sovereign AI data centers starting at 100 MW (scalable to 1 GW), and developing industry-specific agentic AI solutions. TCS becomes OpenAI's first HyperVault customer, ensuring data stays local and secure. The partnership also brings 100,000 ChatGPT Edu licenses and AI training for one million Indian youth. With new OpenAI offices opening in Mumbai and Bengaluru by 2026, this positions India as a global AI powerhouse while giving enterprises tools to compete in the AI-first economy.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"Fractal's Vaidya 2.0 Beats GPT-5 on Healthcare Benchmark\",\n",
    "    \"output\": \"Fractal just launched Vaidya 2.0, a healthcare AI model that's crushing the competition. It scored 50.1 on OpenAI's notoriously tough HealthBench test, becoming the first model to cross 50 and outperforming both GPT-5 and Google's Gemini Pro 3. Think of it as an AI doctor's assistant that can triage emergencies, check symptoms, and guide patients through treatment. Unlike typical AI models that just recall medical facts, Vaidya 2.0 actually reasons through complex healthcare scenarios. Part of India's $1.2 billion AI push, it's designed specifically for healthcare systems in developing regions, bridging the gap between raw patient data and actual medical action.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"OpenAI Building Smart Speakers, Glasses After $6.5B Acquisition\",\n",
    "    \"output\": \"OpenAI is jumping into consumer hardware with a team of over 200 people developing AI-powered devices, including smart speakers, glasses, and even a smart lamp. This follows their massive $6.5 billion acquisition of io Products, Jony Ive's design firm. The first product, a camera-equipped smart speaker priced at $200 to $300, won't ship until February 2027 at the earliest, while smart glasses are slated for 2028. This pivot from pure software to physical products puts OpenAI in direct competition with Meta's successful Ray-Ban glasses and upcoming wearables from Apple and Google, as AI companies race to embed intelligence into everyday objects around your home.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"OpenAI and Microsoft Join UK's £27M AI Safety Push\",\n",
    "    \"output\": \"OpenAI and Microsoft have officially joined the UK's AI Security Institute's international coalition to keep AI development safe and under human control. The Alignment Project, a UK-led initiative, now boasts over £27 million in funding supporting roughly 60 research projects across eight countries. OpenAI is chipping in £5.6 million, joining partners like Anthropic, AWS, and Canada's CIFAR. Think of it as a global insurance policy: researchers get grants, computing power, and mentorship to ensure future AI systems don't go rogue. With a second funding round opening this summer, the coalition aims to build public trust and enable safer AI deployment in critical services worldwide.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"General Catalyst Drops $5 Billion Bet on India\",\n",
    "    \"output\": \"General Catalyst just pledged $5 billion to India over five years, a massive fivefold jump from its previous $500 million to $1 billion commitment. Announced at the India AI Impact Summit, the funds will flow into AI, healthcare, defense tech, fintech, and consumer startups. GC isn't chasing cutting-edge AI model development. Instead, it's betting on deploying AI solutions at scale in the real world, where India's vast market shines. With CEO Neeraj Arora steering the charge and a portfolio already featuring Zepto and PB Health, this signals India's emergence as a global AI deployment powerhouse, not just a talent hub.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"Google Drops Gemini 3.1 Pro With Wild Reasoning Upgrade\",\n",
    "    \"output\": \"Google just launched Gemini 3.1 Pro, a significantly smarter AI model built for complex problems that need more than quick answers. It scored 77.1% on the ARC-AGI-2 benchmark, literally doubling the reasoning power of its predecessor. The upgrade rolls out today across the Gemini app, NotebookLM, API, and enterprise tools. What makes it wild? It can generate animated website code from text, build live aerospace dashboards tracking the ISS, and even code 3D bird simulations with hand-tracking. This positions Google to compete harder in agentic AI workflows where models actually solve multi-step problems autonomously, not just chat.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"PhonePe Lets You Pay Friends Just By Talking\",\n",
    "    \"output\": \"PhonePe just launched AI-powered voice and text search built on Microsoft Foundry, letting its 650 million users skip menus entirely. Say \\\"Pay Hemanth 20 rupees\\\" and it auto-selects the contact, or ask \\\"Gold price\\\" to jump straight there. The feature uses intent-based routing instead of traditional navigation, understanding what you want and taking you there instantly. It runs on a hybrid on-device and cloud model, keeping your transaction data locked within PhonePe's environment. Rolling out in phases across India via the search bar, help center, and history tab, it signals a shift toward conversational interfaces in fintech.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"India Gets 8-Exaflop AI Supercomputer From UAE Partnership\",\n",
    "    \"output\": \"Abu Dhabi's G42 and MBZUAI, teaming up with Cerebras and India's C-DAC, just announced an 8-exaflop AI supercomputer for India at the India AI Impact Summit 2026. That's mind-blowing computing power for training massive AI models tailored to Indian needs. The system will be hosted entirely in India with full data sovereignty, meaning all your data stays within national borders under Indian governance. Once live, universities, startups, SMEs, and government ministries get access to this beast. This positions India as a serious player in sovereign AI infrastructure, reducing dependence on foreign cloud giants while accelerating homegrown AI innovation at scale.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"Meta's Smartwatch Is Back: 2026 AI Wearable Incoming\",\n",
    "    \"output\": \"Meta is reviving its smartwatch ambitions with Malibu 2, slated for late 2026. The device will pack health tracking and a built-in Meta AI assistant, taking on the Apple Watch directly. This marks a comeback after Meta killed a similar project in 2022 during Reality Labs budget cuts. The smartwatch fits into Meta's broader wearables strategy, potentially syncing with its Ray-Ban smart glasses, which shipped nearly 6 million units in 2025. Meta hasn't officially commented. If successful, the AI-powered watch could anchor an ecosystem where your glasses, wrist, and phone work together seamlessly, pushing wearables beyond fitness into ambient computing.\"\n",
    "  },\n",
    "  {\n",
    "    \"headline\": \"Nvidia Ditches $100B Chip Deal for $30B OpenAI Stake\",\n",
    "    \"output\": \"Nvidia is swapping its massive $100 billion multi-year chip supply agreement for a cleaner $30 billion direct equity investment in OpenAI. This shift makes Nvidia an actual owner, not just a supplier, in the AI giant currently valued at $830 billion. OpenAI's hunting for over $100 billion total this round, with SoftBank and Amazon joining the party. Plot twist: OpenAI plans to spend much of that fresh cash buying Nvidia chips anyway. This move signals Nvidia wants skin in the game beyond hardware sales, positioning itself as a stakeholder in AI's future rather than just the picks-and-shovels provider during the gold rush.\"\n",
    "  }\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
