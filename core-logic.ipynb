{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b46ed8-819c-4a4d-8347-caff49f302ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8b07d2-3fcb-46a4-9874-b66a7d800e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c40f33-7bb1-4a7e-aebf-4d1db65d00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38bc4c18-cf92-4190-a820-f0c111653a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4cae96-3669-40fb-b835-3d15a95026dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b56fdcec-32cd-4788-9cf5-8156a6cd83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea80416d-1664-4839-b31d-2bcc9093297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = os.getenv(\"OPEN_AI_API\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f8272e1-f992-458a-bee3-0fd133157358",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase_url = os.environ.get(\"SUPABASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc341ad2-6d3c-408c-b63c-b4a05e4aa1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase_api_key = os.environ.get(\"SUPBASE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2b82176-a6f5-401c-a8b7-b14dafd53ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase: Client = create_client(supabase_url, supabase_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab5f9626-1868-4244-b649-b1c1f3eaeb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = f\"\"\"\n",
    "SELECT * FROM webhooks order by created_at ASC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67746ecd-b01d-489a-bb10-47b6a3081206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSELECT * FROM webhooks order by created_at ASC\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f09bf645-d850-476a-b383-82697863c7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 2,\n",
       "  'news_output': 'Reuters (Jan 24, 2026) reports the Singapore government will invest over S$1 billion (about $778.8 million) in public AI research through 2030. The funding targets priority research areas including responsible and resource-efficient AI, talent development from pre-university to faculty levels, and building capabilities to support industry adoption of AI. The announcement builds on prior Singapore commitments (e.g., 2024 HPC funding and AI Singapore investments) and is intended to strengthen national AI capabilities and global competitiveness.',\n",
       "  'source_urls': ['https://www.reuters.com/world/asia-pacific/singapore-invest-over-779-million-public-ai-research-through-2030-2026-01-24/']},\n",
       " {'id': 3,\n",
       "  'news_output': \"TechCrunch (Jan 24, 2026) published an analysis titled 'A new test for AI labs: Are you even trying to make money?' The piece proposes a five-level scale to rate AI labs by commercial ambition and summarizes recent funding and personnel developments (references Humans&'s large seed round and leadership departures at Thinking Machines Lab), arguing these developments show how investor appetite and commercialization strategies are shaping which labs pursue productization versus pure research.\",\n",
       "  'source_urls': ['https://techcrunch.com/2026/01/24/a-new-test-for-ai-labs-are-you-even-trying-to-make-money/']},\n",
       " {'id': 4,\n",
       "  'news_output': \"COAIO roundup (Jan 24, 2026) — Industry product/feature updates and research items: New Relic announced enhanced monitoring for custom ChatGPT apps (AI observability); Testlio launched LeoInsights, an AI-powered QA analysis platform for large device/device-matrix testing; reporting highlights Yann LeCun's AMI Labs (world-model research) as an emerging lab. The article summarizes these practical product/tool developments and their implications for deployment, monitoring, and QA of AI systems.\",\n",
       "  'source_urls': ['https://coaio.com/news/2026/01/ai-innovations-transforming-software-development-in-2026/']},\n",
       " {'id': 5,\n",
       "  'news_output': 'AIAgentStore daily digest (Jan 24, 2026) — Several material items aggregated: (1) Agentic-AI security risks shifting to “agency hijacking” (attackers manipulating agents’ tools/memory), (2) a new benchmark (Apex-Agents) showing low real-world task success for agents (best: Gemini 3 Flash ~24%), (3) a reported funding round: Witness AI raised $58M this week to secure enterprise AI/agent usage, and (4) product/agent releases noted (Anthropic’s Claude Cowork desktop tool mentioned for working with AI agents in files). The digest highlights enterprise security, hardware supply pressures (TSMC/Nvidia/Micron), and governance trends that materially affect AI deployments.',\n",
       "  'source_urls': ['https://aiagentstore.ai/ai-agent-news/this-week']},\n",
       " {'id': 6,\n",
       "  'news_output': 'Neurophos announced a Series A funding round raising $110 million (Series A, January 2026) to commercialize its photonic AI chip products; lead investor listed as Gates Frontier with participation from multiple strategic VCs and corporate investors. The round is described as oversubscribed and intended for product commercialization and scaling.',\n",
       "  'source_urls': ['https://www.techcompanynews.com/neurophos-raises-110-million-in-series-a-funding-round/']},\n",
       " {'id': 7,\n",
       "  'news_output': 'Blockit AI (an AI scheduling/agent startup) raised $5 million in a seed/early round led by Sequoia, per reporting; the product is an LLM-powered scheduling agent with freemium pricing and plans to scale via subscription licensing for individuals and teams.',\n",
       "  'source_urls': ['https://m.economictimes.com/tech/funding/ai-scheduling-startup-blockit-ai-raises-5-million-in-round-led-by-sequoia/articleshow/127393530.cms']},\n",
       " {'id': 8,\n",
       "  'news_output': 'At Davos (coverage dated Jan 24, 2026), investors and executives discussed AI shifting from hype to production, with panels emphasizing world models, physical AI and the energy/data center implications of large-scale AI deployments. Coverage notes investor focus shifting to \"conviction-driven\" investments where geopolitics and macro uncertainty influence capital allocation.',\n",
       "  'source_urls': ['https://www.cnbc.com/2026/01/24/davos-ai-greenland-trump-musk-energy-geopolitics.html']},\n",
       " {'id': 9,\n",
       "  'news_output': 'Humans& raised a $480 million seed round at about a $4.48 billion valuation, backed by investors including Nvidia, Jeff Bezos and multiple VC firms. Founded by ex-researchers from Anthropic, Google and xAI, the company will focus on human-centric AI collaboration (multi-agent learning, memory and human-AI interaction) and large-scale model training tailored to collaboration use cases. Report date: Jan 24, 2026.',\n",
       "  'source_urls': ['https://theaiinsider.tech/2026/01/24/humans-secures-480m-seed-round-to-build-human-centric-ai-collaboration-platform/']},\n",
       " {'id': 10,\n",
       "  'news_output': 'Gartner published a January 2026 forecast projecting global AI spending of roughly US$2.52 trillion in 2026 (about 44% year-over-year growth). The report highlights AI infrastructure as the primary growth driver (noting large increases in server and AI-optimized hardware spending) and breaks down spending across services, software and models — a materially larger market sizing that has implications for vendors, cloud providers and chip makers.',\n",
       "  'source_urls': ['https://www.idnfinancials.com/news/60637/gartner-global-ai-spending-to-reach-us2-5-trillion-by-2026']},\n",
       " {'id': 11,\n",
       "  'news_output': 'Meta (reporting summarized Jan 24, 2026) paused teen access to its AI character feature as it rebuilds a safety-focused experience — a product and policy change limiting a class of users while the company redesigns moderation/safety controls for conversational AI characters. This is a notable product-safety adjustment from a major AI platform/operator.',\n",
       "  'source_urls': ['https://theaiinsider.tech/2026/01/24/meta-pauses-teen-access-to-ai-characters-as-it-rebuilds-safety-focused-experience/']}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = supabase.table('webhooks')\\\n",
    "    .select('id, news_output,source_urls')\\\n",
    "    .order('created_at', desc=False)\\\n",
    "    .execute()\n",
    "\n",
    "result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1ded3a86-f0a3-4c4b-b0f4-7adbf57dd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_result = []\n",
    "\n",
    "def result_data():\n",
    "    for item in result.data:\n",
    "        formatted_result.append(\n",
    "            f\"\"\" {item['news_output']} source: {item['source_urls'][0]}\"\"\"\n",
    "        )\n",
    "\n",
    "    print(formatted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f1f70d48-d18b-49a9-b778-2e52d8463678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Reuters (Jan 24, 2026) reports the Singapore government will invest over S$1 billion (about $778.8 million) in public AI research through 2030. The funding targets priority research areas including responsible and resource-efficient AI, talent development from pre-university to faculty levels, and building capabilities to support industry adoption of AI. The announcement builds on prior Singapore commitments (e.g., 2024 HPC funding and AI Singapore investments) and is intended to strengthen national AI capabilities and global competitiveness. source: https://www.reuters.com/world/asia-pacific/singapore-invest-over-779-million-public-ai-research-through-2030-2026-01-24/', \" TechCrunch (Jan 24, 2026) published an analysis titled 'A new test for AI labs: Are you even trying to make money?' The piece proposes a five-level scale to rate AI labs by commercial ambition and summarizes recent funding and personnel developments (references Humans&'s large seed round and leadership departures at Thinking Machines Lab), arguing these developments show how investor appetite and commercialization strategies are shaping which labs pursue productization versus pure research. source: https://techcrunch.com/2026/01/24/a-new-test-for-ai-labs-are-you-even-trying-to-make-money/\", \" COAIO roundup (Jan 24, 2026) — Industry product/feature updates and research items: New Relic announced enhanced monitoring for custom ChatGPT apps (AI observability); Testlio launched LeoInsights, an AI-powered QA analysis platform for large device/device-matrix testing; reporting highlights Yann LeCun's AMI Labs (world-model research) as an emerging lab. The article summarizes these practical product/tool developments and their implications for deployment, monitoring, and QA of AI systems. source: https://coaio.com/news/2026/01/ai-innovations-transforming-software-development-in-2026/\", ' AIAgentStore daily digest (Jan 24, 2026) — Several material items aggregated: (1) Agentic-AI security risks shifting to “agency hijacking” (attackers manipulating agents’ tools/memory), (2) a new benchmark (Apex-Agents) showing low real-world task success for agents (best: Gemini 3 Flash ~24%), (3) a reported funding round: Witness AI raised $58M this week to secure enterprise AI/agent usage, and (4) product/agent releases noted (Anthropic’s Claude Cowork desktop tool mentioned for working with AI agents in files). The digest highlights enterprise security, hardware supply pressures (TSMC/Nvidia/Micron), and governance trends that materially affect AI deployments. source: https://aiagentstore.ai/ai-agent-news/this-week', ' Neurophos announced a Series A funding round raising $110 million (Series A, January 2026) to commercialize its photonic AI chip products; lead investor listed as Gates Frontier with participation from multiple strategic VCs and corporate investors. The round is described as oversubscribed and intended for product commercialization and scaling. source: https://www.techcompanynews.com/neurophos-raises-110-million-in-series-a-funding-round/', ' Blockit AI (an AI scheduling/agent startup) raised $5 million in a seed/early round led by Sequoia, per reporting; the product is an LLM-powered scheduling agent with freemium pricing and plans to scale via subscription licensing for individuals and teams. source: https://m.economictimes.com/tech/funding/ai-scheduling-startup-blockit-ai-raises-5-million-in-round-led-by-sequoia/articleshow/127393530.cms', ' At Davos (coverage dated Jan 24, 2026), investors and executives discussed AI shifting from hype to production, with panels emphasizing world models, physical AI and the energy/data center implications of large-scale AI deployments. Coverage notes investor focus shifting to \"conviction-driven\" investments where geopolitics and macro uncertainty influence capital allocation. source: https://www.cnbc.com/2026/01/24/davos-ai-greenland-trump-musk-energy-geopolitics.html', ' Humans& raised a $480 million seed round at about a $4.48 billion valuation, backed by investors including Nvidia, Jeff Bezos and multiple VC firms. Founded by ex-researchers from Anthropic, Google and xAI, the company will focus on human-centric AI collaboration (multi-agent learning, memory and human-AI interaction) and large-scale model training tailored to collaboration use cases. Report date: Jan 24, 2026. source: https://theaiinsider.tech/2026/01/24/humans-secures-480m-seed-round-to-build-human-centric-ai-collaboration-platform/', ' Gartner published a January 2026 forecast projecting global AI spending of roughly US$2.52 trillion in 2026 (about 44% year-over-year growth). The report highlights AI infrastructure as the primary growth driver (noting large increases in server and AI-optimized hardware spending) and breaks down spending across services, software and models — a materially larger market sizing that has implications for vendors, cloud providers and chip makers. source: https://www.idnfinancials.com/news/60637/gartner-global-ai-spending-to-reach-us2-5-trillion-by-2026', ' Meta (reporting summarized Jan 24, 2026) paused teen access to its AI character feature as it rebuilds a safety-focused experience — a product and policy change limiting a class of users while the company redesigns moderation/safety controls for conversational AI characters. This is a notable product-safety adjustment from a major AI platform/operator. source: https://theaiinsider.tech/2026/01/24/meta-pauses-teen-access-to-ai-characters-as-it-rebuilds-safety-focused-experience/']\n"
     ]
    }
   ],
   "source": [
    "result_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9625fddb-ed95-4141-baa1-753e668122eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_research(data):\n",
    "    research_output = []\n",
    "    for i in data:\n",
    "        response = client.responses.create(\n",
    "            model = \"gpt-4o\",\n",
    "            # reasoning = {\"effort\": \"high\"},\n",
    "            tools = [{\n",
    "                \"type\": \"web_search\"\n",
    "            }],\n",
    "\n",
    "            include = [\"web_search_call.action.sources\"],\n",
    "            input = f\"\"\" \n",
    "            You are given news summary and source in {i}, you are supposed to run a deep research and read other sources as well. \n",
    "            And then give a well structured ouput in the form of points and sources. \n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        output = response.output_text\n",
    "\n",
    "        research_output.append(output)\n",
    "\n",
    "    return research_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03348231-c584-4122-8c02-32173234ca90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is a well-structured, in-depth analysis of the situation, integrating multiple sources and organized into clear points with citations. I\\'ve used full markdown formatting (without a title) as requested.\\n\\n---\\n\\n##  Summary of the Development\\n\\n- Meta (owner of Facebook, Instagram, WhatsApp) has **temporarily paused teen access to its AI characters** across all apps globally, effective \"in the coming weeks.\" Teens flagged by date-of-birth or age‑prediction technology are affected. However, they will **still be able to use Meta’s AI assistant**, which includes age‑appropriate protections ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n- The pause aligns with Meta’s plan to **launch a newly rebuilt AI character experience** that integrates stronger **parental controls** and offers **age‑appropriate, limited themes**. When relaunched, characters will focus on topics like education, sports, and hobbies ([theaiinsider.tech](https://theaiinsider.tech/2026/01/24/meta-pauses-teen-access-to-ai-characters-as-it-rebuilds-safety-focused-experience/?utm_source=openai)).\\n\\n- The move comes amid rising **legal and regulatory scrutiny** of tech platforms’ impact on minors. Meta faces trials in Los Angeles and New Mexico related to potential harm to children. Radiating broader industry alertness, other firms like Character.AI have issued similar restrictions following lawsuits alleging unsafe chatbot interactions ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n---\\n\\n##  Background and Timeline\\n\\n**October 2025**\\n- Meta previewed **new parental control tools**: guardians could disable teen chats with AI characters, block specific bots, and receive insights on conversation topics (without full transcripts). These would roll out early 2026 in English-speaking countries including the US ([theguardian.com](https://www.theguardian.com/technology/2025/oct/18/parents-will-be-able-to-block-meta-bots-from-talking-to-their-children-under-new-safeguards?utm_source=openai)).\\n\\n**August 2025**\\n- After a Reuters exposé about AI bots engaging teens in romantic or self-harm content, Meta updated its AI to **avoid such topics** and **limit teen access to select characters**, redirecting to expert resources when needed ([businessinsider.com](https://www.businessinsider.com/meta-changes-the-way-its-ai-chatbot-responds-to-children-2025-8?utm_source=openai)).\\n\\n**Late 2025**\\n- Character.AI responded to lawsuits—including one involving a teen suicide—by **banning under‑18 users** and limiting teen usage before a full block by November 2025 ([nypost.com](https://nypost.com/2025/10/29/business/character-ai-bans-chatbots-for-teens-after-lawsuits-blame-app-for-deaths-suicide-attempts/?utm_source=openai)).\\n\\n**January 23, 2026**\\n- Meta announced its **temporary pause**, ahead of the new version launch ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n---\\n\\n##  Key Motivations & Factors\\n\\n- **Parental Concerns & Feedback**: Parents emphasized desire for more transparency and oversight over teens’ AI interactions, which Meta cited as a key influence in their decision ([theverge.com](https://www.theverge.com/news/866906/meta-teens-ai-characters-stop-block-new-version?utm_source=openai)).\\n\\n- **Regulatory Pressure**: \\n  - Meta faces trials in both Los Angeles and New Mexico over platform harm to teens ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n  - Broader legal and regulatory scrutiny is ongoing (including FTC investigations and state legislation in California mandating bot-user reminders and self-harm safeguards) ([lemonde.fr](https://www.lemonde.fr/en/economy/article/2025/10/15/california-plans-on-protecting-minors-and-preventing-self-destructive-content-by-regulating-ai_6746443_19.html?utm_source=openai)).\\n\\n- **Industry-Wide Safety Movement**: Meta’s move is part of a broader pattern. Character.AI’s actions and legal challenges, along with safety research into AI character interactions, reflect growing focus on youth safety in AI platforms ([nypost.com](https://nypost.com/2025/10/29/business/character-ai-bans-chatbots-for-teens-after-lawsuits-blame-app-for-deaths-suicide-attempts/?utm_source=openai)).\\n\\n---\\n\\n##  What To Expect Next\\n\\n- Once the **updated AI character experience** is ready, it will include:\\n  - **Robust parental controls**—enable or disable full AI character chats or block specific characters; parents will see conversation topics ([techcrunch.com](https://techcrunch.com/2026/01/23/meta-pauses-teen-access-to-ai-characters-ahead-of-new-version/?utm_source=openai)).\\n  - **Age‑appropriate design**: characters will avoid sensitive content (self-harm, romance) and focus on safe themes ([theaiinsider.tech](https://theaiinsider.tech/2026/01/24/meta-pauses-teen-access-to-ai-characters-as-it-rebuilds-safety-focused-experience/?utm_source=openai)).\\n  - **Parental transparency** tools with topic-level insights (not full transcripts) will allow guardians to engage meaningfully with teens about AI usage ([apnews.com](https://apnews.com/article/306b9c49ef69f6894044b2d82c6172fe?utm_source=openai)).\\n\\n- Meta’s AI assistant will remain accessible to teens throughout, with built-in protective design ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n- With trials commencing soon, Meta will likely combine this product move with public messaging to show proactive responsibility.\\n\\n---\\n\\n##  Broader Implications & Context\\n\\n- **Product-Safety Interventions**: Temporarily limiting a user group (teens) while redesigning features represents a strong risk-mitigation strategy, signaling a shift toward safety-first in AI deployments.\\n\\n- **Youth Vulnerability in Conversational AI**:\\n  - Research shows youth are particularly susceptible to emotional relationships with anthropomorphic chatbots, often preferring relational styles that heighten anthropomorphism and emotional reliance ([arxiv.org](https://arxiv.org/abs/2512.15117?utm_source=openai)).\\n  - AI character platforms demonstrate significant safety risks—with studies indicating unsafe response rates exceeding 65%, compared with 17.7% for baseline systems ([arxiv.org](https://arxiv.org/abs/2512.01247?utm_source=openai)).\\n  - Dedicated youth‑centric safety tools like YouthSafe show effectiveness in detecting developmental risks such as grooming or emotional overreliance ([arxiv.org](https://arxiv.org/abs/2509.08997?utm_source=openai)).\\n\\n- **Policy Landscape**:\\n  - California’s law, for instance, now requires AI platforms to clearly indicate chatbot status and protect against self-harm content, with recurring reminders for minors ([lemonde.fr](https://www.lemonde.fr/en/economy/article/2025/10/15/california-plans-on-protecting-minors-and-preventing-self-destructive-content-by-regulating-ai_6746443_19.html?utm_source=openai)).\\n  - Industry precedent like Meta’s move may influence or expedite federal-level regulation and enforcement.\\n\\n---\\n\\n##  Summary Points\\n\\n- Meta has **paused teen access** to its AI characters globally, effective \"in the coming weeks,\" but teens retain access to the AI assistant ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n- This pause enables Meta to design a **safer AI character experience**, embedding **parental controls** and focusing on **PG-13 style, age-appropriate content** ([techcrunch.com](https://techcrunch.com/2026/01/23/meta-pauses-teen-access-to-ai-characters-ahead-of-new-version/?utm_source=openai)).\\n\\n- The decision responds to **parental demand**, **legal trials**, and wider **regulatory pressure**, while aligning with a broader industry move toward youth safety in AI ([lemonde.fr](https://www.lemonde.fr/en/economy/article/2025/10/15/california-plans-on-protecting-minors-and-preventing-self-destructive-content-by-regulating-ai_6746443_19.html?utm_source=openai)).\\n\\n- Research underscores teens\\' heightened **emotional vulnerability** with AI characters, justifying measures like these ([arxiv.org](https://arxiv.org/abs/2512.15117?utm_source=openai)).\\n\\n---\\n\\nLet me know if you\\'d like a deeper breakdown of Meta’s regulatory risks, comparisons with other AI platforms, or a timeline tracking similar safety interventions in the AI industry.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [' Meta (reporting summarized Jan 24, 2026) paused teen access to its AI character feature as it rebuilds a safety-focused experience — a product and policy change limiting a class of users while the company redesigns moderation/safety controls for conversational AI characters. This is a notable product-safety adjustment from a major AI platform/operator. source: https://theaiinsider.tech/2026/01/24/meta-pauses-teen-access-to-ai-characters-as-it-rebuilds-safety-focused-experience/']\n",
    "\n",
    "openai_research(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90c81620-699a-4b2f-afa7-241559a24ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_article_builder(researched_data):\n",
    "    final_news_article = []\n",
    "    for i in researched_data:\n",
    "        response = client.responses.create(\n",
    "            model = \"gpt-4.1\",\n",
    "            input = f\"\"\" \n",
    "            You are a professional tech journalist for \"The AI Times\" newspaper.\n",
    "\n",
    "            Your task: Write a comprehensive news article covering today's AI developments.\n",
    "            \n",
    "            Entire news story and its details: {i}\n",
    "            \n",
    "            INSTRUCTIONS:\n",
    "            1. Write a newspaper-quality article (800-1000 words)\n",
    "            2. Create an engaging headline\n",
    "            3. Start with a lead paragraph summarizing the most important developments\n",
    "            5. Use journalistic style: objective, clear, professional and opinionated\n",
    "            6. Include all the sources & links at the end and not ANY sources or links during the article\n",
    "\n",
    "            You are ONLY supposed to refer to the sources and links and NOT supposed to hallucinate. \n",
    "            \n",
    "            However, the opinion you have be your own but it should be based on the above article. \n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "\n",
    "        final_output = response.output_text\n",
    "\n",
    "        print(final_output)\n",
    "\n",
    "        final_news_article.append(final_output)\n",
    "\n",
    "    return final_news_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef38ab0a-0423-49d4-8ff4-6ac7d2877def",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ['Below is a well-structured, in-depth analysis of the situation, integrating multiple sources and organized into clear points with citations. I\\'ve used full markdown formatting (without a title) as requested.\\n\\n---\\n\\n##  Summary of the Development\\n\\n- Meta (owner of Facebook, Instagram, WhatsApp) has **temporarily paused teen access to its AI characters** across all apps globally, effective \"in the coming weeks.\" Teens flagged by date-of-birth or age‑prediction technology are affected. However, they will **still be able to use Meta’s AI assistant**, which includes age‑appropriate protections ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n- The pause aligns with Meta’s plan to **launch a newly rebuilt AI character experience** that integrates stronger **parental controls** and offers **age‑appropriate, limited themes**. When relaunched, characters will focus on topics like education, sports, and hobbies ([theaiinsider.tech](https://theaiinsider.tech/2026/01/24/meta-pauses-teen-access-to-ai-characters-as-it-rebuilds-safety-focused-experience/?utm_source=openai)).\\n\\n- The move comes amid rising **legal and regulatory scrutiny** of tech platforms’ impact on minors. Meta faces trials in Los Angeles and New Mexico related to potential harm to children. Radiating broader industry alertness, other firms like Character.AI have issued similar restrictions following lawsuits alleging unsafe chatbot interactions ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n---\\n\\n##  Background and Timeline\\n\\n**October 2025**\\n- Meta previewed **new parental control tools**: guardians could disable teen chats with AI characters, block specific bots, and receive insights on conversation topics (without full transcripts). These would roll out early 2026 in English-speaking countries including the US ([theguardian.com](https://www.theguardian.com/technology/2025/oct/18/parents-will-be-able-to-block-meta-bots-from-talking-to-their-children-under-new-safeguards?utm_source=openai)).\\n\\n**August 2025**\\n- After a Reuters exposé about AI bots engaging teens in romantic or self-harm content, Meta updated its AI to **avoid such topics** and **limit teen access to select characters**, redirecting to expert resources when needed ([businessinsider.com](https://www.businessinsider.com/meta-changes-the-way-its-ai-chatbot-responds-to-children-2025-8?utm_source=openai)).\\n\\n**Late 2025**\\n- Character.AI responded to lawsuits—including one involving a teen suicide—by **banning under‑18 users** and limiting teen usage before a full block by November 2025 ([nypost.com](https://nypost.com/2025/10/29/business/character-ai-bans-chatbots-for-teens-after-lawsuits-blame-app-for-deaths-suicide-attempts/?utm_source=openai)).\\n\\n**January 23, 2026**\\n- Meta announced its **temporary pause**, ahead of the new version launch ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n---\\n\\n##  Key Motivations & Factors\\n\\n- **Parental Concerns & Feedback**: Parents emphasized desire for more transparency and oversight over teens’ AI interactions, which Meta cited as a key influence in their decision ([theverge.com](https://www.theverge.com/news/866906/meta-teens-ai-characters-stop-block-new-version?utm_source=openai)).\\n\\n- **Regulatory Pressure**: \\n  - Meta faces trials in both Los Angeles and New Mexico over platform harm to teens ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n  - Broader legal and regulatory scrutiny is ongoing (including FTC investigations and state legislation in California mandating bot-user reminders and self-harm safeguards) ([lemonde.fr](https://www.lemonde.fr/en/economy/article/2025/10/15/california-plans-on-protecting-minors-and-preventing-self-destructive-content-by-regulating-ai_6746443_19.html?utm_source=openai)).\\n\\n- **Industry-Wide Safety Movement**: Meta’s move is part of a broader pattern. Character.AI’s actions and legal challenges, along with safety research into AI character interactions, reflect growing focus on youth safety in AI platforms ([nypost.com](https://nypost.com/2025/10/29/business/character-ai-bans-chatbots-for-teens-after-lawsuits-blame-app-for-deaths-suicide-attempts/?utm_source=openai)).\\n\\n---\\n\\n##  What To Expect Next\\n\\n- Once the **updated AI character experience** is ready, it will include:\\n  - **Robust parental controls**—enable or disable full AI character chats or block specific characters; parents will see conversation topics ([techcrunch.com](https://techcrunch.com/2026/01/23/meta-pauses-teen-access-to-ai-characters-ahead-of-new-version/?utm_source=openai)).\\n  - **Age‑appropriate design**: characters will avoid sensitive content (self-harm, romance) and focus on safe themes ([theaiinsider.tech](https://theaiinsider.tech/2026/01/24/meta-pauses-teen-access-to-ai-characters-as-it-rebuilds-safety-focused-experience/?utm_source=openai)).\\n  - **Parental transparency** tools with topic-level insights (not full transcripts) will allow guardians to engage meaningfully with teens about AI usage ([apnews.com](https://apnews.com/article/306b9c49ef69f6894044b2d82c6172fe?utm_source=openai)).\\n\\n- Meta’s AI assistant will remain accessible to teens throughout, with built-in protective design ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n- With trials commencing soon, Meta will likely combine this product move with public messaging to show proactive responsibility.\\n\\n---\\n\\n##  Broader Implications & Context\\n\\n- **Product-Safety Interventions**: Temporarily limiting a user group (teens) while redesigning features represents a strong risk-mitigation strategy, signaling a shift toward safety-first in AI deployments.\\n\\n- **Youth Vulnerability in Conversational AI**:\\n  - Research shows youth are particularly susceptible to emotional relationships with anthropomorphic chatbots, often preferring relational styles that heighten anthropomorphism and emotional reliance ([arxiv.org](https://arxiv.org/abs/2512.15117?utm_source=openai)).\\n  - AI character platforms demonstrate significant safety risks—with studies indicating unsafe response rates exceeding 65%, compared with 17.7% for baseline systems ([arxiv.org](https://arxiv.org/abs/2512.01247?utm_source=openai)).\\n  - Dedicated youth‑centric safety tools like YouthSafe show effectiveness in detecting developmental risks such as grooming or emotional overreliance ([arxiv.org](https://arxiv.org/abs/2509.08997?utm_source=openai)).\\n\\n- **Policy Landscape**:\\n  - California’s law, for instance, now requires AI platforms to clearly indicate chatbot status and protect against self-harm content, with recurring reminders for minors ([lemonde.fr](https://www.lemonde.fr/en/economy/article/2025/10/15/california-plans-on-protecting-minors-and-preventing-self-destructive-content-by-regulating-ai_6746443_19.html?utm_source=openai)).\\n  - Industry precedent like Meta’s move may influence or expedite federal-level regulation and enforcement.\\n\\n---\\n\\n##  Summary Points\\n\\n- Meta has **paused teen access** to its AI characters globally, effective \"in the coming weeks,\" but teens retain access to the AI assistant ([apnews.com](https://apnews.com/article/f64d53df26893cfefa97dc1249d73ab6?utm_source=openai)).\\n\\n- This pause enables Meta to design a **safer AI character experience**, embedding **parental controls** and focusing on **PG-13 style, age-appropriate content** ([techcrunch.com](https://techcrunch.com/2026/01/23/meta-pauses-teen-access-to-ai-characters-ahead-of-new-version/?utm_source=openai)).\\n\\n- The decision responds to **parental demand**, **legal trials**, and wider **regulatory pressure**, while aligning with a broader industry move toward youth safety in AI ([lemonde.fr](https://www.lemonde.fr/en/economy/article/2025/10/15/california-plans-on-protecting-minors-and-preventing-self-destructive-content-by-regulating-ai_6746443_19.html?utm_source=openai)).\\n\\n- Research underscores teens\\' heightened **emotional vulnerability** with AI characters, justifying measures like these ([arxiv.org](https://arxiv.org/abs/2512.15117?utm_source=openai)).\\n\\n---\\n\\nLet me know if you\\'d like a deeper breakdown of Meta’s regulatory risks, comparisons with other AI platforms, or a timeline tracking similar safety interventions in the AI industry.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7abaa48c-f807-485a-a404-16764d0556b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Meta Puts Teen Access to AI Characters on Hold Amid Regulatory Storm and Safety Concerns**\n",
      "\n",
      "Meta, the social media titan behind Facebook, Instagram, and WhatsApp, is taking the extraordinary step of pausing teen access to its popular AI-powered characters across all its platforms worldwide. The decision, set to be implemented in the coming weeks, arrives at a watershed moment for both Meta and the wider AI industry, as companies grapple with the growing outcry over the safety and psychological risks of conversational bots for younger users.\n",
      "\n",
      "**A Precaution Amid Intensifying Scrutiny**\n",
      "\n",
      "For years, tech companies have cultivated AI chatbots as the next leap in digital engagement. These virtual personalities, ranging from celebrity-inspired characters to customized “friends,” have become ubiquitous—especially among teens craving connection and entertainment online. Yet, as headlines about concerning chatbot interactions multiply and legal battles escalate, Meta’s temporary ban underscores both industry anxiety and a newfound willingness to prioritize safety over expansion.\n",
      "\n",
      "Teens identified through self-reported birthdate or age-prediction algorithms will be unable to access Meta’s suite of AI characters. Notably, the company will continue to offer its basic AI assistant—with what it describes as “age-appropriate protections”—to minors, ensuring that some AI functionality remains while a more robust system is rebuilt.\n",
      "\n",
      "**The Road to Reform: Pressure from Parents, Lawmakers, and Courts**\n",
      "\n",
      "Several converging forces have nudged Meta toward this radical, if temporary, measure:\n",
      "\n",
      "- **Parental Anxiety**: Repeated feedback from parents has pressed Meta to offer greater transparency and oversight, voicing concerns about unsupervised AI chats and the real impact on adolescent wellbeing.\n",
      "\n",
      "- **Legal and Regulatory Threats**: Meta now faces lawsuits in courts from Los Angeles to New Mexico, with plaintiffs alleging that the platform’s AI characters have exposed minors to dangerous or harmful content—including topics like romance and self-harm. Regulatory scrutiny is increasing, with states such as California pushing for new laws mandating safety features, bot disclosures, and explicit protections for underage users.\n",
      "\n",
      "- **Precedents in the Tech World**: The move is not happening in a vacuum. Rivals such as Character.AI have already clamped down by banning under-18s and disabling sensitive chatbot topics after high-profile lawsuits linked unsafe AI interactions to tragic outcomes.\n",
      "\n",
      "- **Academic Research and Advocacy**: A mounting body of research reveals just how susceptible teens are to emotional entanglement with anthropomorphic chatbots. Studies have demonstrated that adolescents may rapidly form attachments to virtual agents, exposing themselves to unhealthy levels of dependence and vulnerability to manipulation or inappropriate content. Alarmingly, investigations have shown that certain AI character platforms generate unsafe or age-inappropriate responses in as many as 65% of test cases—a rate multiple times higher than baseline models.\n",
      "\n",
      "**Inside Meta’s Reboot: What’s Changing and Why**\n",
      "\n",
      "Meta’s stated aim is to overhaul its AI character experience with a suite of new parental control tools, tighter content restrictions, and more transparent reporting for guardians. When the upgraded system relaunches, teens—and their parents—can expect:\n",
      "\n",
      "- **Full Parental Oversight**: Parents will be able to disable or enable AI character chats, block access to specific characters, or restrict subject matter outright. Guardians will also gain insight into the themes discussed by their children, though not the full chat transcripts—a balance between privacy and safety.\n",
      "\n",
      "- **Reimagined Content Boundaries**: Gone will be the AI characters capable of straying into risky territory. The new experience will focus on “safe,” constructive topics such as education, sports, and hobbies, steering clear of issues like romance, self-harm, or violence.\n",
      "\n",
      "- **Transparency and Engagement**: Meta will introduce tools for parental transparency, allowing for better communication between families about the nature of teens’ interactions with AI and encouraging more active parental involvement.\n",
      "\n",
      "During this transition, teens will maintain access to Meta’s core AI assistant, which is designed to avoid risky discussions and promote responsible usage.\n",
      "\n",
      "**Broader Industry Reverberations and the Ethics of AI for Youth**\n",
      "\n",
      "Meta’s pause and redesign signal the start of a new chapter in AI product safety. It’s a marked departure from the industry’s earlier, sometimes reckless, pursuit of user engagement at any cost. In effect, it’s a tacit admission that—when it comes to emerging technologies and young users—speed must sometimes yield to caution.\n",
      "\n",
      "This move also casts a long shadow across the industry. If the world’s largest social network can freeze features for millions of users to address safety concerns, rivals will feel pressure to prove their own vigilance. With more jurisdictions weighing in—from the FTC to state legislatures—it may foreshadow a wave of new rules and a standardization of youth protections in the AI ecosystem.\n",
      "\n",
      "Policy trends are already moving in this direction. For example, California has enacted legislation compelling platforms to clearly disclose when users are chatting with a bot and to implement consistent reminders and checks against exposure to self-harm content. Academics have developed and piloted tools specifically to scan for patterns of grooming or emotional over-attachment in youth’s AI interactions, showing real promise at catching risks before they crystallize into harm.\n",
      "\n",
      "**Navigating the Tension: Innovation Versus Safety**\n",
      "\n",
      "There is a clear tension here: AI character chatbots have the potential for educational enrichment, social support, and creative interaction. Banning or restricting them wholesale for young people risks both stifling innovation and depriving teens of potentially positive uses. Yet the evidence is mounting that, left unchecked, these systems can exploit emotional vulnerabilities, introduce harmful ideas, and lead to tragic outcomes.\n",
      "\n",
      "Meta’s leadership—however belated or self-interested—is a watershed moment. By taking a pause, it acknowledges the mistakes and blind spots of the “move fast and break things” era. It also sets a blueprint for AI safety interventions: temporary restriction, parent-first design, transparent reporting, and a genuine willingness to listen to outside expertise and concerns.\n",
      "\n",
      "**The Takeaway: Setting a New Industry Bar**\n",
      "\n",
      "As legal trials begin and the next generation of AI features takes shape, the world will be watching Meta carefully. Will its revamped controls set a new standard for teen safety? Will regulators step in with tougher mandates, or will industry self-regulation suffice? And how will parents, once skeptical, respond to systems designed for partnership instead of secrecy?\n",
      "\n",
      "One thing is clear: the age of unchecked AI access for minors is ending. For Meta, and the entire industry, the challenge ahead is not just technical—it's ethical, cultural, and human. Getting it right may be the most important innovation of all.\n",
      "\n",
      "---\n",
      "\n",
      "**Sources**  \n",
      "- apnews.com  \n",
      "- theaiinsider.tech  \n",
      "- theguardian.com  \n",
      "- businessinsider.com  \n",
      "- nypost.com  \n",
      "- theverge.com  \n",
      "- lemonde.fr  \n",
      "- techcrunch.com  \n",
      "- arxiv.org\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"**Meta Puts Teen Access to AI Characters on Hold Amid Regulatory Storm and Safety Concerns**\\n\\nMeta, the social media titan behind Facebook, Instagram, and WhatsApp, is taking the extraordinary step of pausing teen access to its popular AI-powered characters across all its platforms worldwide. The decision, set to be implemented in the coming weeks, arrives at a watershed moment for both Meta and the wider AI industry, as companies grapple with the growing outcry over the safety and psychological risks of conversational bots for younger users.\\n\\n**A Precaution Amid Intensifying Scrutiny**\\n\\nFor years, tech companies have cultivated AI chatbots as the next leap in digital engagement. These virtual personalities, ranging from celebrity-inspired characters to customized “friends,” have become ubiquitous—especially among teens craving connection and entertainment online. Yet, as headlines about concerning chatbot interactions multiply and legal battles escalate, Meta’s temporary ban underscores both industry anxiety and a newfound willingness to prioritize safety over expansion.\\n\\nTeens identified through self-reported birthdate or age-prediction algorithms will be unable to access Meta’s suite of AI characters. Notably, the company will continue to offer its basic AI assistant—with what it describes as “age-appropriate protections”—to minors, ensuring that some AI functionality remains while a more robust system is rebuilt.\\n\\n**The Road to Reform: Pressure from Parents, Lawmakers, and Courts**\\n\\nSeveral converging forces have nudged Meta toward this radical, if temporary, measure:\\n\\n- **Parental Anxiety**: Repeated feedback from parents has pressed Meta to offer greater transparency and oversight, voicing concerns about unsupervised AI chats and the real impact on adolescent wellbeing.\\n\\n- **Legal and Regulatory Threats**: Meta now faces lawsuits in courts from Los Angeles to New Mexico, with plaintiffs alleging that the platform’s AI characters have exposed minors to dangerous or harmful content—including topics like romance and self-harm. Regulatory scrutiny is increasing, with states such as California pushing for new laws mandating safety features, bot disclosures, and explicit protections for underage users.\\n\\n- **Precedents in the Tech World**: The move is not happening in a vacuum. Rivals such as Character.AI have already clamped down by banning under-18s and disabling sensitive chatbot topics after high-profile lawsuits linked unsafe AI interactions to tragic outcomes.\\n\\n- **Academic Research and Advocacy**: A mounting body of research reveals just how susceptible teens are to emotional entanglement with anthropomorphic chatbots. Studies have demonstrated that adolescents may rapidly form attachments to virtual agents, exposing themselves to unhealthy levels of dependence and vulnerability to manipulation or inappropriate content. Alarmingly, investigations have shown that certain AI character platforms generate unsafe or age-inappropriate responses in as many as 65% of test cases—a rate multiple times higher than baseline models.\\n\\n**Inside Meta’s Reboot: What’s Changing and Why**\\n\\nMeta’s stated aim is to overhaul its AI character experience with a suite of new parental control tools, tighter content restrictions, and more transparent reporting for guardians. When the upgraded system relaunches, teens—and their parents—can expect:\\n\\n- **Full Parental Oversight**: Parents will be able to disable or enable AI character chats, block access to specific characters, or restrict subject matter outright. Guardians will also gain insight into the themes discussed by their children, though not the full chat transcripts—a balance between privacy and safety.\\n\\n- **Reimagined Content Boundaries**: Gone will be the AI characters capable of straying into risky territory. The new experience will focus on “safe,” constructive topics such as education, sports, and hobbies, steering clear of issues like romance, self-harm, or violence.\\n\\n- **Transparency and Engagement**: Meta will introduce tools for parental transparency, allowing for better communication between families about the nature of teens’ interactions with AI and encouraging more active parental involvement.\\n\\nDuring this transition, teens will maintain access to Meta’s core AI assistant, which is designed to avoid risky discussions and promote responsible usage.\\n\\n**Broader Industry Reverberations and the Ethics of AI for Youth**\\n\\nMeta’s pause and redesign signal the start of a new chapter in AI product safety. It’s a marked departure from the industry’s earlier, sometimes reckless, pursuit of user engagement at any cost. In effect, it’s a tacit admission that—when it comes to emerging technologies and young users—speed must sometimes yield to caution.\\n\\nThis move also casts a long shadow across the industry. If the world’s largest social network can freeze features for millions of users to address safety concerns, rivals will feel pressure to prove their own vigilance. With more jurisdictions weighing in—from the FTC to state legislatures—it may foreshadow a wave of new rules and a standardization of youth protections in the AI ecosystem.\\n\\nPolicy trends are already moving in this direction. For example, California has enacted legislation compelling platforms to clearly disclose when users are chatting with a bot and to implement consistent reminders and checks against exposure to self-harm content. Academics have developed and piloted tools specifically to scan for patterns of grooming or emotional over-attachment in youth’s AI interactions, showing real promise at catching risks before they crystallize into harm.\\n\\n**Navigating the Tension: Innovation Versus Safety**\\n\\nThere is a clear tension here: AI character chatbots have the potential for educational enrichment, social support, and creative interaction. Banning or restricting them wholesale for young people risks both stifling innovation and depriving teens of potentially positive uses. Yet the evidence is mounting that, left unchecked, these systems can exploit emotional vulnerabilities, introduce harmful ideas, and lead to tragic outcomes.\\n\\nMeta’s leadership—however belated or self-interested—is a watershed moment. By taking a pause, it acknowledges the mistakes and blind spots of the “move fast and break things” era. It also sets a blueprint for AI safety interventions: temporary restriction, parent-first design, transparent reporting, and a genuine willingness to listen to outside expertise and concerns.\\n\\n**The Takeaway: Setting a New Industry Bar**\\n\\nAs legal trials begin and the next generation of AI features takes shape, the world will be watching Meta carefully. Will its revamped controls set a new standard for teen safety? Will regulators step in with tougher mandates, or will industry self-regulation suffice? And how will parents, once skeptical, respond to systems designed for partnership instead of secrecy?\\n\\nOne thing is clear: the age of unchecked AI access for minors is ending. For Meta, and the entire industry, the challenge ahead is not just technical—it's ethical, cultural, and human. Getting it right may be the most important innovation of all.\\n\\n---\\n\\n**Sources**  \\n- apnews.com  \\n- theaiinsider.tech  \\n- theguardian.com  \\n- businessinsider.com  \\n- nypost.com  \\n- theverge.com  \\n- lemonde.fr  \\n- techcrunch.com  \\n- arxiv.org\"]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_article_builder(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f4326-555c-452d-8c7f-bccf216f25b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
